backend/llm_config.py:104:                    print(f"[llm_config] {stage} config from DB: max_tokens={config.get('max_tokens')}", file=sys.stderr)
backend/llm_config.py:106:                    print(f"[llm_config] {stage} no DB config returned, using fallback: max_tokens={config.get('max_tokens')}", file=sys.stderr)
backend/llm_config.py:109:            print(f"[llm_config] get_llm_config failed for {department_id}: {type(e).__name__} - using fallback: max_tokens={config.get('max_tokens')}", file=sys.stderr)
backend/vector_store.py:65:        print(f"[QDRANT] Connected to {QDRANT_URL}")
backend/vector_store.py:69:        print(f"[QDRANT] Connection failed: {e}")
backend/vector_store.py:83:        print("[QDRANT] Connection closed")
backend/vector_store.py:114:                print(f"[QDRANT] Created collection: {collection_name}")
backend/vector_store.py:116:                print(f"[QDRANT] Collection exists: {collection_name}")
backend/vector_store.py:125:                print(f"[QDRANT] Created company_id index for: {collection_name}")
backend/vector_store.py:129:                    print(f"[QDRANT] Index creation note for {collection_name}: {index_err}")
backend/vector_store.py:134:        print(f"[QDRANT] Failed to ensure collections: {e}")
backend/vector_store.py:144:        print("[QDRANT] No OpenRouter API key for embeddings")
backend/vector_store.py:165:        print(f"[QDRANT] Embedding failed: {e}")
backend/vector_store.py:217:        print(f"[QDRANT] Failed to upsert conversation: {e}")
backend/vector_store.py:262:        print(f"[QDRANT] Failed to upsert knowledge entry: {e}")
backend/vector_store.py:311:        print(f"[QDRANT] Search failed: {e}")
backend/vector_store.py:359:        print(f"[QDRANT] Knowledge search failed: {e}")
backend/vector_store.py:378:        print(f"[QDRANT] Delete failed: {e}")
backend/vector_store.py:397:        print(f"[QDRANT] Delete failed: {e}")
backend/cache.py:77:        print(f"[CACHE] Redis connection failed: {e}")
backend/cache.py:178:        print(f"[CACHE] Get failed: {e}")
backend/cache.py:211:        print(f"[CACHE] Set failed: {e}")
backend/cache.py:238:        print(f"[CACHE] Invalidate failed: {e}")
backend/cache.py:289:        print(f"[CACHE] Rate limit check failed: {e}")
backend/sentry.py:69:            print("[Sentry] sentry-sdk not installed. Error tracking disabled.", flush=True)
backend/sentry.py:74:            print("[Sentry] DSN not configured. Error tracking disabled.", flush=True)
backend/sentry.py:114:    print(f"[Sentry] Initialized for environment: {ENVIRONMENT}{release_info}", flush=True)
backend/utils/encryption.py:33:                "Generate one with: python -c \"from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())\""
backend/utils/encryption.py:48:        python -c "import secrets; print(secrets.token_hex(32))"
backend/model_registry.py:104:        print(f"[model_registry] Failed to create Supabase client: {type(e).__name__}", file=sys.stderr)
backend/model_registry.py:150:        print(f"[model_registry] get_models({role}->{resolved_role}) failed: {type(e).__name__}", file=sys.stderr)
backend/mock_llm.py:35:        print(msg)
backend/config.py:30:        print(f"[CONFIG] ERROR: Missing required environment variables: {missing}", file=sys.stderr)
backend/config.py:31:        print("[CONFIG] Please check your .env file or environment configuration.", file=sys.stderr)
backend/config.py:86:        print(f"[CONFIG] Invalid MOCK_LLM_LENGTH_OVERRIDE: {_raw_override}", file=sys.stderr)
