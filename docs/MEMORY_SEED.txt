# Project Architecture Memory Seed
Analyze this project structure and core files to establish a persistent memory of the architecture.

## 1. Directory Structure
```
├── .claude
│   └── settings.local.json
├── .env
├── .github
│   └── copilot-instructions.md
├── .gitignore
├── README.md
├── backend
│   ├── __init__.py
│   ├── attachments.py
│   ├── auth.py
│   ├── billing.py
│   ├── config.py
│   ├── context_loader.py
│   ├── council.py
│   ├── curator.py
│   ├── database.py
│   ├── image_analyzer.py
│   ├── knowledge.py
│   ├── knowledge_fallback.py
│   ├── leaderboard.py
│   ├── main.py
│   ├── migrations
│   │   ├── 003_attachments.sql
│   │   └── 01_organization_schema.sql
│   ├── mock_llm.py
│   ├── openrouter.py
│   ├── org_sync.py
│   ├── routers
│   │   ├── __init__.py
│   │   └── company.py
│   ├── storage.py
│   └── triage.py
├── check_context.py
├── councils
│   ├── README.md
│   ├── departments
│   │   ├── executive
│   │   │   └── _base.md
│   │   ├── legal
│   │   │   └── _base.md
│   │   ├── marketing
│   │   │   ├── _base.md
│   │   │   └── channels
│   │   │       ├── email.md
│   │   │       ├── linkedin.md
│   │   │       └── x.md
│   │   └── sales
│   │       └── _base.md
│   ├── organisations
│   │   ├── axcouncil
│   │   │   ├── config.json
│   │   │   ├── context.md
│   │   │   └── departments
│   │   │       ├── executive
│   │   │       │   └── context.md
│   │   │       ├── finance
│   │   │       │   └── context.md
│   │   │       ├── legal
│   │   │       │   └── context.md
│   │   │       ├── marketing
│   │   │       │   └── context.md
│   │   │       ├── operations
│   │   │       │   ├── context.md
│   │   │       │   └── roles
│   │   │       │       ├── ai-people-culture.md
│   │   │       │       └── ai-ux-ui-designer.md
│   │   │       ├── sales
│   │   │       │   └── context.md
│   │   │       └── technology
│   │   │           ├── context.md
│   │   │           └── roles
│   │   │               ├── ai-ux-ui-designer.md
│   │   │               └── cto.md
│   │   └── simple-af
│   │       ├── config.json
│   │       ├── context.md
│   │       └── departments
│   │           ├── executive
│   │           │   └── context.md
│   │           ├── finance
│   │           │   └── context.md
│   │           ├── legal
│   │           │   └── context.md
│   │           ├── marketing
│   │           │   └── context.md
│   │           ├── operations
│   │           │   └── context.md
│   │           ├── sales
│   │           │   └── context.md
│   │           └── technology
│   │               └── context.md
│   ├── outputs
│   │   ├── analysis.md
│   │   ├── plan.md
│   │   └── post.md
│   └── styles
│       ├── authors
│       │   ├── .gitkeep
│       │   └── ann-friedman.md
│       └── tones
│           ├── formal.md
│           └── informal.md
├── create_project.py
├── docs
│   ├── CLAUDE_MEMORY.md
│   └── MEMORY_SEED.txt
├── fix_selects.py
├── frontend
│   ├── .env
│   ├── .gitignore
│   ├── README.md
│   ├── components.json
│   ├── eslint.config.js
│   ├── index.html
│   ├── jsconfig.json
│   ├── nul
│   ├── package-lock.json
│   ├── package.json
│   ├── postcss.config.js
│   ├── public
│   │   └── vite.svg
│   ├── src
│   │   ├── App.css
│   │   ├── App.jsx
│   │   ├── AuthContext.jsx
│   │   ├── api.js
│   │   ├── assets
│   │   │   └── react.svg
│   │   ├── components
│   │   │   ├── Billing.css
│   │   │   ├── Billing.jsx
│   │   │   ├── ChatInterface.css
│   │   │   ├── ChatInterface.jsx
│   │   │   ├── CouncilProgressCapsule.css
│   │   │   ├── CouncilProgressCapsule.jsx
│   │   │   ├── CuratorPanel.css
│   │   │   ├── CuratorPanel.jsx
│   │   │   ├── ImageUpload.css
│   │   │   ├── ImageUpload.jsx
│   │   │   ├── KnowledgeBase.css
│   │   │   ├── KnowledgeBase.jsx
│   │   │   ├── Leaderboard.css
│   │   │   ├── Leaderboard.jsx
│   │   │   ├── Login.css
│   │   │   ├── Login.jsx
│   │   │   ├── MarkdownViewer.css
│   │   │   ├── MarkdownViewer.jsx
│   │   │   ├── MyCompany.css
│   │   │   ├── MyCompany.jsx
│   │   │   ├── Organization.css
│   │   │   ├── Organization.jsx
│   │   │   ├── ProjectModal.css
│   │   │   ├── ProjectModal.jsx
│   │   │   ├── SaveKnowledgeModal.css
│   │   │   ├── SaveKnowledgeModal.jsx
│   │   │   ├── Settings.css
│   │   │   ├── Settings.jsx
│   │   │   ├── Sidebar.css
│   │   │   ├── Sidebar.jsx
│   │   │   ├── Stage1.css
│   │   │   ├── Stage1.jsx
│   │   │   ├── Stage2.css
│   │   │   ├── Stage2.jsx
│   │   │   ├── Stage3.css
│   │   │   ├── Stage3.jsx
│   │   │   ├── Triage.css
│   │   │   ├── Triage.jsx
│   │   │   └── ui
│   │   │       ├── DepartmentSelect.css
│   │   │       ├── DepartmentSelect.jsx
│   │   │       ├── StatusSelect.css
│   │   │       ├── StatusSelect.jsx
│   │   │       ├── aurora-background.jsx
│   │   │       ├── button.jsx
│   │   │       ├── card.jsx
│   │   │       ├── dialog.jsx
│   │   │       ├── input.jsx
│   │   │       ├── select.css
│   │   │       ├── select.jsx
│   │   │       ├── sonner.jsx
│   │   │       └── textarea.jsx
│   │   ├── index.css
│   │   ├── lib
│   │   │   ├── DESIGN_SYSTEM.md
│   │   │   ├── colors.js
│   │   │   ├── smartTextToMarkdown.js
│   │   │   └── utils.js
│   │   ├── main.jsx
│   │   ├── styles
│   │   │   └── tailwind.css
│   │   ├── supabase.js
│   │   └── utils
│   │       └── diffUtils.js
│   ├── tailwind.config.js
│   ├── vercel.json
│   └── vite.config.js
├── knowledge-base
│   └── README.md
├── main.py
├── migrations
│   ├── 001_knowledge_entries.sql
│   ├── 002_knowledge_schema_expansion.sql
│   ├── 003_enable_rls_hotfix.sql
│   ├── 004_add_curator_history.sql
│   └── 005_conversation_star_archive.sql
├── nul
├── pyproject.toml
├── requirements.txt
├── scripts
│   ├── generate_memory_seed.py
│   └── migrate_org_to_db.py
├── start.sh
└── supabase
    ├── .temp
    │   ├── cli-latest
    │   ├── gotrue-version
    │   ├── pooler-url
    │   ├── postgres-version
    │   ├── project-ref
    │   ├── rest-version
    │   ├── storage-migration
    │   └── storage-version
    ├── migrations
    │   ├── 20251212201000_organization_schema_v2.sql
    │   ├── 20251212202000_seed_axcouncil_company.sql
    │   ├── 20251212203000_seed_axcouncil_full.sql
    │   ├── 20251212235000_role_playbooks_junction.sql
    │   ├── 20251212240000_migrate_role_prompts.sql
    │   ├── 20251212250000_add_context_md_columns.sql
    │   ├── 20251212260000_add_activity_logs.sql
    │   ├── 20251213000000_fix_duplicate_roles.sql
    │   ├── 20251213000001_fix_duplicates_v2.sql
    │   ├── 20251213100000_playbook_tags_and_multi_dept.sql
    │   ├── 20251213120000_knowledge_entries_consolidation.sql
    │   ├── 20251213140000_add_council_type.sql
    │   ├── 20251216000000_performance_indexes.sql
    │   ├── 20251216140000_org_docs_indexes.sql
    │   ├── 20251216180000_projects_enhancement.sql
    │   └── 20251216_add_department_to_projects.sql
    └── verify_and_fix_roles.sql

```

## 2. Critical File Contents

### File: README.md
```md
# AxCouncil - AI Council Platform

A multi-model AI council platform that enables intelligent conversations with context-aware responses from multiple AI models working together.

## Features

### Core Functionality
- **Multi-Model Council**: Leverages 5 AI models (Claude Opus 4.5, GPT-5.1, Gemini 3 Pro, Grok 4, DeepSeek) for comprehensive responses
- **3-Stage Pipeline**:
  1. **Stage 1**: Individual responses from 5 AI models in parallel
  2. **Stage 2**: Anonymized peer review and ranking
  3. **Stage 3**: Chairman synthesis of final answer
- **Company Context**: Associate conversations with companies, projects, and departments
- **Command Center**: Decisions, playbooks, activity tracking, and team management

### My Company Feature
- **Company Management**: Create and manage company profiles with context
- **Project Management**: Organize work by projects within companies
- **Department Councils**: Configure AI councils for different departments (Marketing, Sales, Legal, etc.)
- **Role-Based Personas**: Assign specific AI personas to department roles
- **Playbooks**: SOPs, frameworks, and policies with auto-injection into council context
- **Decisions**: Save and archive council decisions with department tagging

### Data Architecture (Supabase)

**All context and configuration is stored in Supabase PostgreSQL database.** The `councils/` folder contains legacy templates and is NOT used at runtime.

| Table | Purpose | Key Fields |
|-------|---------|------------|
| `companies` | Company profiles | `name`, `slug`, `context_md` |
| `departments` | Department configs | `name`, `slug`, `context_md`, `company_id` |
| `roles` | AI role personas | `name`, `slug`, `system_prompt`, `department_id` |
| `projects` | Projects within companies | `name`, `context_md`, `company_id` |
| `org_documents` | Playbooks (SOPs, policies) | `title`, `doc_type`, `auto_inject` |
| `knowledge_entries` | Saved decisions | `title`, `summary`, `scope`, `auto_inject` |
| `conversations` | Chat history | `title`, `company_id`, `department_id` |

### Context Injection Order

When you ask the council a question, context is injected in this order:

1. **Company Context** (`companies.context_md`) - Business overview, goals, constraints
2. **Role System Prompt** (`roles.system_prompt`) - AI persona instructions
3. **Department Context** (`departments.context_md`) - Department-specific knowledge
4. **Project Context** (`projects.context_md`) - If a project is selected
5. **Decisions** - Auto-injected prior decisions marked `auto_inject=true`
6. **Playbooks** - SOPs and policies marked `auto_inject=true`

### UI/UX
- **Modern Design System**: Radix UI components with consistent styling
- **Responsive Layout**: Sidebar navigation with collapsible conversation groups
- **Markdown Rendering**: Full markdown support with syntax highlighting
- **Real-time Updates**: Live streaming responses via SSE

## Tech Stack

### Frontend
- **React 19** with Vite
- **Radix UI** for accessible components (Select, Dialog, etc.)
- **Tailwind CSS v4** for styling
- **React Markdown** for content rendering

### Backend
- **FastAPI** (Python) on port 8080
- **OpenRouter API** for multi-model access
- **Supabase** for PostgreSQL database and authentication

### Database
- **Supabase PostgreSQL** with Row Level Security (RLS)
- Multi-tenant data isolation via `company_id`
- Service client for admin operations that bypass RLS

## Getting Started

### Prerequisites
- Node.js 18+
- Python 3.10+
- OpenRouter API key
- Supabase project (URL and keys)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/AI-council.git
   cd AI-council
   ```

2. **Backend Setup**
   ```bash
   # Create virtual environment
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate

   # Install dependencies
   pip install -r requirements.txt
   ```

3. **Environment Variables**

   Create a `.env` file in the root directory:
   ```env
   # OpenRouter
   OPENROUTER_API_KEY=your_openrouter_api_key

   # Supabase
   SUPABASE_URL=https://your-project.supabase.co
   SUPABASE_ANON_KEY=your_anon_key
   SUPABASE_SERVICE_KEY=your_service_key

   # Optional: Stripe for billing
   STRIPE_SECRET_KEY=your_stripe_key
   STRIPE_WEBHOOK_SECRET=your_webhook_secret
   ```

4. **Database Setup**

   Run the Supabase migrations in order:
   ```bash
   # Apply migrations via Supabase CLI or dashboard
   cd supabase/migrations
   # Apply each .sql file in chronological order
   ```

5. **Frontend Setup**
   ```bash
   cd frontend
   npm install
   ```

### Running the Application

1. **Start the Backend**
   ```bash
   python -m uvicorn backend.main:app --reload --host 0.0.0.0 --port 8080
   ```

2. **Start the Frontend**
   ```bash
   cd frontend
   npm run dev
   ```

3. **Access the Application**
   - Frontend: http://localhost:5173
   - API Docs: http://localhost:8080/docs

## Project Structure

```
AI-council/
├── backend/
│   ├── main.py              # FastAPI application entry
│   ├── openrouter.py        # OpenRouter API integration
│   ├── database.py          # Supabase client configuration
│   ├── context_loader.py    # Loads context from Supabase tables
│   ├── knowledge.py         # Knowledge base operations
│   ├── storage.py           # Project/document storage
│   └── routers/
│       ├── company.py       # Company/project/department APIs
│       ├── auth.py          # Authentication endpoints
│       └── ...
├── frontend/
│   ├── src/
│   │   ├── components/
│   │   │   ├── ChatInterface.jsx
│   │   │   ├── MyCompany.jsx
│   │   │   ├── Sidebar.jsx
│   │   │   └── ui/          # Reusable UI components
│   │   ├── lib/             # Utilities and design system
│   │   └── api.js           # API client
│   └── package.json
├── supabase/
│   └── migrations/          # Database schema migrations
├── councils/                # LEGACY - not used at runtime
│   ├── departments/         # Template department configs
│   ├── organisations/       # Template org context (deprecated)
│   ├── outputs/             # Output format templates
│   └── styles/              # Writing style templates
└── knowledge-base/          # Exported conversations (local)
```

## Managing Company Context

### Adding/Editing Company Context

All context is managed through the **My Company** interface in the app or directly in Supabase:

1. **Company Context**: Edit `companies.context_md` in Supabase
2. **Department Context**: Edit `departments.context_md` in Supabase
3. **Role Prompts**: Edit `roles.system_prompt` in Supabase
4. **Playbooks**: Create `org_documents` with `auto_inject=true`

**Do NOT edit markdown files in the `councils/` folder** - these are legacy templates and are not read by the application.

### Example: Updating CTO Role Prompt

```sql
UPDATE roles
SET system_prompt = 'Your new CTO instructions here...'
WHERE slug = 'cto';
```

Or use the My Company > Team interface to edit roles.

## Design System

The application follows a consistent design system documented in `frontend/src/lib/DESIGN_SYSTEM.md`:

- **Colors**: Orange/amber primary, gray neutrals, semantic colors
- **Border Radius**: 12px for dropdowns/cards, 8px for items, 16px for pills
- **Shadows**: Consistent elevation system
- **Typography**: Inter/system fonts with defined scale

## API Endpoints

### Conversations
- `GET /conversations` - List conversations
- `POST /conversations` - Create new conversation
- `POST /conversations/{id}/message` - Send message (SSE streaming)

### Companies
- `GET /companies` - List companies
- `POST /companies` - Create company
- `GET /companies/{id}/projects` - List company projects
- `POST /companies/{id}/projects` - Create project

### Departments
- `GET /departments` - List departments
- `GET /departments/{id}/roles` - List department roles

### Decisions
- `GET /knowledge` - List saved decisions
- `POST /knowledge` - Save decision from council
- `PUT /knowledge/{id}/archive` - Archive a decision

## Development & AI Tools

This project is optimized for AI-assisted development.

- **AI Agent Instructions**: See [.github/copilot-instructions.md](.github/copilot-instructions.md) for architectural context and guidelines.
- **Claude Memory**: If using Claude Code CLI, see [docs/CLAUDE_MEMORY.md](docs/CLAUDE_MEMORY.md) to set up persistent project memory.

## License

MIT License - see LICENSE file for details.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

Built with AI assistance using Claude Code.

```

### File: pyproject.toml
```toml
[project]
name = "llm-council"
version = "0.1.0"
description = "Your LLM Council"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.32.0",
    "python-dotenv>=1.0.0",
    "httpx>=0.27.0",
    "pydantic>=2.9.0",
    "supabase>=2.0.0",
    "gunicorn>=21.0.0",
]

```

### File: backend/main.py
```py
"""FastAPI backend for LLM Council."""

from fastapi import FastAPI, HTTPException, Depends, File, UploadFile, Form, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, Response
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from fastapi import Request
import uuid
import json
import asyncio

from . import storage
from .council import run_full_council, generate_conversation_title, stage1_collect_responses, stage1_stream_responses, stage2_collect_rankings, stage2_stream_rankings, stage3_synthesize_final, stage3_stream_synthesis, calculate_aggregate_rankings, chat_stream_response
from .context_loader import list_available_businesses, load_business_context
from .auth import get_current_user
from . import leaderboard
from . import triage
from . import curator
from . import org_sync
from . import config
from . import billing
from . import attachments
from . import image_analyzer
from . import knowledge
from .routers import company as company_router

app = FastAPI(title="LLM Council API")

# CORS origins list
CORS_ORIGINS = [
    "http://localhost:5173",
    "http://localhost:5174",
    "http://localhost:5175",
    "http://localhost:5176",
    "http://localhost:5177",
    "http://localhost:5178",
    "http://localhost:5179",
    "http://localhost:5180",
    "http://localhost:5181",
    "http://localhost:5182",
    "http://localhost:3000",
    "https://ai-council-three.vercel.app",
]

# Enable CORS - MUST be added before any routes
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins for local development
    allow_credentials=False,  # Must be False when using allow_origins=["*"]
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["Content-Disposition"],  # Allow frontend to read filename header
)

# Exception handler to ensure CORS headers on error responses
@app.exception_handler(HTTPException)
async def cors_exception_handler(request: Request, exc: HTTPException):
    from fastapi.responses import JSONResponse
    origin = request.headers.get("origin", "")
    headers = {}
    if origin in CORS_ORIGINS or origin.endswith(".vercel.app"):
        headers = {
            "Access-Control-Allow-Origin": origin,
            "Access-Control-Allow-Credentials": "true",
        }
    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail},
        headers=headers
    )

# Include routers
app.include_router(company_router.router)

# Health check endpoint
@app.get("/health")
async def health_check():
    """Health check endpoint to verify deployment."""
    return {"status": "healthy", "version": "2025-12-09-v15-profile-debug"}


class CreateConversationRequest(BaseModel):
    """Request to create a new conversation."""
    pass


class SendMessageRequest(BaseModel):
    """Request to send a message in a conversation."""
    content: str
    business_id: Optional[str] = None
    department: Optional[str] = "standard"
    role: Optional[str] = None  # Role ID for persona injection (e.g., 'cto', 'head-of-ai-people-culture')
    project_id: Optional[str] = None  # Project ID for project-specific context
    attachment_ids: Optional[List[str]] = None  # Optional list of attachment IDs (images to analyze)


class ChatRequest(BaseModel):
    """Request to send a chat message (Chairman only, no full council)."""
    content: str
    business_id: Optional[str] = None
    department_id: Optional[str] = None
    project_id: Optional[str] = None  # Project ID for project-specific context


class CreateDepartmentRequest(BaseModel):
    """Request to create a new department for a business."""
    id: str
    name: str


class CreateKnowledgeRequest(BaseModel):
    """Request to create a knowledge entry with structured decision fields."""
    company_id: str
    title: str
    summary: str  # Kept for backwards compatibility
    category: str  # technical_decision, ux_pattern, feature, policy, process, role, framework, sop
    department_id: Optional[str] = None
    role_id: Optional[str] = None
    project_id: Optional[str] = None
    source_conversation_id: Optional[str] = None
    source_message_id: Optional[str] = None   # Specific message ID for precise linking
    # Structured decision fields
    problem_statement: Optional[str] = None  # What problem/question led to this
    decision_text: Optional[str] = None       # The actual decision made
    reasoning: Optional[str] = None           # Why this decision was made
    status: str = "active"                    # active, superseded, archived
    # Framework/SOP support
    body_md: Optional[str] = None             # Long-form markdown content for SOPs/Frameworks
    version: str = "v1"                       # Version tracking (v1, v2, etc.)
    # Knowledge consolidation fields (new)
    auto_inject: bool = False                 # Auto-inject into future council context
    scope: str = "department"                 # Visibility: company, department, project
    tags: Optional[List[str]] = None          # Tags for categorization


class UpdateKnowledgeRequest(BaseModel):
    """Request to update a knowledge entry."""
    title: Optional[str] = None
    summary: Optional[str] = None
    category: Optional[str] = None
    department_id: Optional[str] = None
    project_id: Optional[str] = None
    problem_statement: Optional[str] = None
    decision_text: Optional[str] = None
    reasoning: Optional[str] = None
    status: Optional[str] = None  # active, superseded, archived
    body_md: Optional[str] = None
    version: Optional[str] = None
    # Knowledge consolidation fields (new)
    auto_inject: Optional[bool] = None
    scope: Optional[str] = None  # company, department, project
    tags: Optional[List[str]] = None


class ConversationMetadata(BaseModel):
    """Conversation metadata for list view."""
    id: str
    created_at: str
    last_updated: str
    title: str
    message_count: int
    archived: bool = False
    department: str = "standard"


class Conversation(BaseModel):
    """Full conversation with all messages."""
    id: str
    created_at: str
    title: str
    messages: List[Dict[str, Any]]


@app.get("/")
async def root():
    """Health check endpoint."""
    return {"status": "ok", "service": "LLM Council API"}


@app.get("/api/businesses")
async def get_businesses():
    """List all available business contexts."""
    return list_available_businesses()


@app.post("/api/businesses/{business_id}/departments")
async def create_department(business_id: str, request: CreateDepartmentRequest):
    """Create a new department for a business.

    This scaffolds the department folder structure and creates an initial context file.
    """
    from .context_loader import create_department_for_business

    try:
        result = create_department_for_business(business_id, request.id, request.name)
        return result
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create department: {str(e)}")


@app.get("/api/conversations")
async def list_conversations(
    user: dict = Depends(get_current_user),
    limit: int = 20,
    offset: int = 0,
    search: Optional[str] = None,
    include_archived: bool = False,
    sort_by: str = "date"
):
    """
    List conversations for the authenticated user (metadata only).

    Args:
        sort_by: "date" (most recent first, default) or "activity" (most messages first)

    Returns { conversations: [...], has_more: bool } for pagination.
    """
    import time
    start = time.time()
    result = storage.list_conversations(
        user["id"],
        access_token=user.get("access_token"),
        limit=limit,
        offset=offset,
        search=search,
        include_archived=include_archived,
        sort_by=sort_by
    )
    elapsed = time.time() - start
    print(f"[PERF] list_conversations took {elapsed:.2f}s for {len(result['conversations'])} conversations (limit={limit}, offset={offset}, sort_by={sort_by})", flush=True)
    return result


@app.post("/api/conversations", response_model=Conversation)
async def create_conversation(request: CreateConversationRequest, user: dict = Depends(get_current_user)):
    """Create a new conversation for the authenticated user."""
    conversation_id = str(uuid.uuid4())
    conversation = storage.create_conversation(conversation_id, user["id"], access_token=user.get("access_token"))
    return conversation


@app.get("/api/conversations/{conversation_id}", response_model=Conversation)
async def get_conversation(conversation_id: str, user: dict = Depends(get_current_user)):
    """Get a specific conversation with all its messages (must be owner)."""
    import time
    start = time.time()
    conversation = storage.get_conversation(conversation_id, access_token=user.get("access_token"))
    elapsed = time.time() - start
    print(f"[PERF] get_conversation took {elapsed:.2f}s", flush=True)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")
    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")
    return conversation


@app.post("/api/conversations/{conversation_id}/message")
async def send_message(conversation_id: str, request: SendMessageRequest, user: dict = Depends(get_current_user)):
    """
    Send a message and run the 3-stage council process.
    Returns the complete response with all stages.
    """
    access_token = user.get("access_token")

    # Check if conversation exists
    conversation = storage.get_conversation(conversation_id, access_token=access_token)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    # Check billing limits before running council
    can_query_result = billing.check_can_query(user["id"], access_token=access_token)
    if not can_query_result["can_query"]:
        raise HTTPException(
            status_code=402,
            detail={
                "error": can_query_result["reason"],
                "action": "upgrade_required",
                "remaining": can_query_result["remaining"]
            }
        )

    # Check if this is the first message
    is_first_message = len(conversation["messages"]) == 0

    # Add user message with user_id
    storage.add_user_message(conversation_id, request.content, user["id"], access_token=access_token)

    # If this is the first message, generate a title
    if is_first_message:
        title = await generate_conversation_title(request.content)
        storage.update_conversation_title(conversation_id, title, access_token=access_token)

    # Run the 3-stage council process
    stage1_results, stage2_results, stage3_result, metadata = await run_full_council(
        request.content,
        business_id=request.business_id
    )

    # Add assistant message with all stages and metadata
    storage.add_assistant_message(
        conversation_id,
        stage1_results,
        stage2_results,
        stage3_result,
        user["id"],
        label_to_model=metadata.get('label_to_model'),
        aggregate_rankings=metadata.get('aggregate_rankings'),
        access_token=access_token
    )

    # Increment query usage after successful council run
    billing.increment_query_usage(user["id"], access_token=access_token)

    # Return the complete response with metadata
    return {
        "stage1": stage1_results,
        "stage2": stage2_results,
        "stage3": stage3_result,
        "metadata": metadata
    }


@app.post("/api/conversations/{conversation_id}/message/stream")
async def send_message_stream(conversation_id: str, request: SendMessageRequest, user: dict = Depends(get_current_user)):
    """
    Send a message and stream the 3-stage council process.
    Returns Server-Sent Events as each stage completes.
    """
    access_token = user.get("access_token")

    # Check if conversation exists
    conversation = storage.get_conversation(conversation_id, access_token=access_token)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    # Check billing limits before running council
    can_query_result = billing.check_can_query(user["id"], access_token=access_token)
    if not can_query_result["can_query"]:
        raise HTTPException(
            status_code=402,
            detail={
                "error": can_query_result["reason"],
                "action": "upgrade_required",
                "remaining": can_query_result["remaining"]
            }
        )

    # Check if this is the first message
    is_first_message = len(conversation["messages"]) == 0

    # Capture user_id and access_token for use in generator
    user_id = user["id"]

    # NOTE: conversation_history is intentionally NOT built or passed to Stage 1.
    # Previous chairman synthesis responses contained "Chairman's Synthesis" language
    # that caused Stage 1 models to mimic the synthesis format instead of providing
    # independent responses. Each council query operates in isolation.

    async def event_generator():
        try:
            print(f"[STREAM] Starting event_generator for conversation {conversation_id}", flush=True)

            # Add user message with user_id
            storage.add_user_message(conversation_id, request.content, user_id, access_token=access_token)
            print(f"[STREAM] User message saved", flush=True)

            # Process image attachments if provided
            enhanced_query = request.content
            if request.attachment_ids:
                print(f"[STREAM] Processing {len(request.attachment_ids)} image attachments", flush=True)
                yield f"data: {json.dumps({'type': 'image_analysis_start', 'count': len(request.attachment_ids)})}\n\n"

                # Download all images
                images = []
                for attachment_id in request.attachment_ids:
                    image_data = await attachments.download_attachment(
                        user_id=user_id,
                        access_token=access_token,
                        attachment_id=attachment_id,
                    )
                    if image_data:
                        images.append(image_data)
                        print(f"[STREAM] Downloaded image: {image_data['name']}", flush=True)

                # Analyze images with vision model
                if images:
                    print(f"[STREAM] Analyzing {len(images)} images with vision model", flush=True)
                    image_analysis = await image_analyzer.analyze_images(images, request.content)
                    enhanced_query = image_analyzer.format_query_with_images(request.content, image_analysis)
                    print(f"[STREAM] Image analysis complete, query enhanced", flush=True)

                    # Send the image analysis to frontend so user can see what the council receives
                    yield f"data: {json.dumps({'type': 'image_analysis_complete', 'analyzed': len(images), 'analysis': image_analysis})}\n\n"
                else:
                    yield f"data: {json.dumps({'type': 'image_analysis_complete', 'analyzed': 0})}\n\n"

            # Start title generation in parallel (don't await yet)
            title_task = None
            if is_first_message:
                title_task = asyncio.create_task(generate_conversation_title(request.content))

            # Resolve company UUID for knowledge base lookup
            company_uuid = None
            if request.business_id:
                try:
                    company_uuid = storage.resolve_company_id(request.business_id, access_token)
                    print(f"[STREAM] Resolved company_uuid: {company_uuid}", flush=True)
                except Exception as e:
                    print(f"[STREAM] Could not resolve company_uuid: {e}", flush=True)

            # Stage 1: Collect responses with streaming
            print(f"[STREAM] Emitting stage1_start", flush=True)
            yield f"data: {json.dumps({'type': 'stage1_start'})}\n\n"
            stage1_results = []
            print(f"[STREAM] Starting stage1_stream_responses", flush=True)
            # NOTE: Do NOT pass conversation_history to Stage 1!
            # Previous chairman synthesis responses contain "Chairman's Synthesis" language
            # that causes Stage 1 models to mimic the synthesis format instead of providing
            # independent responses. Each council query should be a clean slate.
            async for event in stage1_stream_responses(
                enhanced_query,  # Use enhanced query with image analysis
                business_id=request.business_id,
                department_id=request.department,
                role_id=request.role,
                conversation_history=None,  # Intentionally None - keep Stage 1 isolated
                project_id=request.project_id,
                access_token=access_token,
                company_uuid=company_uuid
            ):
                if event['type'] == 'stage1_token':
                    # Stream individual tokens
                    yield f"data: {json.dumps(event)}\n\n"
                elif event['type'] == 'stage1_model_complete':
                    # A single model finished
                    yield f"data: {json.dumps(event)}\n\n"
                elif event['type'] == 'stage1_model_error':
                    # A model had an error
                    yield f"data: {json.dumps(event)}\n\n"
                elif event['type'] == 'stage1_all_complete':
                    # All models done - capture results
                    stage1_results = event['data']
                    yield f"data: {json.dumps({'type': 'stage1_complete', 'data': stage1_results})}\n\n"

            # Stage 2: Collect rankings with streaming
            yield f"data: {json.dumps({'type': 'stage2_start'})}\n\n"
            stage2_results = []
            label_to_model = {}
            aggregate_rankings = []
            async for event in stage2_stream_rankings(enhanced_query, stage1_results, business_id=request.business_id):
                if event['type'] == 'stage2_token':
                    yield f"data: {json.dumps(event)}\n\n"
                elif event['type'] == 'stage2_model_complete':
                    yield f"data: {json.dumps(event)}\n\n"
                elif event['type'] == 'stage2_model_error':
                    yield f"data: {json.dumps(event)}\n\n"
                elif event['type'] == 'stage2_all_complete':
                    stage2_results = event['data']
                    label_to_model = event['label_to_model']
                    aggregate_rankings = event['aggregate_rankings']
                    yield f"data: {json.dumps({'type': 'stage2_complete', 'data': stage2_results, 'metadata': {'label_to_model': label_to_model, 'aggregate_rankings': aggregate_rankings}})}\n\n"

            # Stage 3: Synthesize final answer with streaming
            yield f"data: {json.dumps({'type': 'stage3_start'})}\n\n"
            stage3_result = {}
            async for event in stage3_stream_synthesis(
                enhanced_query,  # Use enhanced query with image analysis
                stage1_results,
                stage2_results,
                business_id=request.business_id,
                project_id=request.project_id,
                access_token=access_token,
                company_uuid=company_uuid
            ):
                if event['type'] == 'stage3_token':
                    yield f"data: {json.dumps(event)}\n\n"
                elif event['type'] == 'stage3_error':
                    yield f"data: {json.dumps(event)}\n\n"
                elif event['type'] == 'stage3_complete':
                    stage3_result = event['data']
                    yield f"data: {json.dumps({'type': 'stage3_complete', 'data': stage3_result})}\n\n"

            # Wait for title generation if it was started
            if title_task:
                title = await title_task
                storage.update_conversation_title(conversation_id, title, access_token=access_token)
                yield f"data: {json.dumps({'type': 'title_complete', 'data': {'title': title}})}\n\n"

            # Update department on first message
            if is_first_message and request.department:
                storage.update_conversation_department(conversation_id, request.department, access_token=access_token)

            # Save complete assistant message with metadata
            storage.add_assistant_message(
                conversation_id,
                stage1_results,
                stage2_results,
                stage3_result,
                user_id,
                label_to_model=label_to_model,
                aggregate_rankings=aggregate_rankings,
                access_token=access_token
            )

            # Increment query usage after successful council run
            billing.increment_query_usage(user_id, access_token=access_token)

            # Record rankings to leaderboard
            if aggregate_rankings:
                leaderboard.record_session_rankings(
                    conversation_id=conversation_id,
                    department=request.department or "standard",
                    business_id=request.business_id,
                    aggregate_rankings=aggregate_rankings
                )

            # Send completion event
            yield f"data: {json.dumps({'type': 'complete'})}\n\n"

        except Exception as e:
            # Send error event with full traceback
            import traceback
            error_details = traceback.format_exc()
            print(f"[STREAM ERROR] Exception in event_generator: {e}\n{error_details}", flush=True)
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # Disable nginx/proxy buffering
            "Transfer-Encoding": "chunked",  # Force chunked encoding
        }
    )


@app.post("/api/conversations/{conversation_id}/chat/stream")
async def chat_with_chairman(conversation_id: str, request: ChatRequest, user: dict = Depends(get_current_user)):
    """
    Send a follow-up chat message and stream a response from the Chairman only.
    Used for iterating on council advice without running full deliberation.
    """
    access_token = user.get("access_token")

    # Check if conversation exists
    conversation = storage.get_conversation(conversation_id, access_token=access_token)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    # Check billing limits (chat mode requires active subscription but doesn't count toward limit)
    can_query_result = billing.check_can_query(user["id"], access_token=access_token)
    if can_query_result["remaining"] == 0 and can_query_result["remaining"] != -1:
        # Only block if they have 0 remaining AND it's not unlimited (-1)
        raise HTTPException(
            status_code=402,
            detail={
                "error": "No remaining queries. Chat mode requires at least 1 remaining query.",
                "action": "upgrade_required",
                "remaining": 0
            }
        )

    # Capture user_id and access_token for use in generator
    user_id = user["id"]

    async def event_generator():
        try:
            # Build conversation history from existing messages
            history = []

            for msg in conversation.get("messages", []):
                if msg.get("role") == "user":
                    history.append({
                        "role": "user",
                        "content": msg.get("content", "")
                    })
                elif msg.get("role") == "assistant":
                    # For assistant messages, use the Stage 3 synthesized response
                    stage3 = msg.get("stage3", {})
                    content = stage3.get("response") or stage3.get("content", "")
                    if content:
                        history.append({
                            "role": "assistant",
                            "content": content
                        })

            # Add the new user message to history
            history.append({
                "role": "user",
                "content": request.content
            })

            # Also save the user message to storage with user_id
            storage.add_user_message(conversation_id, request.content, user_id, access_token=access_token)

            yield f"data: {json.dumps({'type': 'chat_start'})}\n\n"

            # Resolve company UUID for knowledge base lookup
            company_uuid = None
            if request.business_id:
                try:
                    company_uuid = storage.resolve_company_id(request.business_id, access_token)
                except Exception:
                    pass  # Non-critical, continue without knowledge

            # Stream response from chairman
            full_content = ""
            async for event in chat_stream_response(
                history,
                business_id=request.business_id,
                department_id=request.department_id,
                project_id=request.project_id,
                access_token=access_token,
                company_uuid=company_uuid
            ):
                if event['type'] == 'chat_token':
                    full_content += event['content']
                    yield f"data: {json.dumps(event)}\n\n"
                elif event['type'] == 'chat_error':
                    yield f"data: {json.dumps(event)}\n\n"
                elif event['type'] == 'chat_complete':
                    yield f"data: {json.dumps(event)}\n\n"

            # Save the chat response as a simplified assistant message
            # Use empty stage1/stage2 since this is chat-only
            storage.add_assistant_message(
                conversation_id,
                stage1=[],  # No stage 1 for chat mode
                stage2=[],  # No stage 2 for chat mode
                stage3={"model": "chat", "response": full_content},
                user_id=user_id,
                access_token=access_token
            )

            yield f"data: {json.dumps({'type': 'complete'})}\n\n"

        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # Disable nginx/proxy buffering
            "Transfer-Encoding": "chunked",  # Force chunked encoding
        }
    )


# Triage endpoints
class TriageRequest(BaseModel):
    """Request for triage analysis."""
    content: str
    business_id: Optional[str] = None


class TriageContinueRequest(BaseModel):
    """Request to continue triage with additional info."""
    original_query: str
    previous_constraints: Dict[str, Any]
    user_response: str
    business_id: Optional[str] = None


@app.post("/api/triage/analyze")
async def analyze_triage(request: TriageRequest):
    """
    Analyze a user's question for the 4 required constraints.
    Returns whether ready to proceed or what questions to ask.
    """
    # Load business context if specified
    business_context = None
    if request.business_id:
        business_context = load_business_context(request.business_id)

    result = await triage.analyze_for_triage(
        request.content,
        business_context=business_context
    )

    return result


@app.post("/api/triage/continue")
async def continue_triage_conversation(request: TriageContinueRequest):
    """
    Continue triage conversation with user's additional information.
    """
    business_context = None
    if request.business_id:
        business_context = load_business_context(request.business_id)

    result = await triage.continue_triage(
        original_query=request.original_query,
        previous_constraints=request.previous_constraints,
        user_response=request.user_response,
        business_context=business_context
    )

    return result


# Rename endpoint
class RenameRequest(BaseModel):
    """Request to rename a conversation."""
    title: str


@app.patch("/api/conversations/{conversation_id}/rename")
async def rename_conversation(conversation_id: str, request: RenameRequest, user: dict = Depends(get_current_user)):
    """Rename a conversation (must be owner)."""
    access_token = user.get("access_token")
    conversation = storage.get_conversation(conversation_id, access_token=access_token)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    storage.update_conversation_title(conversation_id, request.title, access_token=access_token)
    return {"success": True, "title": request.title}


# Star/Archive/Delete endpoints
class StarRequest(BaseModel):
    """Request to star/unstar a conversation."""
    starred: bool = True


class ArchiveRequest(BaseModel):
    """Request to archive/unarchive a conversation."""
    archived: bool = True


@app.post("/api/conversations/{conversation_id}/star")
async def star_conversation(conversation_id: str, request: StarRequest, user: dict = Depends(get_current_user)):
    """Star or unstar a conversation (must be owner). Starred conversations appear at top of list."""
    access_token = user.get("access_token")
    conversation = storage.get_conversation(conversation_id, access_token=access_token)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    storage.star_conversation(conversation_id, request.starred, access_token=access_token)
    return {"success": True, "starred": request.starred}


@app.post("/api/conversations/{conversation_id}/archive")
async def archive_conversation(conversation_id: str, request: ArchiveRequest, user: dict = Depends(get_current_user)):
    """Archive or unarchive a conversation (must be owner)."""
    access_token = user.get("access_token")
    conversation = storage.get_conversation(conversation_id, access_token=access_token)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    storage.archive_conversation(conversation_id, request.archived, access_token=access_token)
    return {"success": True, "archived": request.archived}


@app.delete("/api/conversations/{conversation_id}")
async def delete_conversation(conversation_id: str, user: dict = Depends(get_current_user)):
    """Permanently delete a conversation (must be owner)."""
    access_token = user.get("access_token")
    conversation = storage.get_conversation(conversation_id, access_token=access_token)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    success = storage.delete_conversation(conversation_id, access_token=access_token)
    if not success:
        raise HTTPException(status_code=404, detail="Conversation not found")
    return {"success": True}


class BulkDeleteRequest(BaseModel):
    conversation_ids: List[str]


@app.post("/api/conversations/bulk-delete")
async def bulk_delete_conversations(request: BulkDeleteRequest, user: dict = Depends(get_current_user)):
    """Permanently delete multiple conversations (must be owner of all)."""
    access_token = user.get("access_token")
    deleted = []
    failed = []

    for conv_id in request.conversation_ids:
        try:
            conversation = storage.get_conversation(conv_id, access_token=access_token)
            if conversation is None:
                failed.append({"id": conv_id, "reason": "not found"})
                continue

            # Verify ownership
            if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
                failed.append({"id": conv_id, "reason": "access denied"})
                continue

            success = storage.delete_conversation(conv_id, access_token=access_token)
            if success:
                deleted.append(conv_id)
            else:
                failed.append({"id": conv_id, "reason": "delete failed"})
        except Exception as e:
            failed.append({"id": conv_id, "reason": str(e)})

    return {"deleted": deleted, "failed": failed, "deleted_count": len(deleted)}


# Leaderboard endpoints
@app.get("/api/leaderboard")
async def get_leaderboard_summary():
    """Get full leaderboard summary with overall and per-department rankings."""
    return leaderboard.get_leaderboard_summary()


@app.get("/api/leaderboard/overall")
async def get_overall_leaderboard():
    """Get overall model leaderboard across all sessions."""
    return leaderboard.get_overall_leaderboard()


@app.get("/api/leaderboard/department/{department}")
async def get_department_leaderboard(department: str):
    """Get leaderboard for a specific department."""
    return leaderboard.get_department_leaderboard(department)


# Export endpoint
@app.get("/api/conversations/{conversation_id}/export")
async def export_conversation_markdown(conversation_id: str, user: dict = Depends(get_current_user)):
    """
    Export a conversation as a formatted Markdown file (must be owner).
    Returns the markdown content with proper headers and formatting.
    """
    access_token = user.get("access_token")
    conversation = storage.get_conversation(conversation_id, access_token=access_token)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    # Build the markdown content
    md_lines = []

    # Header
    md_lines.append(f"# {conversation.get('title', 'AI Council Conversation')}")
    md_lines.append("")
    md_lines.append(f"**Date:** {conversation.get('created_at', 'Unknown')[:10]}")
    md_lines.append("")
    md_lines.append("---")
    md_lines.append("")

    # Process each message pair
    for msg in conversation.get("messages", []):
        if msg.get("role") == "user":
            md_lines.append("## Question")
            md_lines.append("")
            md_lines.append(msg.get("content", ""))
            md_lines.append("")

        elif msg.get("role") == "assistant":
            # Stage 3 - Final Answer (most important for knowledge base)
            stage3 = msg.get("stage3", {})
            if stage3:
                md_lines.append("## AI Council Answer")
                md_lines.append("")
                # Support both "response" and "content" field names
                md_lines.append(stage3.get("response") or stage3.get("content", ""))
                md_lines.append("")

            # Stage 1 - Individual Responses (collapsible for reference)
            stage1 = msg.get("stage1", [])
            if stage1:
                md_lines.append("### Individual Model Responses")
                md_lines.append("")
                md_lines.append("<details>")
                md_lines.append("<summary>Click to expand individual responses</summary>")
                md_lines.append("")
                for resp in stage1:
                    model_name = resp.get("model", "Unknown Model")
                    # Support both "response" and "content" field names
                    resp_content = resp.get("response") or resp.get("content", "")
                    md_lines.append(f"#### {model_name}")
                    md_lines.append("")
                    md_lines.append(resp_content)
                    md_lines.append("")
                md_lines.append("</details>")
                md_lines.append("")

            # Stage 2 - Rankings (summary only)
            stage2 = msg.get("stage2", [])
            if stage2:
                md_lines.append("### Peer Rankings")
                md_lines.append("")
                md_lines.append("<details>")
                md_lines.append("<summary>Click to expand peer rankings</summary>")
                md_lines.append("")
                for ranking in stage2:
                    model_name = ranking.get("model", "Unknown Model")
                    parsed = ranking.get("parsed_ranking", [])
                    if parsed:
                        md_lines.append(f"**{model_name}:** {', '.join(parsed)}")
                    else:
                        md_lines.append(f"**{model_name}:** (no parsed ranking)")
                md_lines.append("")
                md_lines.append("</details>")
                md_lines.append("")

            md_lines.append("---")
            md_lines.append("")

    # Footer
    md_lines.append("*Generated by AI Council*")

    markdown_content = "\n".join(md_lines)

    # Create a safe filename from the title
    safe_title = "".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in conversation.get('title', 'conversation'))
    safe_title = safe_title.strip().replace(' ', '-')[:50]
    filename = f"{safe_title}.md"

    return Response(
        content=markdown_content,
        media_type="text/markdown",
        headers={
            "Content-Disposition": f'attachment; filename="{filename}"'
        }
    )


# Curator endpoints
class CurateRequest(BaseModel):
    """Request to analyze a conversation for knowledge updates."""
    business_id: str
    department_id: Optional[str] = None


class ApplySuggestionRequest(BaseModel):
    """Request to apply a curator suggestion."""
    business_id: str
    suggestion: Dict[str, Any]


@app.post("/api/conversations/{conversation_id}/curate")
async def curate_conversation(conversation_id: str, request: CurateRequest, user: dict = Depends(get_current_user)):
    """
    Analyze a conversation and suggest updates to the business context (must be owner).
    Returns a list of suggestions with section info, current text, and proposed updates.
    """
    access_token = user.get("access_token")
    conversation = storage.get_conversation(conversation_id, access_token=access_token)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    result = await curator.analyze_conversation_for_updates(
        conversation=conversation,
        business_id=request.business_id,
        department_id=request.department_id
    )

    return result


@app.post("/api/context/apply-suggestion")
async def apply_context_suggestion(request: ApplySuggestionRequest):
    """
    Apply an accepted suggestion to the business context file.
    Updates the specified section and refreshes the 'Last Updated' date.
    """
    result = curator.apply_suggestion(
        business_id=request.business_id,
        suggestion=request.suggestion
    )

    if not result.get('success'):
        raise HTTPException(status_code=400, detail=result.get('message', 'Failed to apply suggestion'))

    return result


@app.get("/api/context/{business_id}/section/{section_name}")
async def get_context_section(business_id: str, section_name: str, department: Optional[str] = None):
    """Get the full content of a specific section in the business context.

    Args:
        business_id: The business folder name
        section_name: The section heading to find
        department: Optional department ID to look in department-specific context
    """
    content = curator.get_section_content(business_id, section_name, department)
    if content is None:
        # Return empty content instead of 404 - this is expected for new sections
        return {"section": section_name, "content": "", "exists": False}
    return {"section": section_name, "content": content, "exists": True}


class SaveCuratorRunRequest(BaseModel):
    """Request to record a curator run."""
    business_id: str
    suggestions_count: int
    accepted_count: int
    rejected_count: int


@app.post("/api/conversations/{conversation_id}/curator-history")
async def save_curator_run(conversation_id: str, request: SaveCuratorRunRequest, user: dict = Depends(get_current_user)):
    """
    Record that the curator was run on this conversation (must be owner).
    Stores when it was run and the results.
    """
    access_token = user.get("access_token")
    conversation = storage.get_conversation(conversation_id, access_token=access_token)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Verify ownership
    if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    storage.save_curator_run(
        conversation_id=conversation_id,
        business_id=request.business_id,
        suggestions_count=request.suggestions_count,
        accepted_count=request.accepted_count,
        rejected_count=request.rejected_count,
        access_token=access_token
    )

    return {"success": True}


@app.get("/api/conversations/{conversation_id}/curator-history")
async def get_curator_history(conversation_id: str, user: dict = Depends(get_current_user)):
    """
    Get curator run history for a conversation (must be owner).
    Returns list of previous curator runs with timestamps and results.
    """
    try:
        access_token = user.get("access_token")
        conversation = storage.get_conversation(conversation_id, access_token=access_token)
        if conversation is None:
            raise HTTPException(status_code=404, detail="Conversation not found")

        # Verify ownership
        if conversation.get("user_id") and conversation.get("user_id") != user["id"]:
            raise HTTPException(status_code=403, detail="Access denied")

        history = storage.get_curator_history(conversation_id, access_token=access_token)
        return {"history": history or []}
    except HTTPException:
        raise
    except Exception as e:
        print(f"[CURATOR ERROR] get_curator_history failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/context/{business_id}/last-updated")
async def get_context_last_updated(business_id: str):
    """
    Get the last updated date from a business context file.
    Used for smart curator history comparison.
    """
    content = curator.get_section_content(business_id, "")
    if content is None:
        # Try loading the full context
        context_file = curator.CONTEXTS_DIR / business_id / "context.md"
        if not context_file.exists():
            raise HTTPException(status_code=404, detail="Business context not found")
        content = context_file.read_text(encoding='utf-8')

    last_updated = curator.extract_last_updated(content)
    return {"last_updated": last_updated}


# Org sync endpoints
@app.post("/api/businesses/{business_id}/sync-org")
async def sync_org_structure(business_id: str):
    """
    Manually trigger org structure sync from config.json to context.md.
    This regenerates the auto-generated Organization Structure section.
    """
    result = org_sync.sync_org_structure_to_context(business_id)

    if not result.get('success'):
        raise HTTPException(status_code=400, detail=result.get('message', 'Sync failed'))

    return result


class AddRoleRequest(BaseModel):
    """Request to add a new role to a department."""
    role_id: str
    role_name: str
    role_description: str = ""


@app.post("/api/businesses/{business_id}/departments/{department_id}/roles")
async def add_role_to_department(business_id: str, department_id: str, request: AddRoleRequest):
    """
    Add a new role to a department and sync org structure to context.md.
    """
    result = org_sync.add_role_to_department(
        business_id=business_id,
        department_id=department_id,
        role_id=request.role_id,
        role_name=request.role_name,
        role_description=request.role_description
    )

    if not result.get('success'):
        raise HTTPException(status_code=400, detail=result.get('message', 'Failed to add role'))

    return result


# ============================================
# ORGANIZATION MANAGEMENT ENDPOINTS
# ============================================

class UpdateDepartmentRequest(BaseModel):
    """Request to update department info."""
    name: Optional[str] = None
    description: Optional[str] = None


class UpdateRoleRequest(BaseModel):
    """Request to update role info."""
    name: Optional[str] = None
    description: Optional[str] = None


@app.put("/api/businesses/{business_id}/departments/{department_id}")
async def update_department(business_id: str, department_id: str, request: UpdateDepartmentRequest):
    """
    Update a department's name and/or description in config.json and sync to context.md.
    """
    result = org_sync.update_department(
        business_id=business_id,
        department_id=department_id,
        name=request.name,
        description=request.description
    )

    if not result.get('success'):
        raise HTTPException(status_code=400, detail=result.get('message', 'Failed to update department'))

    return result


@app.put("/api/businesses/{business_id}/departments/{department_id}/roles/{role_id}")
async def update_role(business_id: str, department_id: str, role_id: str, request: UpdateRoleRequest):
    """
    Update a role's name and/or description in config.json and sync to context.md.
    """
    result = org_sync.update_role(
        business_id=business_id,
        department_id=department_id,
        role_id=role_id,
        name=request.name,
        description=request.description
    )

    if not result.get('success'):
        raise HTTPException(status_code=400, detail=result.get('message', 'Failed to update role'))

    return result


@app.get("/api/businesses/{business_id}/departments/{department_id}/roles/{role_id}/context")
async def get_role_context(business_id: str, department_id: str, role_id: str):
    """
    Get the system prompt/context for a specific role.
    Returns the content of the role's .md file if it exists.
    """
    from .context_loader import load_role_context

    context = load_role_context(business_id, department_id, role_id)

    return {
        "context": context,
        "exists": context is not None,
        "path": f"councils/organisations/{business_id}/departments/{department_id}/roles/{role_id}.md"
    }


# ============================================
# PROJECTS API
# ============================================

class ProjectCreate(BaseModel):
    """Request to create a new project."""
    name: str
    description: Optional[str] = None
    context_md: Optional[str] = None
    department_id: Optional[str] = None  # Assign to a department


class ProjectUpdate(BaseModel):
    """Request to update a project."""
    name: Optional[str] = None
    description: Optional[str] = None
    context_md: Optional[str] = None
    status: Optional[str] = None  # 'active', 'completed', 'archived'
    department_id: Optional[str] = None  # Can reassign to different department


class PolishTextRequest(BaseModel):
    """Request to polish/rewrite text using AI."""
    text: str
    field_type: str  # e.g., "client_background", "goals", "constraints", "additional"


@app.get("/api/companies/{company_id}/projects")
async def list_projects(company_id: str, user: dict = Depends(get_current_user)):
    """List all active projects for a company."""
    access_token = user.get("access_token")
    try:
        projects = storage.get_projects(company_id, access_token)
        return {"projects": projects}
    except Exception as e:
        # Log error but return empty list to not break the app
        # Projects feature is new and may have DB/RLS issues
        print(f"[ERROR] Failed to list projects: {e}", flush=True)
        return {"projects": []}


@app.post("/api/companies/{company_id}/projects")
async def create_project(
    company_id: str,
    project: ProjectCreate,
    user: dict = Depends(get_current_user)
):
    """Create a new project."""
    access_token = user.get("access_token")
    user_id = user.get("id")

    try:
        result = storage.create_project(
            company_id_or_slug=company_id,
            user_id=user_id,
            name=project.name,
            description=project.description,
            context_md=project.context_md,
            department_id=project.department_id,
            access_token=access_token
        )

        if not result:
            raise HTTPException(status_code=500, detail="Failed to create project - no result returned")

        return {"project": result}
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Failed to create project: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=f"Failed to create project: {str(e)}")


@app.get("/api/projects/{project_id}")
async def get_project(project_id: str, user: dict = Depends(get_current_user)):
    """Get a single project."""
    access_token = user.get("access_token")
    project = storage.get_project(project_id, access_token)

    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    return {"project": project}


@app.patch("/api/projects/{project_id}")
async def update_project(
    project_id: str,
    update: ProjectUpdate,
    user: dict = Depends(get_current_user)
):
    """Update a project's name, description, context, or status."""
    access_token = user.get("access_token")

    try:
        result = storage.update_project(
            project_id=project_id,
            access_token=access_token,
            name=update.name,
            description=update.description,
            context_md=update.context_md,
            status=update.status,
            department_id=update.department_id
        )

        if not result:
            raise HTTPException(status_code=404, detail="Project not found")

        return {"project": result}
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        print(f"[ERROR] Failed to update project: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=f"Failed to update project: {str(e)}")


@app.post("/api/projects/{project_id}/touch")
async def touch_project(project_id: str, user: dict = Depends(get_current_user)):
    """Update a project's last_accessed_at timestamp (called when project is selected in chat)."""
    access_token = user.get("access_token")
    success = storage.touch_project_last_accessed(project_id, access_token)
    return {"success": success}


@app.get("/api/companies/{company_id}/projects/stats")
async def list_projects_with_stats(
    company_id: str,
    status: Optional[str] = None,
    include_archived: bool = False,
    user: dict = Depends(get_current_user)
):
    """
    List projects with stats for the Projects Tab in Command Centre.

    Query params:
    - status: Filter by 'active', 'completed', or 'archived'
    - include_archived: If true, include archived projects (default: false)
    """
    access_token = user.get("access_token")
    try:
        projects = storage.get_projects_with_stats(
            company_id,
            access_token,
            status_filter=status,
            include_archived=include_archived
        )
        return {"projects": projects}
    except Exception as e:
        print(f"[ERROR] Failed to list projects with stats: {e}", flush=True)
        return {"projects": []}


@app.post("/api/utils/polish-text")
async def polish_text(request: PolishTextRequest, user: dict = Depends(get_current_user)):
    """
    Use AI to polish/rewrite user-provided text for clarity and structure.
    Used to help users write better project context without knowing markdown.
    """
    from .openrouter import query_model

    # Special handling for markdown conversion - comprehensive formatting
    if request.field_type == "markdown":
        prompt = f"""You are a markdown formatting expert. Convert the following text into clean, well-structured Markdown.

RULES:
1. Preserve ALL information - don't remove or summarize anything
2. Use proper Markdown syntax:
   - # for main title, ## for sections, ### for subsections
   - | col | col | for tables (with header separator |---|---|)
   - ```language for code blocks (detect language: javascript, css, python, etc.)
   - **bold** for emphasis
   - - for bullet lists
   - 1. for numbered lists
3. If you see tabular data (columns of values), convert to proper Markdown tables
4. If you see code (CSS properties, JavaScript, functions), wrap in code blocks
5. Detect numbered sections like "1. Title" and convert to ## headers
6. Output ONLY the formatted markdown, no explanations

TEXT TO CONVERT:
{request.text}

MARKDOWN:"""

        try:
            messages = [
                {"role": "system", "content": "You are a markdown formatting expert. Convert text to clean, properly structured Markdown."},
                {"role": "user", "content": prompt}
            ]

            result = await query_model(
                model="google/gemini-3-pro-preview",  # Council model - confirmed working
                messages=messages
            )

            if result and result.get('content'):
                return {"polished": result['content'].strip()}
            else:
                raise HTTPException(status_code=500, detail="Failed to get AI response")
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"AI polish failed: {str(e)}")

    # Field-specific prompts for better context
    field_prompts = {
        "client_background": "This text describes a client or project. Rewrite it clearly, organizing information about the company, industry, size, and key people.",
        "goals": "This text describes goals and objectives. Rewrite it as clear, actionable bullet points or short paragraphs.",
        "constraints": "This text describes constraints and requirements. Rewrite it clearly, organizing budget, timeline, technical, and other constraints.",
        "additional": "This is additional context for an AI advisor. Rewrite it clearly and concisely."
    }

    field_context = field_prompts.get(request.field_type, "Rewrite this text clearly and concisely.")

    prompt = f"""You are a helpful writing assistant. The user has written some rough notes and wants you to polish them into clear, well-structured text.

{field_context}

IMPORTANT:
- Keep the same information - don't add or invent details
- Make it clear and easy to read
- Use bullet points if there are multiple items
- Keep it concise but complete
- Don't use markdown headers (##) - just plain text and bullet points
- Output ONLY the polished text, nothing else

User's rough text:
{request.text}

Polished version:"""

    try:
        # Build messages list in the format query_model expects
        messages = [
            {"role": "system", "content": "You are a helpful writing assistant that polishes rough notes into clear, well-structured text."},
            {"role": "user", "content": prompt}
        ]

        result = await query_model(
            model="google/gemini-3-pro-preview",  # Council model - confirmed working
            messages=messages
        )

        if result and result.get('content'):
            return {"polished": result['content'].strip()}
        else:
            raise HTTPException(status_code=500, detail="Failed to get AI response")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI polish failed: {str(e)}")


# Billing endpoints
class CheckoutRequest(BaseModel):
    """Request to create a checkout session."""
    tier_id: str
    success_url: str
    cancel_url: str


class BillingPortalRequest(BaseModel):
    """Request to create a billing portal session."""
    return_url: str


@app.get("/api/billing/plans")
async def get_billing_plans():
    """Get available subscription plans."""
    return billing.get_available_plans()


@app.get("/api/billing/subscription")
async def get_subscription(user: dict = Depends(get_current_user)):
    """Get current user's subscription status."""
    return billing.get_user_subscription(user["id"], access_token=user.get("access_token"))


@app.get("/api/billing/can-query")
async def check_can_query(user: dict = Depends(get_current_user)):
    """Check if user can make a council query."""
    return billing.check_can_query(user["id"], access_token=user.get("access_token"))


@app.post("/api/billing/checkout")
async def create_checkout(request: CheckoutRequest, user: dict = Depends(get_current_user)):
    """Create a Stripe Checkout session for subscription."""
    try:
        result = billing.create_checkout_session(
            user_id=user["id"],
            email=user["email"],
            tier_id=request.tier_id,
            success_url=request.success_url,
            cancel_url=request.cancel_url,
            access_token=user.get("access_token")
        )
        return result
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create checkout: {str(e)}")


@app.post("/api/billing/portal")
async def create_billing_portal(request: BillingPortalRequest, user: dict = Depends(get_current_user)):
    """Create a Stripe Billing Portal session for managing subscription."""
    try:
        result = billing.create_billing_portal_session(
            user_id=user["id"],
            email=user["email"],
            return_url=request.return_url,
            access_token=user.get("access_token")
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create portal: {str(e)}")


@app.post("/api/billing/webhook")
async def stripe_webhook(request: Request):
    """Handle Stripe webhook events."""
    payload = await request.body()
    sig_header = request.headers.get("stripe-signature", "")

    result = billing.handle_webhook_event(payload, sig_header)

    if not result.get("success"):
        raise HTTPException(status_code=400, detail=result.get("error", "Webhook failed"))

    return {"received": True}


# Profile endpoints
class ProfileUpdateRequest(BaseModel):
    """Request to update user profile."""
    display_name: Optional[str] = None
    company: Optional[str] = None
    phone: Optional[str] = None
    bio: Optional[str] = None


@app.get("/api/profile")
async def get_profile(user: dict = Depends(get_current_user)):
    """Get current user's profile."""
    try:
        print(f"[PROFILE] Getting profile for user: {user['id']}", flush=True)
        profile = storage.get_user_profile(user["id"], user.get("access_token"))
        print(f"[PROFILE] Got profile: {profile}", flush=True)
        return profile or {
            "display_name": "",
            "company": "",
            "phone": "",
            "bio": "",
        }
    except Exception as e:
        print(f"[PROFILE ERROR] get_profile failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.put("/api/profile")
async def update_profile(request: ProfileUpdateRequest, user: dict = Depends(get_current_user)):
    """Update current user's profile."""
    try:
        print(f"[PROFILE] Updating profile for user: {user['id']}", flush=True)
        profile_data = {
            "display_name": request.display_name,
            "company": request.company,
            "phone": request.phone,
            "bio": request.bio,
        }
        print(f"[PROFILE] Profile data: {profile_data}", flush=True)
        result = storage.update_user_profile(user["id"], profile_data, user.get("access_token"))
        print(f"[PROFILE] Update result: {result}", flush=True)
        if not result:
            raise HTTPException(status_code=500, detail="Failed to update profile - storage returned None")
        return {"success": True, "profile": result}
    except HTTPException:
        raise
    except Exception as e:
        print(f"[PROFILE ERROR] update_profile failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ATTACHMENTS ENDPOINTS
# ============================================

@app.post("/api/attachments/upload")
async def upload_attachment(
    file: UploadFile = File(...),
    conversation_id: Optional[str] = Form(None),
    message_index: Optional[int] = Form(None),
    user: dict = Depends(get_current_user),
):
    """
    Upload an image attachment.

    The image is stored in Supabase Storage and a record is created
    in the attachments table. Returns a signed URL for immediate display.

    Args:
        file: The image file to upload
        conversation_id: Optional conversation ID to link to
        message_index: Optional message index within the conversation

    Returns:
        Attachment metadata including signed URL
    """
    try:
        # Read file content
        file_data = await file.read()

        # Upload to storage
        result = await attachments.upload_attachment(
            user_id=user["id"],
            access_token=user.get("access_token"),
            file_data=file_data,
            file_name=file.filename or "image.png",
            file_type=file.content_type or "image/png",
            conversation_id=conversation_id,
            message_index=message_index,
        )

        return result

    except ValueError as e:
        print(f"[ATTACHMENTS ERROR] upload ValueError: {e}", flush=True)
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        print(f"[ATTACHMENTS ERROR] upload failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/attachments/{attachment_id}")
async def get_attachment(
    attachment_id: str,
    user: dict = Depends(get_current_user),
):
    """Get attachment metadata and a fresh signed URL."""
    try:
        result = await attachments.get_attachment_data(
            user_id=user["id"],
            access_token=user.get("access_token"),
            attachment_id=attachment_id,
        )

        if not result:
            raise HTTPException(status_code=404, detail="Attachment not found")

        return result

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ATTACHMENTS ERROR] get failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/attachments/{attachment_id}/url")
async def get_attachment_url(
    attachment_id: str,
    user: dict = Depends(get_current_user),
):
    """Get a fresh signed URL for an attachment."""
    try:
        url = await attachments.get_attachment_url(
            user_id=user["id"],
            access_token=user.get("access_token"),
            attachment_id=attachment_id,
        )

        if not url:
            raise HTTPException(status_code=404, detail="Attachment not found")

        return {"signed_url": url}

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ATTACHMENTS ERROR] get_url failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/attachments/{attachment_id}")
async def delete_attachment(
    attachment_id: str,
    user: dict = Depends(get_current_user),
):
    """Delete an attachment."""
    try:
        success = await attachments.delete_attachment(
            user_id=user["id"],
            access_token=user.get("access_token"),
            attachment_id=attachment_id,
        )

        if not success:
            raise HTTPException(status_code=404, detail="Attachment not found")

        return {"success": True}

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ATTACHMENTS ERROR] delete failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


# Mock mode endpoints
class MockModeRequest(BaseModel):
    """Request to toggle mock mode."""
    enabled: bool


@app.get("/api/settings/mock-mode")
async def get_mock_mode():
    """Get current mock mode status."""
    from . import openrouter
    # Return the runtime value from openrouter (the actual flag being used)
    return {
        "enabled": openrouter.MOCK_LLM,
        "scenario": config.MOCK_LLM_SCENARIO
    }


@app.post("/api/settings/mock-mode")
async def set_mock_mode(request: MockModeRequest):
    """
    Toggle mock mode on/off at runtime.
    Note: This changes the in-memory setting only.
    For persistent changes, update MOCK_LLM in .env and restart.
    """
    import importlib
    from . import openrouter

    # Update the config module
    config.MOCK_LLM = request.enabled

    # Reload the openrouter module to pick up the change
    # This ensures the mock intercepts are properly set
    if request.enabled:
        # Import mock functions if enabling
        try:
            from .mock_llm import generate_mock_response, generate_mock_response_stream
            openrouter.MOCK_LLM = True
            openrouter.generate_mock_response = generate_mock_response
            openrouter.generate_mock_response_stream = generate_mock_response_stream
            print("[MOCK] Mock mode ENABLED via API", flush=True)
        except ImportError as e:
            return {"success": False, "error": f"Failed to load mock module: {e}"}
    else:
        openrouter.MOCK_LLM = False
        print("[MOCK] Mock mode DISABLED via API", flush=True)

    return {
        "success": True,
        "enabled": openrouter.MOCK_LLM,
        "message": f"Mock mode {'enabled' if request.enabled else 'disabled'}"
    }


# Prompt caching endpoints
class CachingModeRequest(BaseModel):
    """Request to toggle prompt caching."""
    enabled: bool


@app.get("/api/settings/caching-mode")
async def get_caching_mode():
    """Get current prompt caching status."""
    from . import openrouter
    return {
        "enabled": config.ENABLE_PROMPT_CACHING,
        "supported_models": config.CACHE_SUPPORTED_MODELS
    }


@app.post("/api/settings/caching-mode")
async def set_caching_mode(request: CachingModeRequest):
    """
    Toggle prompt caching on/off at runtime.
    Note: This changes the in-memory setting only.
    For persistent changes, update ENABLE_PROMPT_CACHING in .env and restart.
    """
    from . import openrouter

    # Update the config module
    config.ENABLE_PROMPT_CACHING = request.enabled

    # Update openrouter module to use new setting
    # The convert_to_cached_messages function reads from config directly
    if request.enabled:
        print("[CACHE] Prompt caching ENABLED via API", flush=True)
    else:
        print("[CACHE] Prompt caching DISABLED via API", flush=True)

    return {
        "success": True,
        "enabled": config.ENABLE_PROMPT_CACHING,
        "message": f"Prompt caching {'enabled' if request.enabled else 'disabled'}"
    }


# ============================================
# Knowledge Base Endpoints
# ============================================

@app.post("/api/knowledge")
async def create_knowledge_entry(
    request: CreateKnowledgeRequest,
    user: dict = Depends(get_current_user)
):
    """Create a new knowledge entry."""
    try:
        access_token = user.get("access_token")

        # Resolve company_id if it's a slug (e.g., "axcouncil" -> UUID)
        company_uuid = storage.resolve_company_id(request.company_id, access_token)

        # Resolve department_id if it's a slug (e.g., "technology" -> UUID)
        department_uuid = storage.resolve_department_id(
            request.department_id,
            company_uuid,
            access_token
        )

        result = knowledge.create_knowledge_entry(
            user_id=user["id"],
            company_id=company_uuid,
            title=request.title,
            summary=request.summary,
            category=request.category,
            department_id=department_uuid,
            role_id=request.role_id,
            project_id=request.project_id,
            source_conversation_id=request.source_conversation_id,
            source_message_id=request.source_message_id,
            access_token=access_token,
            # Structured decision fields
            problem_statement=request.problem_statement,
            decision_text=request.decision_text,
            reasoning=request.reasoning,
            status=request.status,
            # Framework/SOP fields
            body_md=request.body_md,
            version=request.version,
            # Knowledge consolidation fields
            auto_inject=request.auto_inject,
            scope=request.scope,
            tags=request.tags
        )
        if result:
            # Log activity with conversation link so activity feed can navigate back
            await company_router.log_activity(
                company_id=company_uuid,
                event_type="decision",
                title=f"Saved: {request.title}",
                description=request.summary[:200] if request.summary else None,
                department_id=department_uuid,  # Use resolved UUID, not slug
                related_id=result.get("id"),
                related_type="decision",
                conversation_id=request.source_conversation_id
            )
            return result
        raise HTTPException(status_code=500, detail="Failed to create knowledge entry")
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        print(f"[KNOWLEDGE ERROR] create failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/knowledge/{company_id}")
async def get_knowledge_entries(
    company_id: str,
    department_id: Optional[str] = None,
    project_id: Optional[str] = None,
    category: Optional[str] = None,
    status: Optional[str] = Query("active"),  # Default to active entries
    search: Optional[str] = None,
    limit: int = 50,
    user: dict = Depends(get_current_user)
):
    """Get knowledge entries for a company with filtering options."""
    try:
        access_token = user.get("access_token")

        # Resolve company_id if it's a slug
        company_uuid = storage.resolve_company_id(company_id, access_token)

        entries = knowledge.get_knowledge_entries(
            company_id=company_uuid,
            department_id=department_id,
            project_id=project_id,
            category=category,
            status=status,
            search=search,
            limit=limit,
            access_token=access_token
        )
        return {"entries": entries}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        print(f"[KNOWLEDGE ERROR] get failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/conversations/{conversation_id}/knowledge-count")
async def get_knowledge_count_for_conversation(
    conversation_id: str,
    company_id: str,
    user: dict = Depends(get_current_user)
):
    """Get count of knowledge entries saved from a specific conversation."""
    try:
        access_token = user.get("access_token")
        # Resolve company_id if it's a slug
        company_uuid = storage.resolve_company_id(company_id, access_token)

        count = knowledge.get_knowledge_count_for_conversation(
            conversation_id=conversation_id,
            company_id=company_uuid
        )
        return {"count": count}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        print(f"[KNOWLEDGE ERROR] get count failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.patch("/api/knowledge/{entry_id}")
async def update_knowledge_entry(
    entry_id: str,
    request: UpdateKnowledgeRequest,
    user: dict = Depends(get_current_user)
):
    """Update a knowledge entry."""
    try:
        result = knowledge.update_knowledge_entry(
            entry_id=entry_id,
            user_id=user["id"],
            updates=request.model_dump(exclude_unset=True),
            access_token=user.get("access_token")
        )
        if result:
            return result
        raise HTTPException(status_code=404, detail="Entry not found or access denied")
    except Exception as e:
        print(f"[KNOWLEDGE ERROR] update failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/knowledge/{entry_id}")
async def delete_knowledge_entry(
    entry_id: str,
    user: dict = Depends(get_current_user)
):
    """Soft delete a knowledge entry."""
    try:
        success = knowledge.deactivate_knowledge_entry(
            entry_id=entry_id,
            user_id=user["id"],
            access_token=user.get("access_token")
        )
        if success:
            return {"success": True}
        raise HTTPException(status_code=404, detail="Entry not found")
    except Exception as e:
        print(f"[KNOWLEDGE ERROR] delete failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


class ExtractDecisionRequest(BaseModel):
    """Request to extract decision from council response."""
    user_question: str
    council_response: str  # The Stage 3 chairman synthesis


@app.post("/api/knowledge/extract")
async def extract_decision_from_response(
    request: ExtractDecisionRequest,
    user: dict = Depends(get_current_user)
):
    """
    Use AI to extract the key decision/recommendation from a council response.
    Returns structured data: title, problem_statement, decision_text, reasoning, category, department.

    IMPORTANT: Always returns clean, readable data - either from AI or fallback.
    The fallback sanitizes text to remove code/SQL that shouldn't appear in user-facing content.
    """
    from .openrouter import query_model, MOCK_LLM
    from .knowledge_fallback import extract_knowledge_fallback

    # Handle mock mode - return a reasonable mock extraction
    if MOCK_LLM:
        print("[MOCK] Returning mock knowledge extraction response", flush=True)
        return {
            "success": True,
            "extracted": {
                "title": "Persistent Context Storage Implementation",
                "problem_statement": "The team needed a reliable way to store AI context and decisions across multiple sessions.\n\n• Previous conversations were lost after each session\n• No way to reference past decisions or guidelines\n• New team members had no access to institutional knowledge",
                "decision_text": "Implement a Supabase-based context storage system:\n\n• Create a dedicated knowledge_entries table for storing decisions\n• Each entry includes title, problem statement, reasoning, and metadata\n• Integrate with existing authentication for secure access\n• Support filtering by department and category for easy retrieval",
                "reasoning": "Why Supabase was chosen:\n\n• Already handles authentication - no new systems needed\n• Provides real-time sync capabilities\n• Structured tables allow easy querying and filtering\n• Scales well as knowledge base grows",
                "category": "technical_decision",
                "department": "technology",
                "used_ai": True
            }
        }

    # Create a focused prompt for decision extraction
    # CRITICAL: Only use clean user content, truncated to prevent prompt bloat
    user_question = request.user_question[:3000] if request.user_question else ""
    council_response = request.council_response[:5000] if request.council_response else ""

    extraction_prompt = f"""Extract and REWRITE the key decision into SHORT, CLEAN business language.

QUESTION: {user_question}

RESPONSE: {council_response}

---

EXTRACT these 7 fields (keep each field SHORT and CLEAN):

1. CONTEXT_SUMMARY: A clean 1-2 sentence summary of what was asked. Write it like a professional brief.
   - NO bullet points, just flowing prose
   - Max 100 words
   - Example: "The team sought guidance on implementing persistent storage for AI council decisions, with constraints around using the existing React/FastAPI/Supabase stack and avoiding manual file editing."

2. TITLE: 5-8 words describing the DECISION (not the question)

3. PROBLEM_STATEMENT: What problem was being solved? (2-4 bullet points)
   Example: "• Users couldn't find past decisions\\n• No central knowledge repository"

4. DECISION_TEXT: What was decided? The actual recommendation. (2-4 bullet points)
   Example: "• Create a Knowledge Base page\\n• Store decisions in Supabase\\n• Add search and filters"

5. REASONING: Why this approach? (2-3 bullet points)
   Example: "• Fits existing tech stack\\n• Easy to maintain"

6. CATEGORY: ONE of: technical_decision, ux_pattern, feature, policy, process, general

7. DEPARTMENT: ONE of: technology, ux, marketing, operations, strategy, finance, hr, general

RESPOND WITH JSON ONLY:
{{
  "context_summary": "Clean 1-2 sentence summary of the question...",
  "title": "Short Decision Title",
  "problem_statement": "• Point 1\\n• Point 2",
  "decision_text": "• Decision 1\\n• Decision 2",
  "reasoning": "• Reason 1\\n• Reason 2",
  "category": "category_id",
  "department": "department_id"
}}

RULES:
- REWRITE in your own words - do NOT copy text verbatim from the response
- context_summary should be professional prose, NOT bullet points
- Other fields: 50-150 characters max, use bullet points (•)
- NO markdown headers (##), NO asterisks (*), NO code
- Focus on the ACTIONABLE decision, not meta-discussion about rankings
- CRITICAL: decision_text and reasoning MUST be DIFFERENT content
  - decision_text = WHAT to do (the action/recommendation)
  - reasoning = WHY to do it (the justification/benefits)
  - If there's no clear reasoning, leave reasoning as empty string ""
- NEVER copy the same content to multiple fields"""

    try:
        messages = [
            {"role": "system", "content": "You are a business analyst extracting key decisions from council discussions. Always respond with valid JSON. Never include code or technical syntax in your output."},
            {"role": "user", "content": extraction_prompt}
        ]

        result = await query_model(
            model="anthropic/claude-3-5-haiku-20241022",  # Fast, good at structured extraction
            messages=messages
        )

        if result and result.get('content'):
            # Parse the JSON response
            content = result['content'].strip()
            # Handle potential markdown code blocks
            if content.startswith('```'):
                content = content.split('\n', 1)[1]  # Remove first line
                if content.endswith('```'):
                    content = content[:-3]
                elif '```' in content:
                    content = content.split('```')[0]
            content = content.strip()

            import json
            try:
                extracted = json.loads(content)
                extracted["used_ai"] = True
                return {
                    "success": True,
                    "extracted": extracted
                }
            except json.JSONDecodeError as e:
                print(f"[EXTRACT] JSON parse error, using fallback: {e}", flush=True)
                # AI returned invalid JSON - use fallback
                fallback = extract_knowledge_fallback(request.user_question, request.council_response)
                return {
                    "success": True,
                    "extracted": fallback
                }
        else:
            # No response from AI - use fallback
            print("[EXTRACT] No AI response, using fallback", flush=True)
            fallback = extract_knowledge_fallback(request.user_question, request.council_response)
            return {
                "success": True,
                "extracted": fallback
            }

    except Exception as e:
        # AI failed (rate limit, network error, etc.) - use fallback
        print(f"[EXTRACT] AI failed ({type(e).__name__}: {e}), using fallback", flush=True)
        fallback = extract_knowledge_fallback(request.user_question, request.council_response)
        return {
            "success": True,
            "extracted": fallback
        }


class ExtractProjectRequest(BaseModel):
    """Request to extract project details from council response."""
    user_question: str
    council_response: str


@app.post("/api/projects/extract")
async def extract_project_from_response(
    request: ExtractProjectRequest,
    user: dict = Depends(get_current_user)
):
    """
    Use AI to extract a clear project name and description from a council response.
    Designed to be understandable by anyone - like onboarding documentation.
    A new hire should be able to read the project and understand what it's about.

    IMPORTANT: Always returns clean, readable data - either from AI or fallback.
    """
    print(f"[PROJECT EXTRACT] Called with question: {request.user_question[:100]}...", flush=True)
    from .openrouter import query_model, MOCK_LLM
    from .knowledge_fallback import extract_project_fallback

    # Handle mock mode
    if MOCK_LLM:
        print("[MOCK] Returning mock project extraction", flush=True)
        return {
            "success": True,
            "extracted": {
                "name": "Context Memory System",
                "description": "A system to help AI assistants remember important decisions and context across conversations.\n\nKey Goals:\n• Store decisions and guidelines persistently\n• Surface relevant context in future discussions\n• Help new team members access institutional knowledge\n\nThis ensures consistency across all AI-assisted conversations.",
                "used_ai": True
            }
        }

    # Truncate inputs to prevent prompt bloat
    user_question = request.user_question[:3000] if request.user_question else ""
    council_response = request.council_response[:5000] if request.council_response else ""

    # Create a prompt focused on generating clear, accessible project details
    extraction_prompt = f"""You are creating project documentation that needs to be understood by ANYONE in the company - including new hires on their first day, executives who aren't technical, and team members from completely different departments.

CONTEXT: A council of AI advisors just had a discussion. Based on this discussion, we need to create a new project. Extract a clear project name and description.

ORIGINAL QUESTION THAT STARTED THE DISCUSSION:
{user_question}

COUNCIL'S RESPONSE:
{council_response}

---

Create project details that answer these questions for someone who knows NOTHING about this:
- What is this project? (the name should be clear and professional)
- Why does this project exist? What problem is it solving?
- What is the goal or outcome?

REQUIREMENTS:
1. PROJECT NAME: 2-5 words, clear and professional. Should make sense standalone without context.
   - BAD: "Context Updates" (too vague)
   - BAD: "CTO Council Question Response" (that's not a project name)
   - GOOD: "AI Context Memory System"
   - GOOD: "Customer Onboarding Automation"

2. DESCRIPTION: Start with 1-2 sentences explaining what this is, then use bullet points for key goals.
   Format it like this:
   "A system to help [who] do [what].

   Key Goals:
   • Goal or benefit 1
   • Goal or benefit 2
   • Goal or benefit 3

   This ensures [outcome/benefit]."

Respond in this exact JSON format:
{{
  "name": "Clear Project Name",
  "description": "A clear explanation sentence.\\n\\nKey Goals:\\n• Goal 1\\n• Goal 2\\n• Goal 3\\n\\nFinal sentence about outcome."
}}

CRITICAL:
- Use bullet points (•) to make goals easy to scan
- Use \\n\\n between sections and \\n between bullets
- A non-technical person must understand it
- NEVER include code, SQL, or technical syntax"""

    try:
        messages = [
            {"role": "system", "content": "You are a technical writer creating project documentation. Your goal is clarity and accessibility - write so anyone can understand. Always respond with valid JSON. Never include code or technical syntax."},
            {"role": "user", "content": extraction_prompt}
        ]

        result = await query_model(
            model="anthropic/claude-3-5-haiku-20241022",
            messages=messages
        )

        if result and result.get('content'):
            content = result['content'].strip()
            # Handle markdown code blocks
            if content.startswith('```'):
                content = content.split('\n', 1)[1]
                if content.endswith('```'):
                    content = content[:-3]
                elif '```' in content:
                    content = content.split('```')[0]
            content = content.strip()

            import json
            try:
                extracted = json.loads(content)
                extracted["used_ai"] = True
                return {
                    "success": True,
                    "extracted": extracted
                }
            except json.JSONDecodeError as e:
                print(f"[PROJECT EXTRACT] JSON parse error, using fallback: {e}", flush=True)
                # AI returned invalid JSON - use fallback
                fallback = extract_project_fallback(request.user_question, request.council_response)
                return {
                    "success": True,
                    "extracted": fallback
                }
        else:
            # No response from AI - use fallback
            print("[PROJECT EXTRACT] No AI response, using fallback", flush=True)
            fallback = extract_project_fallback(request.user_question, request.council_response)
            return {
                "success": True,
                "extracted": fallback
            }

    except Exception as e:
        # AI failed (rate limit, network error, etc.) - use fallback
        print(f"[PROJECT EXTRACT] AI failed ({type(e).__name__}: {e}), using fallback", flush=True)
        fallback = extract_project_fallback(request.user_question, request.council_response)
        return {
            "success": True,
            "extracted": fallback
        }


@app.get("/api/projects/{project_id}/report")
async def get_project_report(
    project_id: str,
    user: dict = Depends(get_current_user)
):
    """
    Generate a professional report of all decisions made for a project.
    Returns structured data that can be rendered as HTML/PDF.
    Client-friendly - no mention of AI Council or internal tooling.
    """
    try:
        access_token = user.get("access_token")

        # Get project details
        project = storage.get_project(project_id, access_token)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")

        project_name = project.get('name', 'Untitled Project')
        company_id = project.get('company_id')

        if not company_id:
            raise HTTPException(status_code=400, detail="Project has no company association")

        report = knowledge.generate_project_report(
            project_id=project_id,
            project_name=project_name,
            company_id=company_id
        )

        return report
    except HTTPException:
        raise
    except Exception as e:
        print(f"[REPORT ERROR] generate failed: {type(e).__name__}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)

```

### File: backend/council.py
```py
"""3-stage LLM Council orchestration."""

import asyncio
from typing import List, Dict, Any, Tuple, Optional, AsyncGenerator
from .openrouter import query_models_parallel, query_model, query_model_stream
from .config import COUNCIL_MODELS, CHAIRMAN_MODEL, CHAIRMAN_MODELS
from .context_loader import get_system_prompt_with_context


async def stage1_collect_responses(
    user_query: str,
    business_id: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    Stage 1: Collect individual responses from all council models.

    Args:
        user_query: The user's question
        business_id: Optional business context to load

    Returns:
        List of dicts with 'model' and 'response' keys
    """
    # Build messages with optional business context
    messages = []

    # Add system prompt with business context if specified
    system_prompt = get_system_prompt_with_context(business_id)
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})

    messages.append({"role": "user", "content": user_query})

    # Query all models in parallel
    responses = await query_models_parallel(COUNCIL_MODELS, messages)

    # Format results
    stage1_results = []
    for model, response in responses.items():
        if response is not None:  # Only include successful responses
            stage1_results.append({
                "model": model,
                "response": response.get('content', '')
            })

    return stage1_results


async def stage1_stream_responses(
    user_query: str,
    business_id: Optional[str] = None,
    department_id: Optional[str] = None,
    role_id: Optional[str] = None,
    channel_id: Optional[str] = None,
    style_id: Optional[str] = None,
    conversation_history: Optional[List[Dict[str, str]]] = None,
    project_id: Optional[str] = None,
    access_token: Optional[str] = None,
    company_uuid: Optional[str] = None,
    department_uuid: Optional[str] = None
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    Stage 1 with streaming: Collect individual responses from all council models,
    yielding token updates as they arrive.

    Args:
        user_query: The user's question
        business_id: Optional business context to load
        department_id: Optional department persona to load
        role_id: Optional role persona to load (e.g., 'cto', 'head-of-ai-people-culture')
        channel_id: Optional channel context to load
        style_id: Optional writing style to load
        conversation_history: Optional list of previous messages [{"role": "user/assistant", "content": "..."}]
        project_id: Optional project ID to load project-specific context
        access_token: User's JWT access token for RLS authentication

    Yields:
        Dicts with 'type' (token/complete), 'model', and 'content'/'response'
    """
    # Build messages with optional contexts
    messages = []

    system_prompt = get_system_prompt_with_context(
        business_id=business_id,
        department_id=department_id,
        role_id=role_id,
        channel_id=channel_id,
        style_id=style_id,
        project_id=project_id,
        access_token=access_token,
        company_uuid=company_uuid,
        department_uuid=department_uuid
    )
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})

    # Add conversation history if provided (for follow-up council queries)
    if conversation_history:
        messages.extend(conversation_history)

    messages.append({"role": "user", "content": user_query})

    # Use a queue to collect events from all models
    queue: asyncio.Queue = asyncio.Queue()
    model_content: Dict[str, str] = {}

    async def stream_single_model(model: str):
        """Stream tokens from a single model and put events on the queue."""
        print(f"[STAGE1 TASK START] {model}: Task started", flush=True)
        content = ""
        chunk_count = 0
        try:
            async for chunk in query_model_stream(model, messages):
                chunk_count += 1
                content += chunk
                await queue.put({"type": "stage1_token", "model": model, "content": chunk})
            print(f"[STAGE1 TASK DONE] {model}: Received {chunk_count} chunks, {len(content)} chars", flush=True)
            model_content[model] = content
            await queue.put({"type": "stage1_model_complete", "model": model, "response": content})
        except Exception as e:
            print(f"[STAGE1 TASK ERROR] {model}: {type(e).__name__}: {e}", flush=True)
            await queue.put({"type": "stage1_model_error", "model": model, "error": str(e)})

    # Start all model streams with staggered delays to avoid rate limiting
    # While waiting between starts, process and yield any events from already-started models
    print(f"[STAGE1] Starting {len(COUNCIL_MODELS)} models: {COUNCIL_MODELS}", flush=True)
    tasks = []
    completed_count = 0
    total_models = len(COUNCIL_MODELS)

    for i, model in enumerate(COUNCIL_MODELS):
        print(f"[STAGE1] Creating task for {model}", flush=True)
        tasks.append(asyncio.create_task(stream_single_model(model)))

        if i < total_models - 1:
            # Wait 2s before starting next model, but yield events during the wait
            print(f"[STAGE1] Waiting 2s before starting {COUNCIL_MODELS[i+1]}...", flush=True)
            wait_end = asyncio.get_event_loop().time() + 2.0
            while asyncio.get_event_loop().time() < wait_end:
                try:
                    # Short timeout to check for events frequently
                    event = await asyncio.wait_for(queue.get(), timeout=0.05)
                    yield event
                    if event['type'] in ('stage1_model_complete', 'stage1_model_error'):
                        completed_count += 1
                except asyncio.TimeoutError:
                    pass  # No event yet, continue waiting

    print(f"[STAGE1] All {total_models} tasks created, waiting for remaining results...", flush=True)

    # Continue processing events until all models complete
    while completed_count < total_models:
        try:
            # Wait for next event with timeout to check if tasks are done
            event = await asyncio.wait_for(queue.get(), timeout=0.1)
            yield event

            # Count completions
            if event['type'] in ('stage1_model_complete', 'stage1_model_error'):
                completed_count += 1
        except asyncio.TimeoutError:
            # Check if all tasks are done
            if all(task.done() for task in tasks):
                # Drain any remaining events
                while not queue.empty():
                    event = await queue.get()
                    yield event
                    if event['type'] in ('stage1_model_complete', 'stage1_model_error'):
                        completed_count += 1
                break

    # Yield final complete event with all results
    final_results = [
        {"model": model, "response": content}
        for model, content in model_content.items()
        if content  # Only include models that returned content
    ]
    yield {"type": "stage1_all_complete", "data": final_results}


async def stage2_stream_rankings(
    user_query: str,
    stage1_results: List[Dict[str, Any]],
    business_id: Optional[str] = None,
    department_id: Optional[str] = None,
    channel_id: Optional[str] = None,
    style_id: Optional[str] = None
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    Stage 2 with streaming: Each model ranks the anonymized responses,
    yielding token updates as they arrive.

    Yields:
        Dicts with event type and data
    """
    # Create anonymized labels for responses (Response A, Response B, etc.)
    labels = [chr(65 + i) for i in range(len(stage1_results))]  # A, B, C, ...

    # Create mapping from label to model name
    label_to_model = {
        f"Response {label}": result['model']
        for label, result in zip(labels, stage1_results)
    }

    # Build the ranking prompt
    responses_text = "\n\n".join([
        f"Response {label}:\n{result['response']}"
        for label, result in zip(labels, stage1_results)
    ])

    ranking_prompt = f"""You are evaluating different responses to the following question:

Question: {user_query}

Here are the responses from different models (anonymized):

{responses_text}

Your task:
1. First, evaluate each response individually. For each response, explain what it does well and what it does poorly.
2. Then, at the very end of your response, provide a final ranking.

IMPORTANT: Your final ranking MUST be formatted EXACTLY as follows:
- Start with the line "FINAL RANKING:" (all caps, with colon)
- Then list the responses from best to worst as a numbered list
- Each line should be: number, period, space, then ONLY the response label (e.g., "1. Response A")
- Do not add any other text or explanations in the ranking section

Example of the correct format for your ENTIRE response:

Response A provides good detail on X but misses Y...
Response B is accurate but lacks depth on Z...
Response C offers the most comprehensive answer...

FINAL RANKING:
1. Response C
2. Response A
3. Response B

Now provide your evaluation and ranking:"""

    # Build messages with optional contexts
    messages = []

    system_prompt = get_system_prompt_with_context(
        business_id=business_id,
        department_id=department_id,
        channel_id=channel_id,
        style_id=style_id
    )
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})

    messages.append({"role": "user", "content": ranking_prompt})

    # Use a queue to collect events from all models
    queue: asyncio.Queue = asyncio.Queue()
    model_content: Dict[str, str] = {}

    async def stream_single_model(model: str):
        """Stream tokens from a single model and put events on the queue."""
        print(f"[STAGE2 TASK START] {model}: Task started", flush=True)
        content = ""
        chunk_count = 0
        try:
            async for chunk in query_model_stream(model, messages):
                chunk_count += 1
                content += chunk
                await queue.put({"type": "stage2_token", "model": model, "content": chunk})
            print(f"[STAGE2 TASK DONE] {model}: Received {chunk_count} chunks, {len(content)} chars", flush=True)
            model_content[model] = content
            await queue.put({"type": "stage2_model_complete", "model": model, "ranking": content})
        except Exception as e:
            print(f"[STAGE2 TASK ERROR] {model}: {type(e).__name__}: {e}", flush=True)
            await queue.put({"type": "stage2_model_error", "model": model, "error": str(e)})

    # Start all model streams with staggered delays to avoid rate limiting
    # While waiting between starts, process and yield any events from already-started models
    print(f"[STAGE2] Starting {len(COUNCIL_MODELS)} models: {COUNCIL_MODELS}", flush=True)
    tasks = []
    completed_count = 0
    total_models = len(COUNCIL_MODELS)

    for i, model in enumerate(COUNCIL_MODELS):
        print(f"[STAGE2] Creating task for {model}", flush=True)
        tasks.append(asyncio.create_task(stream_single_model(model)))

        if i < total_models - 1:
            # Wait 2s before starting next model, but yield events during the wait
            print(f"[STAGE2] Waiting 2s before starting {COUNCIL_MODELS[i+1]}...", flush=True)
            wait_end = asyncio.get_event_loop().time() + 2.0
            while asyncio.get_event_loop().time() < wait_end:
                try:
                    # Short timeout to check for events frequently
                    event = await asyncio.wait_for(queue.get(), timeout=0.05)
                    yield event
                    if event['type'] in ('stage2_model_complete', 'stage2_model_error'):
                        completed_count += 1
                except asyncio.TimeoutError:
                    pass  # No event yet, continue waiting

    print(f"[STAGE2] All {total_models} tasks created, waiting for remaining results...", flush=True)

    # Continue processing events until all models complete
    while completed_count < total_models:
        try:
            event = await asyncio.wait_for(queue.get(), timeout=0.1)
            yield event

            if event['type'] in ('stage2_model_complete', 'stage2_model_error'):
                completed_count += 1
        except asyncio.TimeoutError:
            if all(task.done() for task in tasks):
                while not queue.empty():
                    event = await queue.get()
                    yield event
                    if event['type'] in ('stage2_model_complete', 'stage2_model_error'):
                        completed_count += 1
                break

    # Build final results with parsed rankings
    stage2_results = []
    for model, content in model_content.items():
        if content:
            parsed = parse_ranking_from_text(content)
            stage2_results.append({
                "model": model,
                "ranking": content,
                "parsed_ranking": parsed
            })

    # Calculate aggregate rankings
    aggregate_rankings = calculate_aggregate_rankings(stage2_results, label_to_model)

    yield {
        "type": "stage2_all_complete",
        "data": stage2_results,
        "label_to_model": label_to_model,
        "aggregate_rankings": aggregate_rankings
    }


async def stage3_stream_synthesis(
    user_query: str,
    stage1_results: List[Dict[str, Any]],
    stage2_results: List[Dict[str, Any]],
    business_id: Optional[str] = None,
    department_id: Optional[str] = None,
    channel_id: Optional[str] = None,
    style_id: Optional[str] = None,
    project_id: Optional[str] = None,
    access_token: Optional[str] = None,
    company_uuid: Optional[str] = None,
    department_uuid: Optional[str] = None
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    Stage 3 with streaming: Chairman synthesizes final response,
    yielding tokens as they arrive.

    Args:
        project_id: Optional project ID to load project-specific context
        access_token: User's JWT access token for RLS authentication

    Yields:
        Dicts with event type and data
    """
    # Build comprehensive context for chairman
    stage1_text = "\n\n".join([
        f"Model: {result['model']}\nResponse: {result['response']}"
        for result in stage1_results
    ])

    stage2_text = "\n\n".join([
        f"Model: {result['model']}\nRanking: {result['ranking']}"
        for result in stage2_results
    ])

    chairman_prompt = f"""You are the Chairman of an LLM Council. Multiple AI models have provided responses to a user's question, and then ranked each other's responses.

Original Question: {user_query}

STAGE 1 - Individual Responses:
{stage1_text}

STAGE 2 - Peer Rankings:
{stage2_text}

Your task as Chairman is to synthesize all of this information into a single, comprehensive, accurate answer to the user's original question. Consider:
- The individual responses and their insights
- The peer rankings and what they reveal about response quality
- Any patterns of agreement or disagreement

Provide a clear, well-reasoned final answer that represents the council's collective wisdom:"""

    # Build messages with optional contexts
    messages = []

    system_prompt = get_system_prompt_with_context(
        business_id=business_id,
        department_id=department_id,
        channel_id=channel_id,
        style_id=style_id,
        project_id=project_id,
        access_token=access_token,
        company_uuid=company_uuid,
        department_uuid=department_uuid
    )
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})

    messages.append({"role": "user", "content": chairman_prompt})

    # Try each chairman model in order until one succeeds
    successful_chairman = None
    final_content = ""

    for chairman_index, chairman_model in enumerate(CHAIRMAN_MODELS):
        print(f"[STAGE3] Trying chairman {chairman_index + 1}/{len(CHAIRMAN_MODELS)}: {chairman_model}", flush=True)

        content = ""
        chunk_count = 0
        had_error = False

        try:
            async for chunk in query_model_stream(chairman_model, messages):
                # Check if this is an error message
                if chunk.startswith("[Error:"):
                    print(f"[STAGE3] Chairman {chairman_model} returned error: {chunk}", flush=True)
                    had_error = True
                    # Try next chairman
                    break

                chunk_count += 1
                content += chunk
                yield {"type": "stage3_token", "model": chairman_model, "content": chunk}

            if not had_error and content and len(content) > 50:  # Successful response
                print(f"[STAGE3] Chairman {chairman_model} succeeded: {chunk_count} chunks, {len(content)} chars", flush=True)
                successful_chairman = chairman_model
                final_content = content
                break
            elif not had_error:
                print(f"[STAGE3] Chairman {chairman_model} returned insufficient content ({len(content)} chars), trying next...", flush=True)

        except Exception as e:
            print(f"[STAGE3 ERROR] Chairman {chairman_model}: {type(e).__name__}: {e}", flush=True)
            yield {"type": "stage3_error", "model": chairman_model, "error": str(e)}

        # If not the last chairman, notify we're trying fallback
        if chairman_index < len(CHAIRMAN_MODELS) - 1:
            print(f"[STAGE3] Falling back to next chairman...", flush=True)
            yield {"type": "stage3_fallback", "failed_model": chairman_model, "next_model": CHAIRMAN_MODELS[chairman_index + 1]}

    if not successful_chairman:
        print(f"[STAGE3] All chairmen failed!", flush=True)
        final_content = "[Error: All chairman models failed. Please try again.]"
        successful_chairman = CHAIRMAN_MODELS[0]  # Report as primary for consistency

    yield {
        "type": "stage3_complete",
        "data": {
            "model": successful_chairman,
            "response": final_content
        }
    }


async def stage2_collect_rankings(
    user_query: str,
    stage1_results: List[Dict[str, Any]],
    business_id: Optional[str] = None
) -> Tuple[List[Dict[str, Any]], Dict[str, str]]:
    """
    Stage 2: Each model ranks the anonymized responses.

    Args:
        user_query: The original user query
        stage1_results: Results from Stage 1
        business_id: Optional business context to load

    Returns:
        Tuple of (rankings list, label_to_model mapping)
    """
    # Create anonymized labels for responses (Response A, Response B, etc.)
    labels = [chr(65 + i) for i in range(len(stage1_results))]  # A, B, C, ...

    # Create mapping from label to model name
    label_to_model = {
        f"Response {label}": result['model']
        for label, result in zip(labels, stage1_results)
    }

    # Build the ranking prompt
    responses_text = "\n\n".join([
        f"Response {label}:\n{result['response']}"
        for label, result in zip(labels, stage1_results)
    ])

    ranking_prompt = f"""You are evaluating different responses to the following question:

Question: {user_query}

Here are the responses from different models (anonymized):

{responses_text}

Your task:
1. First, evaluate each response individually. For each response, explain what it does well and what it does poorly.
2. Then, at the very end of your response, provide a final ranking.

IMPORTANT: Your final ranking MUST be formatted EXACTLY as follows:
- Start with the line "FINAL RANKING:" (all caps, with colon)
- Then list the responses from best to worst as a numbered list
- Each line should be: number, period, space, then ONLY the response label (e.g., "1. Response A")
- Do not add any other text or explanations in the ranking section

Example of the correct format for your ENTIRE response:

Response A provides good detail on X but misses Y...
Response B is accurate but lacks depth on Z...
Response C offers the most comprehensive answer...

FINAL RANKING:
1. Response C
2. Response A
3. Response B

Now provide your evaluation and ranking:"""

    # Build messages with optional business context
    messages = []

    system_prompt = get_system_prompt_with_context(business_id)
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})

    messages.append({"role": "user", "content": ranking_prompt})

    # Get rankings from all council models in parallel
    responses = await query_models_parallel(COUNCIL_MODELS, messages)

    # Format results
    stage2_results = []
    for model, response in responses.items():
        if response is not None:
            full_text = response.get('content', '')
            parsed = parse_ranking_from_text(full_text)
            stage2_results.append({
                "model": model,
                "ranking": full_text,
                "parsed_ranking": parsed
            })

    return stage2_results, label_to_model


async def stage3_synthesize_final(
    user_query: str,
    stage1_results: List[Dict[str, Any]],
    stage2_results: List[Dict[str, Any]],
    business_id: Optional[str] = None
) -> Dict[str, Any]:
    """
    Stage 3: Chairman synthesizes final response.

    Args:
        user_query: The original user query
        stage1_results: Individual model responses from Stage 1
        stage2_results: Rankings from Stage 2
        business_id: Optional business context to load

    Returns:
        Dict with 'model' and 'response' keys
    """
    # Build comprehensive context for chairman
    stage1_text = "\n\n".join([
        f"Model: {result['model']}\nResponse: {result['response']}"
        for result in stage1_results
    ])

    stage2_text = "\n\n".join([
        f"Model: {result['model']}\nRanking: {result['ranking']}"
        for result in stage2_results
    ])

    chairman_prompt = f"""You are the Chairman of an LLM Council. Multiple AI models have provided responses to a user's question, and then ranked each other's responses.

Original Question: {user_query}

STAGE 1 - Individual Responses:
{stage1_text}

STAGE 2 - Peer Rankings:
{stage2_text}

Your task as Chairman is to synthesize all of this information into a single, comprehensive, accurate answer to the user's original question. Consider:
- The individual responses and their insights
- The peer rankings and what they reveal about response quality
- Any patterns of agreement or disagreement

Provide a clear, well-reasoned final answer that represents the council's collective wisdom:"""

    # Build messages with optional business context
    messages = []

    system_prompt = get_system_prompt_with_context(business_id)
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})

    messages.append({"role": "user", "content": chairman_prompt})

    # Query the chairman model
    response = await query_model(CHAIRMAN_MODEL, messages)

    if response is None:
        # Fallback if chairman fails
        return {
            "model": CHAIRMAN_MODEL,
            "response": "Error: Unable to generate final synthesis."
        }

    return {
        "model": CHAIRMAN_MODEL,
        "response": response.get('content', '')
    }


def parse_ranking_from_text(ranking_text: str) -> List[str]:
    """
    Parse the FINAL RANKING section from the model's response.

    Args:
        ranking_text: The full text response from the model

    Returns:
        List of response labels in ranked order
    """
    import re

    # Look for "FINAL RANKING:" section
    if "FINAL RANKING:" in ranking_text:
        # Extract everything after "FINAL RANKING:"
        parts = ranking_text.split("FINAL RANKING:")
        if len(parts) >= 2:
            ranking_section = parts[1]
            # Try to extract numbered list format (e.g., "1. Response A")
            # This pattern looks for: number, period, optional space, "Response X"
            numbered_matches = re.findall(r'\d+\.\s*Response [A-Z]', ranking_section)
            if numbered_matches:
                # Extract just the "Response X" part
                return [re.search(r'Response [A-Z]', m).group() for m in numbered_matches]

            # Fallback: Extract all "Response X" patterns in order
            matches = re.findall(r'Response [A-Z]', ranking_section)
            return matches

    # Fallback: try to find any "Response X" patterns in order
    matches = re.findall(r'Response [A-Z]', ranking_text)
    return matches


def calculate_aggregate_rankings(
    stage2_results: List[Dict[str, Any]],
    label_to_model: Dict[str, str]
) -> List[Dict[str, Any]]:
    """
    Calculate aggregate rankings across all models.

    Args:
        stage2_results: Rankings from each model
        label_to_model: Mapping from anonymous labels to model names

    Returns:
        List of dicts with model name and average rank, sorted best to worst
    """
    from collections import defaultdict

    # Track positions for each model
    model_positions = defaultdict(list)

    for ranking in stage2_results:
        ranking_text = ranking['ranking']

        # Parse the ranking from the structured format
        parsed_ranking = parse_ranking_from_text(ranking_text)

        for position, label in enumerate(parsed_ranking, start=1):
            if label in label_to_model:
                model_name = label_to_model[label]
                model_positions[model_name].append(position)

    # Calculate average position for each model
    aggregate = []
    for model, positions in model_positions.items():
        if positions:
            avg_rank = sum(positions) / len(positions)
            aggregate.append({
                "model": model,
                "average_rank": round(avg_rank, 2),
                "rankings_count": len(positions)
            })

    # Sort by average rank (lower is better)
    aggregate.sort(key=lambda x: x['average_rank'])

    return aggregate


async def generate_conversation_title(user_query: str) -> str:
    """
    Generate a short title for a conversation based on the first user message.

    Args:
        user_query: The first user message

    Returns:
        A short title (3-5 words)
    """
    print(f"[TITLE] Starting title generation for query: {user_query[:50]}...", flush=True)

    title_prompt = f"""Generate a very short title (3-5 words maximum) that summarizes the following question.
The title should be concise and descriptive. Do not use quotes or punctuation in the title.

Question: {user_query}

Title:"""

    messages = [{"role": "user", "content": title_prompt}]

    # Use gemini-2.5-flash for title generation (fast and cheap)
    print(f"[TITLE] Calling google/gemini-2.5-flash...", flush=True)
    response = await query_model("google/gemini-2.5-flash", messages, timeout=30.0)

    if response is None:
        # Fallback to a generic title
        print(f"[TITLE] Model returned None - using fallback title", flush=True)
        return "New Conversation"

    print(f"[TITLE] Got response: {response}", flush=True)
    title = response.get('content', 'New Conversation').strip()

    # Clean up the title - remove quotes, limit length
    title = title.strip('"\'')

    # Truncate if too long
    if len(title) > 50:
        title = title[:47] + "..."

    return title


async def run_full_council(
    user_query: str,
    business_id: Optional[str] = None
) -> Tuple[List, List, Dict, Dict]:
    """
    Run the complete 3-stage council process.

    Args:
        user_query: The user's question
        business_id: Optional business context to load

    Returns:
        Tuple of (stage1_results, stage2_results, stage3_result, metadata)
    """
    # Stage 1: Collect individual responses
    stage1_results = await stage1_collect_responses(user_query, business_id)

    # If no models responded successfully, return error
    if not stage1_results:
        return [], [], {
            "model": "error",
            "response": "All models failed to respond. Please try again."
        }, {}

    # Stage 2: Collect rankings
    stage2_results, label_to_model = await stage2_collect_rankings(
        user_query, stage1_results, business_id
    )

    # Calculate aggregate rankings
    aggregate_rankings = calculate_aggregate_rankings(stage2_results, label_to_model)

    # Stage 3: Synthesize final answer
    stage3_result = await stage3_synthesize_final(
        user_query,
        stage1_results,
        stage2_results,
        business_id
    )

    # Prepare metadata
    metadata = {
        "label_to_model": label_to_model,
        "aggregate_rankings": aggregate_rankings
    }

    return stage1_results, stage2_results, stage3_result, metadata


async def chat_stream_response(
    conversation_history: List[Dict[str, Any]],
    business_id: Optional[str] = None,
    department_id: Optional[str] = None,
    project_id: Optional[str] = None,
    access_token: Optional[str] = None,
    company_uuid: Optional[str] = None,
    department_uuid: Optional[str] = None
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    Stream a chat response from the Chairman model only.
    Used for follow-up questions after council deliberation.

    Args:
        conversation_history: List of message dicts with 'role' and 'content'
        business_id: Optional business context to load
        department_id: Optional department context to load
        project_id: Optional project ID to load project-specific context
        access_token: User's JWT access token for RLS authentication
        company_uuid: Supabase company UUID for knowledge lookup
        department_uuid: Supabase department UUID for knowledge lookup

    Yields:
        Dicts with 'type' (chat_token/chat_complete/chat_error) and 'content'/'model'
    """
    # Build messages with optional contexts
    messages = []

    system_prompt = get_system_prompt_with_context(
        business_id=business_id,
        department_id=department_id,
        project_id=project_id,
        access_token=access_token,
        company_uuid=company_uuid,
        department_uuid=department_uuid
    )

    # Add a chat-specific system prompt prefix
    chat_system = """You are continuing a conversation as the AI Council's advisor. The user has already received council deliberation on their question and may now have follow-up questions, clarifications, or want to explore specific points further.

Be helpful, concise, and reference the previous discussion when relevant. You don't need to consult other models - just provide direct, thoughtful responses."""

    if system_prompt:
        messages.append({"role": "system", "content": chat_system + "\n\n" + system_prompt})
    else:
        messages.append({"role": "system", "content": chat_system})

    # Add the conversation history
    messages.extend(conversation_history)

    # Stream from chairman model(s) with fallback
    successful_chairman = None
    final_content = ""

    for chairman in CHAIRMAN_MODELS:
        print(f"[CHAT] Trying chairman: {chairman}", flush=True)
        try:
            content = ""
            async for chunk in query_model_stream(chairman, messages):
                content += chunk
                yield {"type": "chat_token", "content": chunk, "model": chairman}

            if content:
                print(f"[CHAT] {chairman} succeeded with {len(content)} chars", flush=True)
                final_content = content
                successful_chairman = chairman
                break
        except Exception as e:
            print(f"[CHAT] {chairman} failed: {e}", flush=True)
            yield {"type": "chat_error", "model": chairman, "error": str(e)}
            continue

    if not successful_chairman:
        print(f"[CHAT] All chairmen failed!", flush=True)
        final_content = "[Error: All models failed. Please try again.]"
        successful_chairman = CHAIRMAN_MODELS[0]

    yield {
        "type": "chat_complete",
        "data": {
            "model": successful_chairman,
            "content": final_content
        }
    }

```

### File: backend/database.py
```py
"""Supabase database connection."""

import os
from pathlib import Path
from supabase import create_client, Client
from dotenv import load_dotenv
from typing import Optional

# Load .env from current dir or parent dir
env_path = Path(__file__).resolve().parent.parent / '.env'
if not env_path.exists():
    env_path = Path(__file__).resolve().parent.parent.parent / '.env'
load_dotenv(env_path)

# Supabase configuration (support both SUPABASE_KEY and SUPABASE_ANON_KEY)
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or os.getenv("SUPABASE_ANON_KEY")
SUPABASE_SERVICE_KEY = os.getenv("SUPABASE_SERVICE_KEY")  # Optional: for admin operations

# Supabase client (lazy initialization)
_supabase_client: Client = None
_supabase_service_client: Client = None


def get_supabase() -> Client:
    """Get or create the Supabase client (anon key - subject to RLS)."""
    global _supabase_client

    if _supabase_client is None:
        if not SUPABASE_URL or not SUPABASE_KEY:
            raise ValueError(
                "SUPABASE_URL and SUPABASE_KEY must be set in environment variables. "
                "Add them to your .env file."
            )
        _supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)

    return _supabase_client


def get_supabase_service() -> Optional[Client]:
    """
    Get or create the Supabase service client (bypasses RLS).
    Used for admin operations like webhooks.
    Returns None if service key is not configured.
    """
    global _supabase_service_client

    if _supabase_service_client is None:
        if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
            return None
        _supabase_service_client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)

    return _supabase_service_client


def get_supabase_with_auth(access_token: str) -> Client:
    """
    Create a Supabase client authenticated with a user's JWT token.
    This client will respect RLS policies using the user's identity.

    Args:
        access_token: The user's JWT access token from Supabase Auth

    Returns:
        Authenticated Supabase client
    """
    if not SUPABASE_URL or not SUPABASE_KEY:
        raise ValueError(
            "SUPABASE_URL and SUPABASE_KEY must be set in environment variables. "
            "Add them to your .env file."
        )

    # Create a new client with the user's access token
    client = create_client(SUPABASE_URL, SUPABASE_KEY)

    # Set the auth header to use the user's token
    # This makes auth.uid() return the user's ID in RLS policies
    client.postgrest.auth(access_token)

    # Also set auth for storage operations
    # The storage client needs the Authorization header set
    client.storage._client.headers["Authorization"] = f"Bearer {access_token}"

    return client


def is_supabase_configured() -> bool:
    """Check if Supabase is configured."""
    return bool(SUPABASE_URL and SUPABASE_KEY)

```

### File: backend/migrations/01_organization_schema.sql
```sql
-- =============================================
-- PHASE 1: MY COMPANY ORGANIZATION SCHEMA
-- =============================================
-- Run this in Supabase SQL Editor
-- This creates all tables for the unified "My Company" feature

-- Departments
CREATE TABLE IF NOT EXISTS departments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID REFERENCES companies(id) ON DELETE CASCADE,
    name TEXT NOT NULL,
    slug TEXT NOT NULL,
    description TEXT,
    purpose TEXT,
    budget_annual NUMERIC(12,2),
    budget_currency TEXT DEFAULT 'EUR',
    display_order INTEGER DEFAULT 0,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(company_id, slug)
);

-- Roles
CREATE TABLE IF NOT EXISTS roles (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID REFERENCES companies(id) ON DELETE CASCADE,
    department_id UUID REFERENCES departments(id) ON DELETE CASCADE,
    name TEXT NOT NULL,
    slug TEXT NOT NULL,
    title TEXT,
    responsibilities TEXT,
    problems_solved TEXT,
    system_prompt TEXT,
    is_active BOOLEAN DEFAULT true,
    display_order INTEGER DEFAULT 0,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(department_id, slug)
);

-- Playbooks (SOPs, Frameworks, Policies)
CREATE TABLE IF NOT EXISTS org_documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID REFERENCES companies(id) ON DELETE CASCADE,
    department_id UUID REFERENCES departments(id) ON DELETE SET NULL,
    doc_type TEXT NOT NULL CHECK (doc_type IN ('sop', 'framework', 'policy')),
    title TEXT NOT NULL,
    slug TEXT NOT NULL,
    summary TEXT,
    is_active BOOLEAN DEFAULT true,
    auto_inject BOOLEAN DEFAULT true,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(company_id, doc_type, slug)
);

-- Document Versions
CREATE TABLE IF NOT EXISTS org_document_versions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES org_documents(id) ON DELETE CASCADE,
    version INTEGER NOT NULL,
    content TEXT NOT NULL,
    status TEXT DEFAULT 'active' CHECK (status IN ('draft', 'active', 'archived')),
    change_summary TEXT,
    is_current BOOLEAN DEFAULT false,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    created_by UUID REFERENCES auth.users(id),
    UNIQUE(document_id, version)
);

-- Decisions (replaces Knowledge Base)
CREATE TABLE IF NOT EXISTS decisions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID REFERENCES companies(id) ON DELETE CASCADE,
    department_id UUID REFERENCES departments(id) ON DELETE SET NULL,
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    source_conversation_id UUID REFERENCES conversations(id),
    source_message_id UUID,
    tags TEXT[] DEFAULT '{}',
    is_promoted BOOLEAN DEFAULT false,
    promoted_to_id UUID REFERENCES org_documents(id),
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- =============================================
-- ROW LEVEL SECURITY
-- =============================================

ALTER TABLE departments ENABLE ROW LEVEL SECURITY;
ALTER TABLE roles ENABLE ROW LEVEL SECURITY;
ALTER TABLE org_documents ENABLE ROW LEVEL SECURITY;
ALTER TABLE org_document_versions ENABLE ROW LEVEL SECURITY;
ALTER TABLE decisions ENABLE ROW LEVEL SECURITY;

-- RLS Policies (access via company ownership)
CREATE POLICY "departments_access" ON departments FOR ALL USING (
    company_id IN (SELECT id FROM companies WHERE user_id = auth.uid())
);

CREATE POLICY "roles_access" ON roles FOR ALL USING (
    company_id IN (SELECT id FROM companies WHERE user_id = auth.uid())
);

CREATE POLICY "org_documents_access" ON org_documents FOR ALL USING (
    company_id IN (SELECT id FROM companies WHERE user_id = auth.uid())
);

CREATE POLICY "org_document_versions_access" ON org_document_versions FOR ALL USING (
    document_id IN (
        SELECT id FROM org_documents
        WHERE company_id IN (SELECT id FROM companies WHERE user_id = auth.uid())
    )
);

CREATE POLICY "decisions_access" ON decisions FOR ALL USING (
    company_id IN (SELECT id FROM companies WHERE user_id = auth.uid())
);

-- =============================================
-- PERFORMANCE INDEXES
-- =============================================

CREATE INDEX IF NOT EXISTS idx_departments_company_id ON departments(company_id);
CREATE INDEX IF NOT EXISTS idx_roles_department_id ON roles(department_id);
CREATE INDEX IF NOT EXISTS idx_roles_company_id ON roles(company_id);
CREATE INDEX IF NOT EXISTS idx_decisions_company_id ON decisions(company_id);
CREATE INDEX IF NOT EXISTS idx_org_documents_company_type ON org_documents(company_id, doc_type);
CREATE INDEX IF NOT EXISTS idx_org_document_versions_document ON org_document_versions(document_id);

-- =============================================
-- VERIFICATION
-- =============================================
-- After running, execute these to verify:
-- SELECT * FROM departments;  -- Should return empty, no errors
-- SELECT * FROM roles;        -- Should return empty, no errors
-- SELECT * FROM org_documents; -- Should return empty, no errors
-- SELECT * FROM decisions;    -- Should return empty, no errors

```

### File: frontend/package.json
```json
{
  "name": "frontend",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "@radix-ui/react-dialog": "^1.1.15",
    "@radix-ui/react-select": "^2.2.6",
    "@radix-ui/react-slot": "^1.2.4",
    "@supabase/supabase-js": "^2.86.2",
    "@tailwindcss/typography": "^0.5.19",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "diff": "^8.0.2",
    "framer-motion": "^12.23.25",
    "geist": "^1.5.1",
    "lucide-react": "^0.556.0",
    "next-themes": "^0.4.6",
    "react": "^19.2.0",
    "react-dom": "^19.2.0",
    "react-markdown": "^10.1.0",
    "rehype-slug": "^6.0.0",
    "remark-gfm": "^4.0.1",
    "sonner": "^2.0.7",
    "tailwind-merge": "^3.4.0"
  },
  "devDependencies": {
    "@eslint/js": "^9.39.1",
    "@tailwindcss/postcss": "^4.1.17",
    "@types/react": "^19.2.5",
    "@types/react-dom": "^19.2.3",
    "@vitejs/plugin-react": "^5.1.1",
    "eslint": "^9.39.1",
    "eslint-plugin-react-hooks": "^7.0.1",
    "eslint-plugin-react-refresh": "^0.4.24",
    "globals": "^16.5.0",
    "postcss": "^8.5.6",
    "tailwindcss": "^4.1.17",
    "vite": "^7.2.4"
  }
}

```

### File: frontend/src/App.jsx
```jsx
import { useState, useEffect, useRef, useMemo } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import Sidebar from './components/Sidebar';
import ChatInterface from './components/ChatInterface';
import Leaderboard from './components/Leaderboard';
import Settings from './components/Settings';
import ProjectModal from './components/ProjectModal';
import Triage from './components/Triage';
import Login from './components/Login';
import MyCompany from './components/MyCompany';
import { useAuth } from './AuthContext';
import { api, setTokenGetter } from './api';
import './App.css';

// Default departments when no company is selected or company has no departments
const DEFAULT_DEPARTMENTS = [
  { id: 'standard', name: 'Standard', description: 'General advisory council' },
];

function App() {
  const { user, loading: authLoading, signOut, isAuthenticated, needsPasswordReset, getAccessToken } = useAuth();

  // Set up API token getter when auth is available
  useEffect(() => {
    if (getAccessToken) {
      setTokenGetter(getAccessToken);
    }
  }, [getAccessToken]);

  const [conversations, setConversations] = useState([]);
  const [hasMoreConversations, setHasMoreConversations] = useState(true);
  const [conversationSortBy, setConversationSortBy] = useState('date'); // 'date' or 'activity'
  const [currentConversationId, setCurrentConversationId] = useState(null);
  const [currentConversation, setCurrentConversation] = useState(null);
  const [isLoading, setIsLoading] = useState(false);
  const [businesses, setBusinesses] = useState([]);
  const [selectedBusiness, setSelectedBusiness] = useState(null);
  const [selectedDepartment, setSelectedDepartment] = useState(null); // null = no department selected
  const [selectedRole, setSelectedRole] = useState(null); // null = general council, or specific role
  const [selectedChannel, setSelectedChannel] = useState(null);
  const [selectedStyle, setSelectedStyle] = useState(null);
  const [projects, setProjects] = useState([]); // Projects for selected company
  const [selectedProject, setSelectedProject] = useState(null); // Selected project ID
  const [useCompanyContext, setUseCompanyContext] = useState(true); // Whether to use company context
  const [useDepartmentContext, setUseDepartmentContext] = useState(true); // Whether to use department context
  const [isLeaderboardOpen, setIsLeaderboardOpen] = useState(false);
  const [isSettingsOpen, setIsSettingsOpen] = useState(false);
  const [isProjectModalOpen, setIsProjectModalOpen] = useState(false);
  const [isMyCompanyOpen, setIsMyCompanyOpen] = useState(false);
  const [myCompanyInitialTab, setMyCompanyInitialTab] = useState('overview');
  const [myCompanyInitialDecisionId, setMyCompanyInitialDecisionId] = useState(null);
  const [myCompanyInitialPlaybookId, setMyCompanyInitialPlaybookId] = useState(null);
  const [myCompanyPromoteDecision, setMyCompanyPromoteDecision] = useState(null); // Decision object to open in Promote modal on return
  const [scrollToStage3, setScrollToStage3] = useState(false); // When navigating from decision source, scroll to Stage 3
  const [returnToMyCompanyTab, setReturnToMyCompanyTab] = useState(null); // Tab to return to after viewing source (e.g., 'decisions', 'activity')
  // Triage state
  const [triageState, setTriageState] = useState(null); // null, 'analyzing', or triage result object
  const [originalQuery, setOriginalQuery] = useState('');
  const [isTriageLoading, setIsTriageLoading] = useState(false);
  const [isUploading, setIsUploading] = useState(false); // Image upload in progress
  const abortControllerRef = useRef(null);
  const skipNextLoadRef = useRef(false); // Skip loadConversation when transitioning from temp to real
  const hasLoadedInitialData = useRef(false); // Prevent repeated API calls on mount

  // Get the currently selected business object
  // IMPORTANT: All hooks must be called before any early returns
  const currentBusiness = useMemo(() => {
    return businesses.find((b) => b.id === selectedBusiness) || null;
  }, [businesses, selectedBusiness]);

  // Get departments for the selected company
  const availableDepartments = useMemo(() => {
    if (!currentBusiness || !currentBusiness.departments || currentBusiness.departments.length === 0) {
      return DEFAULT_DEPARTMENTS;
    }
    return currentBusiness.departments;
  }, [currentBusiness]);

  // Get roles for the selected department (if any)
  const availableRoles = useMemo(() => {
    if (!selectedDepartment || !availableDepartments) return [];
    const dept = availableDepartments.find((d) => d.id === selectedDepartment);
    return dept?.roles || [];
  }, [availableDepartments, selectedDepartment]);

  // Get channels for the selected department (if any)
  const availableChannels = useMemo(() => {
    if (!selectedDepartment || !availableDepartments) return [];
    const dept = availableDepartments.find((d) => d.id === selectedDepartment);
    return dept?.channels || [];
  }, [availableDepartments, selectedDepartment]);

  // Get styles for the selected company
  const availableStyles = useMemo(() => {
    if (!currentBusiness || !currentBusiness.styles) return [];
    return currentBusiness.styles;
  }, [currentBusiness]);

  // When business changes, reset department/channel/style/project to defaults and load projects
  // Track the previous business to avoid resetting on initial load
  const prevBusinessRef = useRef(selectedBusiness);
  useEffect(() => {
    // Only reset selections when business actually CHANGES (not on mount or businesses list refresh)
    const businessChanged = prevBusinessRef.current !== selectedBusiness;
    prevBusinessRef.current = selectedBusiness;

    if (businessChanged) {
      // Default to null (General/company-wide) - user can select specific department
      setSelectedDepartment(null);
      setSelectedChannel(null);
      setSelectedStyle(null);
      setSelectedProject(null);
      setProjects([]);
    }

    // Load projects for the selected business
    const loadProjects = async () => {
      if (selectedBusiness) {
        try {
          const result = await api.listProjects(selectedBusiness);
          const loadedProjects = result.projects || [];
          setProjects(loadedProjects);
          // Auto-select the first project if available (only on business change or initial load)
          if (loadedProjects.length > 0 && !selectedProject) {
            setSelectedProject(loadedProjects[0].id);
          }
        } catch (error) {
          console.error('Failed to load projects:', error);
          setProjects([]);
        }
      }
    };
    loadProjects();
    // Note: Only depend on selectedBusiness, NOT businesses array
    // The businesses array changing should not trigger selection resets
  }, [selectedBusiness]);

  // When department changes, reset role and channel
  // Track the previous department to avoid resetting on initial mount
  const prevDepartmentRef = useRef(selectedDepartment);
  useEffect(() => {
    // Only reset when department actually CHANGES (not on mount)
    const departmentChanged = prevDepartmentRef.current !== selectedDepartment;
    prevDepartmentRef.current = selectedDepartment;

    if (departmentChanged && selectedDepartment !== null) {
      // Only reset if we're switching to a different department (not clearing)
      setSelectedRole(null);
      setSelectedChannel(null);
    }
  }, [selectedDepartment]);

  // Define functions BEFORE useEffect hooks that reference them
  const loadBusinesses = async () => {
    try {
      const bizList = await api.listBusinesses();
      setBusinesses(bizList);
      // Auto-select first business if available
      if (bizList.length > 0 && !selectedBusiness) {
        setSelectedBusiness(bizList[0].id);
      }
    } catch (error) {
      console.error('Failed to load businesses:', error);
    }
  };

  const CONVERSATIONS_PAGE_SIZE = 10; // Reduced for faster initial load

  const loadConversations = async (options = {}) => {
    try {
      const limit = options.limit || CONVERSATIONS_PAGE_SIZE;
      const sortBy = options.sortBy || conversationSortBy;
      const result = await api.listConversations({ ...options, limit, sortBy });

      // API now returns { conversations: [...], has_more: bool }
      const convs = result.conversations || result; // Backwards compatible
      const hasMore = result.has_more !== undefined ? result.has_more : convs.length >= limit;

      if (options.offset && options.offset > 0) {
        // Append to existing conversations (Load More) with deduplication
        setConversations(prev => {
          const existingIds = new Set(prev.map(c => c.id));
          const newConvs = convs.filter(c => !existingIds.has(c.id));
          return [...prev, ...newConvs];
        });
      } else {
        // Replace conversations (initial load or search)
        setConversations(convs);
      }

      // Use has_more from API response
      setHasMoreConversations(hasMore);

      return convs;
    } catch (error) {
      console.error('Failed to load conversations:', error);
      return [];
    }
  };

  // Handler for Load More button
  const handleLoadMoreConversations = async (currentOffset, searchQuery = '') => {
    return loadConversations({
      offset: currentOffset,
      search: searchQuery || undefined
    });
  };

  // Handler for search
  const handleSearchConversations = async (searchQuery) => {
    return loadConversations({
      offset: 0,
      search: searchQuery || undefined
    });
  };

  const loadConversation = async (id) => {
    try {
      const conv = await api.getConversation(id);
      setCurrentConversation(conv);
    } catch (error) {
      console.error('Failed to load conversation:', error);
    }
  };

  // Reset loaded flag when user logs out
  useEffect(() => {
    if (!isAuthenticated) {
      hasLoadedInitialData.current = false;
    }
  }, [isAuthenticated]);

  // Load conversations and businesses on mount (with token ready check)
  // Only load once when authenticated, not on every re-render
  useEffect(() => {
    // Check sync BEFORE any async work to prevent race conditions
    if (!isAuthenticated || needsPasswordReset || hasLoadedInitialData.current) {
      return;
    }
    // Mark as loaded immediately to prevent duplicate calls
    hasLoadedInitialData.current = true;

    const loadData = async () => {
      const token = await getAccessToken();
      if (token) {
        loadConversations();
        loadBusinesses();

        // Check for conversation ID in URL parameters
        const urlParams = new URLSearchParams(window.location.search);
        const conversationId = urlParams.get('conversation');
        if (conversationId) {
          // Load the specific conversation from URL
          setCurrentConversationId(conversationId);
          // Clean up URL without reload
          window.history.replaceState({}, '', window.location.pathname);
        }
      }
    };
    loadData();
  }, [isAuthenticated, needsPasswordReset]); // Remove getAccessToken from deps to prevent re-runs

  // Auto-create a temp conversation when authenticated but no conversation selected
  // This ensures users always have an input form available
  useEffect(() => {
    if (isAuthenticated && !needsPasswordReset && !currentConversationId) {
      // Create a temporary conversation in memory only
      const tempId = `temp-${Date.now()}`;
      const tempConv = {
        id: tempId,
        created_at: new Date().toISOString(),
        title: 'New Conversation',
        messages: [],
        isTemp: true,
      };
      setCurrentConversationId(tempId);
      setCurrentConversation(tempConv);
    }
  }, [isAuthenticated, needsPasswordReset, currentConversationId]);

  // Load conversation details when selected (skip temp conversations)
  useEffect(() => {
    if (currentConversationId && !currentConversationId.startsWith('temp-')) {
      // Skip loading if we just transitioned from temp to real (streaming in progress)
      if (skipNextLoadRef.current) {
        skipNextLoadRef.current = false;
        return;
      }
      loadConversation(currentConversationId);
    }
  }, [currentConversationId]);

  // Show loading while checking auth
  if (authLoading) {
    return (
      <div className="app" style={{ display: 'flex', alignItems: 'center', justifyContent: 'center' }}>
        <p>Loading...</p>
      </div>
    );
  }

  // Show login if not authenticated OR if user needs to reset password
  if (!isAuthenticated || needsPasswordReset) {
    return (
      <AnimatePresence mode="wait">
        <motion.div
          key="login"
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
          exit={{ opacity: 0 }}
          transition={{ duration: 0.3 }}
        >
          <Login />
        </motion.div>
      </AnimatePresence>
    );
  }

  const handleNewConversation = () => {
    // Create a temporary conversation in memory only - don't persist until first message
    const tempId = `temp-${Date.now()}`;
    const tempConv = {
      id: tempId,
      created_at: new Date().toISOString(),
      title: 'New Conversation',
      messages: [],
      isTemp: true, // Mark as temporary/unsaved
    };

    // Don't add to conversations list (it would show 0 messages)
    // Just set it as the current conversation
    setCurrentConversationId(tempId);
    setCurrentConversation(tempConv);

    // Clear return-to-company state - user has started a new action
    setReturnToMyCompanyTab(null);
    setMyCompanyPromoteDecision(null);
  };

  const handleSelectConversation = (id) => {
    setCurrentConversationId(id);

    // Clear return-to-company state - user has started a new action
    setReturnToMyCompanyTab(null);
    setMyCompanyPromoteDecision(null);
  };

  const handleArchiveConversation = async (id, archived) => {
    try {
      await api.archiveConversation(id, archived);
      // Update the conversations list
      setConversations((prev) =>
        prev.map((conv) =>
          conv.id === id ? { ...conv, is_archived: archived } : conv
        )
      );
    } catch (error) {
      console.error('Failed to archive conversation:', error);
    }
  };

  const handleStarConversation = async (id, starred) => {
    // Optimistic update - update UI immediately for responsiveness
    setConversations((prev) => {
      const updated = prev.map((conv) =>
        conv.id === id ? { ...conv, is_starred: starred } : conv
      );
      // Re-sort: starred first, then by message count
      return updated.sort((a, b) => {
        if (a.is_starred && !b.is_starred) return -1;
        if (!a.is_starred && b.is_starred) return 1;
        return b.message_count - a.message_count;
      });
    });

    // Sync with backend (revert on error)
    try {
      await api.starConversation(id, starred);
    } catch (error) {
      console.error('Failed to star conversation:', error);
      // Revert the optimistic update on error
      setConversations((prev) => {
        const reverted = prev.map((conv) =>
          conv.id === id ? { ...conv, is_starred: !starred } : conv
        );
        return reverted.sort((a, b) => {
          if (a.is_starred && !b.is_starred) return -1;
          if (!a.is_starred && b.is_starred) return 1;
          return b.message_count - a.message_count;
        });
      });
    }
  };

  const handleDeleteConversation = async (id) => {
    try {
      await api.deleteConversation(id);
      // Remove from conversations list
      setConversations((prev) => prev.filter((conv) => conv.id !== id));
      // If we deleted the current conversation, clear the selection
      if (currentConversationId === id) {
        setCurrentConversationId(null);
        setCurrentConversation(null);
      }
    } catch (error) {
      console.error('Failed to delete conversation:', error);
    }
  };

  const handleBulkDeleteConversations = async (ids) => {
    try {
      const result = await api.bulkDeleteConversations(ids);
      // Remove deleted conversations from the list
      setConversations((prev) => prev.filter((conv) => !result.deleted.includes(conv.id)));
      // If current conversation was deleted, clear selection
      if (result.deleted.includes(currentConversationId)) {
        setCurrentConversationId(null);
        setCurrentConversation(null);
      }
      return result;
    } catch (error) {
      console.error('Failed to bulk delete conversations:', error);
      throw error;
    }
  };

  const handleRenameConversation = async (id, title) => {
    try {
      await api.renameConversation(id, title);
      // Update the conversations list
      setConversations((prev) =>
        prev.map((conv) =>
          conv.id === id ? { ...conv, title } : conv
        )
      );
      // Also update current conversation if it's the one being renamed
      if (currentConversationId === id) {
        setCurrentConversation((prev) =>
          prev ? { ...prev, title } : prev
        );
      }
    } catch (error) {
      console.error('Failed to rename conversation:', error);
    }
  };

  // Triage handlers
  const handleStartTriage = async (content) => {
    if (!currentConversationId) return;

    setOriginalQuery(content);
    setIsTriageLoading(true);
    setTriageState('analyzing');

    // Only pass businessId if useCompanyContext is enabled
    const effectiveBusinessId = useCompanyContext ? selectedBusiness : null;

    try {
      const result = await api.analyzeTriage(content, effectiveBusinessId);
      setTriageState(result);
    } catch (error) {
      console.error('Triage analysis failed:', error);
      // On error, skip triage and go directly to council
      handleSendToCouncil(content);
    } finally {
      setIsTriageLoading(false);
    }
  };

  const handleTriageRespond = async (response) => {
    if (!triageState || triageState === 'analyzing') return;

    setIsTriageLoading(true);

    // Only pass businessId if useCompanyContext is enabled
    const effectiveBusinessId = useCompanyContext ? selectedBusiness : null;

    try {
      const result = await api.continueTriage(
        originalQuery,
        triageState.constraints || {},
        response,
        effectiveBusinessId
      );
      setTriageState(result);
    } catch (error) {
      console.error('Triage continue failed:', error);
      // On error, proceed with what we have
      handleSendToCouncil(triageState.enhanced_query || originalQuery);
    } finally {
      setIsTriageLoading(false);
    }
  };

  const handleTriageSkip = () => {
    // Skip triage and send original query to council
    handleSendToCouncil(originalQuery);
  };

  const handleTriageProceed = (enhancedQuery) => {
    // Proceed with the enhanced query
    handleSendToCouncil(enhancedQuery);
  };

  const handleStopGeneration = () => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      abortControllerRef.current = null;
      setIsLoading(false);

      // Mark the message as stopped (not just loading=false)
      // This tells the UI to show "Stopped" instead of "thinking..."
      setCurrentConversation((prev) => {
        if (!prev || !prev.messages || prev.messages.length === 0) return prev;
        const messages = [...prev.messages];
        const lastMsg = messages[messages.length - 1];
        if (lastMsg.loading) {
          lastMsg.loading = {
            stage1: false,
            stage2: false,
            stage3: false,
          };
          // Mark as stopped so UI can show appropriate feedback
          lastMsg.stopped = true;
        }
        return { ...prev, messages };
      });
    }
  };

  // This is called when user submits a message - goes directly to council (triage disabled)
  const handleSendMessage = async (content, images = null) => {
    if (!currentConversationId) return;
    // TRIAGE DISABLED: Go directly to council
    // To re-enable triage, change this back to: await handleStartTriage(content);
    await handleSendToCouncil(content, images);
  };

  // This is called after triage is complete (or skipped) to send to council
  const handleSendToCouncil = async (content, images = null) => {
    if (!currentConversationId) return;

    // Clear triage state
    setTriageState(null);
    setOriginalQuery('');

    // Create new AbortController for this request
    abortControllerRef.current = new AbortController();

    setIsLoading(true);

    // Upload images if provided and get attachment IDs
    let attachmentIds = null;
    if (images && images.length > 0) {
      try {
        setIsUploading(true);
        console.log(`[APP] Uploading ${images.length} images...`);
        const uploadPromises = images.map(img => api.uploadAttachment(img.file));
        const uploadedAttachments = await Promise.all(uploadPromises);
        attachmentIds = uploadedAttachments.map(a => a.id);
        console.log(`[APP] Uploaded attachments:`, attachmentIds);
      } catch (error) {
        console.error('Failed to upload images:', error);
        // Continue without images if upload fails
      } finally {
        setIsUploading(false);
      }
    }

    // If this is a temporary conversation, create it on the backend first
    let conversationId = currentConversationId;
    const isTemp = currentConversation?.isTemp || currentConversationId.startsWith('temp-');

    if (isTemp) {
      try {
        const newConv = await api.createConversation();
        conversationId = newConv.id;

        // Skip the loadConversation call that would be triggered by setCurrentConversationId
        // We're already managing the conversation state via streaming
        skipNextLoadRef.current = true;

        // Update our state with the real conversation ID
        setCurrentConversationId(conversationId);
        setCurrentConversation((prev) => ({
          ...prev,
          id: conversationId,
          isTemp: false,
        }));

        // Add to conversations list now that it will have a message
        setConversations((prev) => [
          { id: conversationId, created_at: newConv.created_at, message_count: 0, title: 'New Conversation' },
          ...prev,
        ]);
      } catch (error) {
        console.error('Failed to create conversation:', error);
        setIsLoading(false);
        return;
      }
    }

    try {
      // Optimistically add user message to UI
      const userMessage = { role: 'user', content };
      setCurrentConversation((prev) => ({
        ...prev,
        messages: [...prev.messages, userMessage],
      }));

      // Create a partial assistant message that will be updated progressively
      // Start with stage1 loading = true immediately so user sees "Waiting for models..." right away
      const assistantMessage = {
        role: 'assistant',
        stage1: null,
        stage1Streaming: {}, // Track streaming text per model: { 'model-id': { text: '', complete: false } }
        stage2: null,
        stage3: null,
        metadata: null,
        loading: {
          stage1: true,  // Start as true so Stage1 shows immediately
          stage2: false,
          stage3: false,
        },
      };

      // Add the partial assistant message
      setCurrentConversation((prev) => ({
        ...prev,
        messages: [...prev.messages, assistantMessage],
      }));

      // Send message with streaming (with business/department context if enabled)
      // If useCompanyContext is false, pass null for businessId
      // If useDepartmentContext is false, pass null for department
      const effectiveBusinessId = useCompanyContext ? selectedBusiness : null;
      const effectiveDepartment = useDepartmentContext ? selectedDepartment : null;
      await api.sendMessageStream(conversationId, content, (eventType, event) => {
        switch (eventType) {
          case 'stage1_start':
            setCurrentConversation((prev) => {
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? { ...msg, loading: { ...msg.loading, stage1: true }, stage1Streaming: {} }
                  : msg
              );
              return { ...prev, messages };
            });
            break;

          case 'stage1_token':
            // Append token to the specific model's streaming text (IMMUTABLE)
            // Force new array reference to ensure React detects the change
            setCurrentConversation((prev) => {
              const model = event.model;
              const messages = [...prev.messages];
              const lastIdx = messages.length - 1;
              if (lastIdx >= 0) {
                const msg = messages[lastIdx];
                const currentStreaming = msg.stage1Streaming?.[model] || { text: '', complete: false };
                messages[lastIdx] = {
                  ...msg,
                  stage1Streaming: {
                    ...msg.stage1Streaming,
                    [model]: {
                      text: currentStreaming.text + event.content,
                      complete: false,
                    },
                  },
                };
              }
              return { ...prev, messages, _streamTick: Date.now() };
            });
            break;

          case 'stage1_model_complete':
            // Mark a single model as complete (IMMUTABLE)
            setCurrentConversation((prev) => {
              const model = event.model;
              const messages = prev.messages.map((msg, idx) => {
                if (idx !== prev.messages.length - 1) return msg;
                const currentStreaming = msg.stage1Streaming?.[model];
                return {
                  ...msg,
                  stage1Streaming: {
                    ...msg.stage1Streaming,
                    [model]: currentStreaming
                      ? { ...currentStreaming, complete: true }
                      : { text: event.response, complete: true },
                  },
                };
              });
              return { ...prev, messages };
            });
            break;

          case 'stage1_model_error':
            // Handle model error (IMMUTABLE)
            setCurrentConversation((prev) => {
              const model = event.model;
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? {
                      ...msg,
                      stage1Streaming: {
                        ...msg.stage1Streaming,
                        [model]: { text: `Error: ${event.error}`, complete: true, error: true },
                      },
                    }
                  : msg
              );
              return { ...prev, messages };
            });
            break;

          case 'stage1_complete':
            setCurrentConversation((prev) => {
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? { ...msg, stage1: event.data, loading: { ...msg.loading, stage1: false } }
                  : msg
              );
              return { ...prev, messages };
            });
            break;

          case 'stage2_start':
            setCurrentConversation((prev) => {
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? { ...msg, loading: { ...msg.loading, stage2: true }, stage2Streaming: {} }
                  : msg
              );
              return { ...prev, messages };
            });
            break;

          case 'stage2_token':
            // Append token to the specific model's stage2 streaming text (IMMUTABLE)
            // Force new array reference to ensure React detects the change
            setCurrentConversation((prev) => {
              const model = event.model;
              const messages = [...prev.messages];
              const lastIdx = messages.length - 1;
              if (lastIdx >= 0) {
                const msg = messages[lastIdx];
                const currentStreaming = msg.stage2Streaming?.[model] || { text: '', complete: false };
                messages[lastIdx] = {
                  ...msg,
                  stage2Streaming: {
                    ...msg.stage2Streaming,
                    [model]: {
                      text: currentStreaming.text + event.content,
                      complete: false,
                    },
                  },
                };
              }
              return { ...prev, messages, _streamTick: Date.now() };
            });
            break;

          case 'stage2_model_complete':
            // Mark a single model's stage2 evaluation as complete (IMMUTABLE)
            setCurrentConversation((prev) => {
              const model = event.model;
              const messages = prev.messages.map((msg, idx) => {
                if (idx !== prev.messages.length - 1) return msg;
                const currentStreaming = msg.stage2Streaming?.[model];
                return {
                  ...msg,
                  stage2Streaming: {
                    ...msg.stage2Streaming,
                    [model]: currentStreaming
                      ? { ...currentStreaming, complete: true }
                      : { text: event.ranking, complete: true },
                  },
                };
              });
              return { ...prev, messages };
            });
            break;

          case 'stage2_model_error':
            // Handle stage2 model error (IMMUTABLE)
            setCurrentConversation((prev) => {
              const model = event.model;
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? {
                      ...msg,
                      stage2Streaming: {
                        ...msg.stage2Streaming,
                        [model]: { text: `Error: ${event.error}`, complete: true, error: true },
                      },
                    }
                  : msg
              );
              return { ...prev, messages };
            });
            break;

          case 'stage2_complete':
            setCurrentConversation((prev) => {
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? {
                      ...msg,
                      stage2: event.data,
                      metadata: event.metadata,
                      loading: { ...msg.loading, stage2: false },
                    }
                  : msg
              );
              return { ...prev, messages };
            });
            break;

          case 'stage3_start':
            setCurrentConversation((prev) => {
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? { ...msg, loading: { ...msg.loading, stage3: true }, stage3Streaming: { text: '', complete: false } }
                  : msg
              );
              return { ...prev, messages };
            });
            break;

          case 'stage3_token':
            // Append token to stage3 streaming text (IMMUTABLE)
            // Force new array reference to ensure React detects the change
            setCurrentConversation((prev) => {
              const messages = [...prev.messages];
              const lastIdx = messages.length - 1;
              if (lastIdx >= 0) {
                const msg = messages[lastIdx];
                const currentStreaming = msg.stage3Streaming || { text: '', complete: false };
                messages[lastIdx] = {
                  ...msg,
                  stage3Streaming: {
                    text: currentStreaming.text + event.content,
                    complete: false,
                  },
                };
              }
              return { ...prev, messages, _streamTick: Date.now() };
            });
            break;

          case 'stage3_error':
            // Handle stage3 error (IMMUTABLE)
            setCurrentConversation((prev) => {
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? {
                      ...msg,
                      stage3Streaming: { text: `Error: ${event.error}`, complete: true, error: true },
                    }
                  : msg
              );
              return { ...prev, messages };
            });
            break;

          case 'stage3_complete':
            setCurrentConversation((prev) => {
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? {
                      ...msg,
                      stage3: event.data,
                      stage3Streaming: msg.stage3Streaming
                        ? { ...msg.stage3Streaming, complete: true }
                        : { text: event.data.response, complete: true },
                      loading: { ...msg.loading, stage3: false },
                    }
                  : msg
              );
              return { ...prev, messages };
            });
            break;

          case 'title_complete':
            // Reload conversations to get updated title
            loadConversations();
            break;

          case 'complete':
            // Stream complete, reload conversations list
            loadConversations();
            setIsLoading(false);
            break;

          case 'error':
            console.error('Stream error:', event.message);
            // Reset all loading states in the message
            setCurrentConversation((prev) => {
              if (!prev || !prev.messages || prev.messages.length === 0) return prev;
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? {
                      ...msg,
                      loading: { stage1: false, stage2: false, stage3: false },
                    }
                  : msg
              );
              return { ...prev, messages };
            });
            setIsLoading(false);
            break;

          case 'cancelled':
            console.log('Request cancelled');
            setIsLoading(false);
            break;

          case 'image_analysis_start':
            console.log('[IMAGE] Starting analysis of', event.count, 'images');
            break;

          case 'image_analysis_complete':
            console.log('[IMAGE] Analysis complete:', event.analyzed, 'images analyzed');
            if (event.analysis) {
              // Store the image analysis in the message so it can be displayed
              setCurrentConversation((prev) => {
                const lastIdx = prev.messages.length - 1;
                const messages = prev.messages.map((msg, idx) =>
                  idx === lastIdx
                    ? { ...msg, imageAnalysis: event.analysis }
                    : msg
                );
                return { ...prev, messages };
              });
            }
            break;

          default:
            console.log('Unknown event type:', eventType);
        }
      }, {
        businessId: effectiveBusinessId,
        department: effectiveDepartment,
        role: selectedRole,
        projectId: selectedProject,
        attachmentIds: attachmentIds,  // Pass uploaded image attachment IDs
        signal: abortControllerRef.current?.signal,
      });
    } catch (error) {
      // Don't treat cancellation as an error
      if (error.name === 'AbortError') {
        console.log('Request was cancelled');
        setIsLoading(false);
        return;
      }
      console.error('Failed to send message:', error);
      // Remove optimistic messages on error
      setCurrentConversation((prev) => ({
        ...prev,
        messages: prev.messages.slice(0, -2),
      }));
      setIsLoading(false);
    } finally {
      abortControllerRef.current = null;
    }
  };

  // Handle chat mode - send to chairman only (no full council)
  const handleSendChatMessage = async (content) => {
    if (!currentConversationId || currentConversation?.isTemp) return;

    // Create new AbortController for this request
    abortControllerRef.current = new AbortController();
    setIsLoading(true);

    try {
      // Optimistically add user message to UI
      const userMessage = { role: 'user', content };
      setCurrentConversation((prev) => ({
        ...prev,
        messages: [...prev.messages, userMessage],
      }));

      // Create a partial assistant message for chat response
      const assistantMessage = {
        role: 'assistant',
        stage1: [],
        stage2: [],
        stage3: null,
        stage3Streaming: { text: '', complete: false },
        isChat: true, // Mark as chat-only message
        loading: {
          stage1: false,
          stage2: false,
          stage3: true,
        },
      };

      // Add the partial assistant message
      setCurrentConversation((prev) => ({
        ...prev,
        messages: [...prev.messages, assistantMessage],
      }));

      // Build context based on toggles
      const effectiveBusinessId = useCompanyContext ? selectedBusiness : null;
      const effectiveDepartmentId = useDepartmentContext ? selectedDepartment : null;

      await api.sendChatStream(currentConversationId, content, (eventType, event) => {
        switch (eventType) {
          case 'chat_start':
            // Chat stream started
            break;

          case 'chat_token':
            // Append token to streaming text
            setCurrentConversation((prev) => {
              const messages = prev.messages.map((msg, idx) => {
                if (idx !== prev.messages.length - 1) return msg;
                const currentStreaming = msg.stage3Streaming || { text: '', complete: false };
                return {
                  ...msg,
                  stage3Streaming: {
                    ...currentStreaming,
                    text: currentStreaming.text + event.content,
                  },
                };
              });
              return { ...prev, messages };
            });
            break;

          case 'chat_error':
            console.error('Chat error:', event.error);
            break;

          case 'chat_complete':
            setCurrentConversation((prev) => {
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? {
                      ...msg,
                      stage3: { model: event.data.model, response: event.data.content },
                      stage3Streaming: { text: event.data.content, complete: true },
                      loading: { ...msg.loading, stage3: false },
                    }
                  : msg
              );
              return { ...prev, messages };
            });
            break;

          case 'complete':
            setIsLoading(false);
            break;

          case 'error':
            console.error('Chat stream error:', event.message);
            setCurrentConversation((prev) => {
              const messages = prev.messages.map((msg, idx) =>
                idx === prev.messages.length - 1
                  ? {
                      ...msg,
                      loading: { stage1: false, stage2: false, stage3: false },
                    }
                  : msg
              );
              return { ...prev, messages };
            });
            setIsLoading(false);
            break;

          case 'cancelled':
            console.log('Chat request cancelled');
            setIsLoading(false);
            break;

          default:
            console.log('Unknown chat event type:', eventType);
        }
      }, {
        businessId: effectiveBusinessId,
        departmentId: effectiveDepartmentId,
        projectId: selectedProject,
        signal: abortControllerRef.current?.signal,
      });
    } catch (error) {
      if (error.name === 'AbortError') {
        console.log('Chat request was cancelled');
        setIsLoading(false);
        return;
      }
      console.error('Failed to send chat message:', error);
      // Remove optimistic messages on error
      setCurrentConversation((prev) => ({
        ...prev,
        messages: prev.messages.slice(0, -2),
      }));
      setIsLoading(false);
    } finally {
      abortControllerRef.current = null;
    }
  };

  return (
    <motion.div
      className="app-wrapper"
      initial={{ opacity: 0 }}
      animate={{ opacity: 1 }}
      transition={{ duration: 0.5, ease: "easeOut" }}
    >
      <div className="beta-banner">
        BETA - You're testing an early version. Feedback welcome!
      </div>
      <div className="app">
        <Sidebar
          conversations={conversations}
          currentConversationId={currentConversationId}
          onSelectConversation={handleSelectConversation}
          onNewConversation={handleNewConversation}
          onOpenLeaderboard={() => setIsLeaderboardOpen(true)}
          onOpenSettings={() => setIsSettingsOpen(true)}
          onOpenMyCompany={() => {
            // Clear return-to-company state - user is opening it fresh
            setReturnToMyCompanyTab(null);
            setMyCompanyPromoteDecision(null);
            setIsMyCompanyOpen(true);
          }}
          onArchiveConversation={handleArchiveConversation}
          onStarConversation={handleStarConversation}
          onDeleteConversation={handleDeleteConversation}
          onBulkDeleteConversations={handleBulkDeleteConversations}
          onRenameConversation={handleRenameConversation}
          onLoadMore={handleLoadMoreConversations}
          onSearch={handleSearchConversations}
          hasMoreConversations={hasMoreConversations}
          departments={availableDepartments}
          user={user}
          onSignOut={signOut}
          sortBy={conversationSortBy}
          onSortByChange={(newSort) => {
            setConversationSortBy(newSort);
            loadConversations({ sortBy: newSort, offset: 0 });
          }}
        />
      <ChatInterface
        conversation={currentConversation}
        onSendMessage={handleSendMessage}
        onSendChatMessage={handleSendChatMessage}
        onStopGeneration={handleStopGeneration}
        isLoading={isLoading}
        businesses={businesses}
        selectedBusiness={selectedBusiness}
        onSelectBusiness={setSelectedBusiness}
        departments={availableDepartments}
        selectedDepartment={selectedDepartment}
        onSelectDepartment={setSelectedDepartment}
        roles={availableRoles}
        selectedRole={selectedRole}
        onSelectRole={setSelectedRole}
        channels={availableChannels}
        selectedChannel={selectedChannel}
        onSelectChannel={setSelectedChannel}
        styles={availableStyles}
        selectedStyle={selectedStyle}
        onSelectStyle={setSelectedStyle}
        // Projects
        projects={projects}
        selectedProject={selectedProject}
        onSelectProject={(projectId) => {
          setSelectedProject(projectId);
          // Touch project to update last_accessed_at for sorting
          if (projectId) {
            api.touchProject(projectId).catch(err => {
              console.error('Failed to touch project:', err);
            });
          }
        }}
        onOpenProjectModal={() => setIsProjectModalOpen(true)}
        onProjectCreated={(newProject) => {
          // Add to projects list so it appears in dropdown immediately
          setProjects((prev) => [...prev, newProject]);
        }}
        // Independent context toggles
        useCompanyContext={useCompanyContext}
        onToggleCompanyContext={setUseCompanyContext}
        useDepartmentContext={useDepartmentContext}
        onToggleDepartmentContext={setUseDepartmentContext}
        // Triage props
        triageState={triageState}
        originalQuestion={originalQuery}
        isTriageLoading={isTriageLoading}
        onTriageRespond={handleTriageRespond}
        onTriageSkip={handleTriageSkip}
        onTriageProceed={handleTriageProceed}
        // Upload progress
        isUploading={isUploading}
        // Knowledge Base navigation (now part of My Company)
        onViewKnowledgeBase={() => {
          // Clear return-to-company state - user is opening it fresh
          setReturnToMyCompanyTab(null);
          setMyCompanyPromoteDecision(null);
          setIsMyCompanyOpen(true);
        }}
        // Scroll target - for navigating from decision source
        scrollToStage3={scrollToStage3}
        onScrollToStage3Complete={() => setScrollToStage3(false)}
        // Decision/Playbook navigation - open My Company to appropriate tab
        onViewDecision={(decisionId, type = 'decision', playbookId = null) => {
          // Clear return-to-company state - user is taking a new action
          setReturnToMyCompanyTab(null);
          setMyCompanyPromoteDecision(null);

          if (type === 'playbook' && playbookId) {
            setMyCompanyInitialTab('playbooks');
            setMyCompanyInitialPlaybookId(playbookId);
            setMyCompanyInitialDecisionId(null);
          } else {
            setMyCompanyInitialTab('decisions');
            setMyCompanyInitialDecisionId(decisionId);
            setMyCompanyInitialPlaybookId(null);
          }
          setIsMyCompanyOpen(true);
        }}
        // Return to My Company button (after navigating from source)
        returnToMyCompanyTab={returnToMyCompanyTab}
        returnPromoteDecision={myCompanyPromoteDecision}
        onReturnToMyCompany={(tab) => {
          setReturnToMyCompanyTab(null); // Clear the return state
          setMyCompanyInitialTab(tab);
          setMyCompanyInitialDecisionId(null);
          setMyCompanyInitialPlaybookId(null);
          // Don't clear myCompanyPromoteDecision here - let MyCompany use it to re-open modal
          setIsMyCompanyOpen(true);
        }}
      />
      <Leaderboard
        isOpen={isLeaderboardOpen}
        onClose={() => setIsLeaderboardOpen(false)}
      />
      <Settings
        isOpen={isSettingsOpen}
        onClose={() => setIsSettingsOpen(false)}
      />
      {isProjectModalOpen && selectedBusiness && (
        <ProjectModal
          companyId={selectedBusiness}
          onClose={() => setIsProjectModalOpen(false)}
          onProjectCreated={(newProject) => {
            // Add to projects list and select it
            setProjects((prev) => [...prev, newProject]);
            setSelectedProject(newProject.id);
          }}
        />
      )}
      {isMyCompanyOpen && selectedBusiness && (
        <MyCompany
          companyId={selectedBusiness}
          companyName={currentBusiness?.name}
          allCompanies={businesses}
          onSelectCompany={(newCompanyId) => {
            setSelectedBusiness(newCompanyId);
            // Reset to Overview tab when switching companies
            setMyCompanyInitialTab('overview');
            setMyCompanyInitialDecisionId(null);
            setMyCompanyInitialPlaybookId(null);
          }}
          onClose={() => {
            setIsMyCompanyOpen(false);
            // Reset to defaults for next open
            setMyCompanyInitialTab('overview');
            setMyCompanyInitialDecisionId(null);
            setMyCompanyInitialPlaybookId(null);
            setMyCompanyPromoteDecision(null);
          }}
          onNavigateToConversation={(conversationId, fromTab, promoteDecision = null) => {
            setIsMyCompanyOpen(false);
            setScrollToStage3(true); // Scroll to Stage 3 when coming from decision source
            setReturnToMyCompanyTab(fromTab || null); // Remember which tab to return to
            setMyCompanyPromoteDecision(promoteDecision); // Remember decision to re-open Promote modal
            setCurrentConversationId(conversationId);
          }}
          initialTab={myCompanyInitialTab}
          initialDecisionId={myCompanyInitialDecisionId}
          initialPlaybookId={myCompanyInitialPlaybookId}
          initialPromoteDecision={myCompanyPromoteDecision}
          onConsumePromoteDecision={() => setMyCompanyPromoteDecision(null)}
        />
      )}
      </div>
    </motion.div>
  );
}

export default App;

```

### File: frontend/src/api.js
```js
/**
 * API client for the AI Council backend.
 */

const API_BASE = import.meta.env.VITE_API_URL || 'http://localhost:8080';

// Token getter function - set by the app to provide auth tokens
let getAccessToken = null;

/**
 * Set the function that retrieves the access token.
 * @param {function} getter - Async function that returns the access token
 */
export const setTokenGetter = (getter) => {
  getAccessToken = getter;
};

/**
 * Get headers including Authorization if token is available.
 */
const getAuthHeaders = async () => {
  const headers = {
    'Content-Type': 'application/json',
  };
  if (getAccessToken) {
    const token = await getAccessToken();
    if (token) {
      headers['Authorization'] = `Bearer ${token}`;
    }
  }
  return headers;
};

export const api = {
  /**
   * List all available business contexts.
   */
  async listBusinesses() {
    const response = await fetch(`${API_BASE}/api/businesses`);
    if (!response.ok) {
      throw new Error('Failed to list businesses');
    }
    return response.json();
  },

  /**
   * List conversations for the authenticated user with pagination and search.
   * Returns { conversations: [...], has_more: bool }
   *
   * @param {Object} options - Query options
   * @param {number} options.limit - Max conversations to return (default 20)
   * @param {number} options.offset - Number to skip for pagination (default 0)
   * @param {string} options.search - Optional search string for title filtering
   * @param {boolean} options.includeArchived - Include archived conversations (default false)
   * @param {string} options.sortBy - Sort order: "date" (most recent first) or "activity" (most messages first)
   */
  async listConversations({ limit = 20, offset = 0, search = '', includeArchived = false, sortBy = 'date' } = {}) {
    const headers = await getAuthHeaders();
    const params = new URLSearchParams();
    params.set('limit', limit.toString());
    params.set('offset', offset.toString());
    params.set('sort_by', sortBy);
    if (search) {
      params.set('search', search);
    }
    if (includeArchived) {
      params.set('include_archived', 'true');
    }
    const response = await fetch(`${API_BASE}/api/conversations?${params}`, { headers });
    if (!response.ok) {
      throw new Error('Failed to list conversations');
    }
    return response.json();
  },

  /**
   * Star or unstar a conversation.
   * Starred conversations appear at the top of the list.
   *
   * @param {string} conversationId - ID of the conversation
   * @param {boolean} starred - True to star, false to unstar
   */
  async starConversation(conversationId, starred = true) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/star`,
      {
        method: 'POST',
        headers,
        body: JSON.stringify({ starred }),
      }
    );
    if (!response.ok) {
      throw new Error('Failed to star conversation');
    }
    return response.json();
  },

  /**
   * Create a new conversation.
   */
  async createConversation() {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/conversations`, {
      method: 'POST',
      headers,
      body: JSON.stringify({}),
    });
    if (!response.ok) {
      throw new Error('Failed to create conversation');
    }
    return response.json();
  },

  /**
   * Get a specific conversation.
   */
  async getConversation(conversationId) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}`,
      { headers }
    );
    if (!response.ok) {
      throw new Error('Failed to get conversation');
    }
    return response.json();
  },

  /**
   * Send a message in a conversation.
   * @param {string} conversationId - The conversation ID
   * @param {string} content - The message content
   * @param {string|null} businessId - Optional business context ID
   */
  async sendMessage(conversationId, content, businessId = null) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/message`,
      {
        method: 'POST',
        headers,
        body: JSON.stringify({ content, business_id: businessId }),
      }
    );
    if (!response.ok) {
      throw new Error('Failed to send message');
    }
    return response.json();
  },

  /**
   * Send a message and receive streaming updates.
   * @param {string} conversationId - The conversation ID
   * @param {string} content - The message content
   * @param {function} onEvent - Callback function for each event: (eventType, data) => void
   * @param {object} options - Context options
   * @param {string|null} options.businessId - Optional business context ID
   * @param {string|null} options.department - Optional department for leaderboard tracking
   * @param {string|null} options.role - Optional role for persona injection (e.g., 'cto', 'head-of-ai-people-culture')
   * @param {string|null} options.projectId - Optional project ID for project-specific context
   * @param {string[]|null} options.attachmentIds - Optional list of attachment IDs (images to analyze)
   * @param {AbortSignal} options.signal - Optional AbortSignal for cancellation
   * @returns {Promise<void>}
   */
  async sendMessageStream(conversationId, content, onEvent, options = {}) {
    const { businessId = null, department = 'standard', role = null, projectId = null, attachmentIds = null, signal = null } = options;
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/message/stream`,
      {
        method: 'POST',
        headers,
        body: JSON.stringify({
          content,
          business_id: businessId,
          department,
          role,
          project_id: projectId,
          attachment_ids: attachmentIds,
        }),
        signal, // Allow cancellation
      }
    );

    if (!response.ok) {
      throw new Error('Failed to send message');
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let buffer = ''; // Buffer for incomplete SSE events

    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) {
          break;
        }

        const chunk = decoder.decode(value, { stream: true });
        buffer += chunk;

        // Process complete SSE events (separated by double newlines)
        while (buffer.includes('\n\n')) {
          const eventEnd = buffer.indexOf('\n\n');
          const eventText = buffer.slice(0, eventEnd);
          buffer = buffer.slice(eventEnd + 2);

          // Parse the SSE event
          for (const line of eventText.split('\n')) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              try {
                const event = JSON.parse(data);
                onEvent(event.type, event);
              } catch (e) {
                console.error('Failed to parse SSE event:', e);
              }
            }
          }
        }
      }
    } catch (e) {
      if (e.name === 'AbortError') {
        onEvent('cancelled', { message: 'Request was cancelled' });
      } else {
        throw e;
      }
    }
  },

  /**
   * Send a chat message (Chairman only, no full council deliberation).
   * Used for follow-up questions after council response.
   * @param {string} conversationId - The conversation ID
   * @param {string} content - The message content
   * @param {function} onEvent - Callback function for each event: (eventType, data) => void
   * @param {object} options - Context options
   * @param {string|null} options.businessId - Optional business context ID
   * @param {string|null} options.departmentId - Optional department context ID
   * @param {string|null} options.projectId - Optional project ID for project-specific context
   * @param {AbortSignal} options.signal - Optional AbortSignal for cancellation
   * @returns {Promise<void>}
   */
  async sendChatStream(conversationId, content, onEvent, options = {}) {
    const { businessId = null, departmentId = null, projectId = null, signal = null } = options;
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/chat/stream`,
      {
        method: 'POST',
        headers,
        body: JSON.stringify({
          content,
          business_id: businessId,
          department_id: departmentId,
          project_id: projectId,
        }),
        signal,
      }
    );

    if (!response.ok) {
      throw new Error('Failed to send chat message');
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let buffer = '';

    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });

        // Process complete SSE events
        while (buffer.includes('\n\n')) {
          const eventEnd = buffer.indexOf('\n\n');
          const eventText = buffer.slice(0, eventEnd);
          buffer = buffer.slice(eventEnd + 2);

          for (const line of eventText.split('\n')) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              try {
                const event = JSON.parse(data);
                onEvent(event.type, event);
              } catch (e) {
                console.error('Failed to parse SSE event:', e);
              }
            }
          }
        }
      }
    } catch (e) {
      if (e.name === 'AbortError') {
        onEvent('cancelled', { message: 'Request was cancelled' });
      } else {
        throw e;
      }
    }
  },

  /**
   * Get leaderboard summary (overall + all departments).
   */
  async getLeaderboardSummary() {
    const response = await fetch(`${API_BASE}/api/leaderboard`);
    if (!response.ok) {
      throw new Error('Failed to get leaderboard');
    }
    return response.json();
  },

  /**
   * Get overall leaderboard.
   */
  async getOverallLeaderboard() {
    const response = await fetch(`${API_BASE}/api/leaderboard/overall`);
    if (!response.ok) {
      throw new Error('Failed to get overall leaderboard');
    }
    return response.json();
  },

  /**
   * Get department-specific leaderboard.
   * @param {string} department - The department name
   */
  async getDepartmentLeaderboard(department) {
    const response = await fetch(`${API_BASE}/api/leaderboard/department/${department}`);
    if (!response.ok) {
      throw new Error('Failed to get department leaderboard');
    }
    return response.json();
  },

  /**
   * Analyze a question for triage (check for 4 constraints).
   * @param {string} content - The user's question
   * @param {string|null} businessId - Optional business context ID
   * @returns {Promise<{ready: boolean, constraints: object, missing: string[], questions: string|null, enhanced_query: string}>}
   */
  async analyzeTriage(content, businessId = null) {
    const response = await fetch(`${API_BASE}/api/triage/analyze`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ content, business_id: businessId }),
    });
    if (!response.ok) {
      throw new Error('Failed to analyze triage');
    }
    return response.json();
  },

  /**
   * Continue triage conversation with additional user info.
   * @param {string} originalQuery - The original question
   * @param {object} previousConstraints - Previously extracted constraints
   * @param {string} userResponse - User's response to triage questions
   * @param {string|null} businessId - Optional business context ID
   * @returns {Promise<{ready: boolean, constraints: object, missing: string[], questions: string|null, enhanced_query: string}>}
   */
  async continueTriage(originalQuery, previousConstraints, userResponse, businessId = null) {
    const response = await fetch(`${API_BASE}/api/triage/continue`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        original_query: originalQuery,
        previous_constraints: previousConstraints,
        user_response: userResponse,
        business_id: businessId,
      }),
    });
    if (!response.ok) {
      throw new Error('Failed to continue triage');
    }
    return response.json();
  },

  /**
   * Export a conversation as Markdown file.
   * @param {string} conversationId - The conversation ID
   * @returns {Promise<void>} - Triggers a file download
   */
  async exportConversation(conversationId) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/export`,
      { headers }
    );
    if (!response.ok) {
      throw new Error('Failed to export conversation');
    }

    // Get the filename from Content-Disposition header
    const contentDisposition = response.headers.get('Content-Disposition');
    let filename = 'conversation.md';
    if (contentDisposition) {
      const match = contentDisposition.match(/filename="(.+)"/);
      if (match) {
        filename = match[1];
      }
    }

    // Download the file
    const blob = await response.blob();
    const url = window.URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = filename;
    document.body.appendChild(a);
    a.click();
    window.URL.revokeObjectURL(url);
    document.body.removeChild(a);
  },

  /**
   * Rename a conversation.
   * @param {string} conversationId - The conversation ID
   * @param {string} title - The new title
   */
  async renameConversation(conversationId, title) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/rename`,
      {
        method: 'PATCH',
        headers,
        body: JSON.stringify({ title }),
      }
    );
    if (!response.ok) {
      throw new Error('Failed to rename conversation');
    }
    return response.json();
  },

  /**
   * Archive or unarchive a conversation.
   * @param {string} conversationId - The conversation ID
   * @param {boolean} archived - True to archive, false to unarchive
   */
  async archiveConversation(conversationId, archived = true) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/archive`,
      {
        method: 'POST',
        headers,
        body: JSON.stringify({ archived }),
      }
    );
    if (!response.ok) {
      throw new Error('Failed to archive conversation');
    }
    return response.json();
  },

  /**
   * Permanently delete a conversation.
   * @param {string} conversationId - The conversation ID
   */
  async deleteConversation(conversationId) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}`,
      {
        method: 'DELETE',
        headers,
      }
    );
    if (!response.ok) {
      throw new Error('Failed to delete conversation');
    }
    return response.json();
  },

  /**
   * Bulk delete multiple conversations.
   * @param {string[]} conversationIds - Array of conversation IDs to delete
   * @returns {Promise<{deleted: string[], failed: Array, deleted_count: number}>}
   */
  async bulkDeleteConversations(conversationIds) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/bulk-delete`,
      {
        method: 'POST',
        headers,
        body: JSON.stringify({ conversation_ids: conversationIds }),
      }
    );
    if (!response.ok) {
      throw new Error('Failed to bulk delete conversations');
    }
    return response.json();
  },

  /**
   * Analyze a conversation for potential knowledge base updates.
   * @param {string} conversationId - The conversation ID
   * @param {string} businessId - The business context ID
   * @param {string|null} departmentId - Optional department ID
   * @returns {Promise<{suggestions: Array, summary: string, analyzed_at: string}>}
   */
  async curateConversation(conversationId, businessId, departmentId = null) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/curate`,
      {
        method: 'POST',
        headers,
        body: JSON.stringify({
          business_id: businessId,
          department_id: departmentId,
        }),
      }
    );
    if (!response.ok) {
      throw new Error('Failed to analyze conversation');
    }
    return response.json();
  },

  /**
   * Apply a suggestion to update the business context.
   * @param {string} businessId - The business context ID
   * @param {object} suggestion - The suggestion object to apply
   * @returns {Promise<{success: boolean, message: string, updated_at: string}>}
   */
  async applySuggestion(businessId, suggestion) {
    const response = await fetch(`${API_BASE}/api/context/apply-suggestion`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        business_id: businessId,
        suggestion: suggestion,
      }),
    });
    if (!response.ok) {
      throw new Error('Failed to apply suggestion');
    }
    return response.json();
  },

  /**
   * Get a specific section from the business context.
   * @param {string} businessId - The business context ID
   * @param {string} sectionName - The section name to retrieve
   * @param {string|null} department - Optional department ID to look in department context
   * @returns {Promise<{section: string, content: string, exists: boolean}>}
   */
  async getContextSection(businessId, sectionName, department = null) {
    let url = `${API_BASE}/api/context/${businessId}/section/${encodeURIComponent(sectionName)}`;
    if (department && department !== 'company') {
      url += `?department=${encodeURIComponent(department)}`;
    }
    const response = await fetch(url);
    if (!response.ok) {
      throw new Error('Failed to get context section');
    }
    return response.json();
  },

  /**
   * Save a record that the curator was run on this conversation.
   * @param {string} conversationId - The conversation ID
   * @param {string} businessId - The business context ID
   * @param {number} suggestionsCount - Total suggestions generated
   * @param {number} acceptedCount - Number of suggestions accepted
   * @param {number} rejectedCount - Number of suggestions rejected
   * @returns {Promise<{success: boolean}>}
   */
  async saveCuratorRun(conversationId, businessId, suggestionsCount, acceptedCount, rejectedCount) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/curator-history`,
      {
        method: 'POST',
        headers,
        body: JSON.stringify({
          business_id: businessId,
          suggestions_count: suggestionsCount,
          accepted_count: acceptedCount,
          rejected_count: rejectedCount,
        }),
      }
    );
    if (!response.ok) {
      throw new Error('Failed to save curator run');
    }
    return response.json();
  },

  /**
   * Get curator run history for a conversation.
   * @param {string} conversationId - The conversation ID
   * @returns {Promise<{history: Array}>}
   */
  async getCuratorHistory(conversationId) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/curator-history`,
      { headers }
    );
    if (!response.ok) {
      throw new Error('Failed to get curator history');
    }
    return response.json();
  },

  /**
   * Get current mock mode status.
   * @returns {Promise<{enabled: boolean, scenario: string}>}
   */
  async getMockMode() {
    const response = await fetch(`${API_BASE}/api/settings/mock-mode`);
    if (!response.ok) {
      throw new Error('Failed to get mock mode status');
    }
    return response.json();
  },

  /**
   * Toggle mock mode on/off.
   * @param {boolean} enabled - Whether to enable mock mode
   * @returns {Promise<{success: boolean, enabled: boolean, message: string}>}
   */
  async setMockMode(enabled) {
    const response = await fetch(`${API_BASE}/api/settings/mock-mode`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ enabled }),
    });
    if (!response.ok) {
      throw new Error('Failed to set mock mode');
    }
    return response.json();
  },

  /**
   * Get current prompt caching status.
   * @returns {Promise<{enabled: boolean, supported_models: string[]}>}
   */
  async getCachingMode() {
    const response = await fetch(`${API_BASE}/api/settings/caching-mode`);
    if (!response.ok) {
      throw new Error('Failed to get caching mode status');
    }
    return response.json();
  },

  /**
   * Toggle prompt caching on/off.
   * @param {boolean} enabled - Whether to enable prompt caching
   * @returns {Promise<{success: boolean, enabled: boolean, message: string}>}
   */
  async setCachingMode(enabled) {
    const response = await fetch(`${API_BASE}/api/settings/caching-mode`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ enabled }),
    });
    if (!response.ok) {
      throw new Error('Failed to set caching mode');
    }
    return response.json();
  },

  /**
   * Get the last updated date from a business context file.
   * @param {string} businessId - The business context ID
   * @returns {Promise<{last_updated: string|null}>}
   */
  async getContextLastUpdated(businessId) {
    const response = await fetch(
      `${API_BASE}/api/context/${businessId}/last-updated`
    );
    if (!response.ok) {
      throw new Error('Failed to get context last updated');
    }
    return response.json();
  },

  /**
   * Create a new department for a business.
   * This scaffolds the department folder structure and creates an initial context file.
   * @param {string} businessId - The business context ID
   * @param {object} department - The department to create
   * @param {string} department.id - The department ID (lowercase, hyphenated)
   * @param {string} department.name - The display name for the department
   * @returns {Promise<{success: boolean, department_id: string, message: string}>}
   */
  async createDepartment(businessId, department) {
    const response = await fetch(
      `${API_BASE}/api/businesses/${businessId}/departments`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(department),
      }
    );
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to create department' }));
      throw new Error(error.detail || 'Failed to create department');
    }
    return response.json();
  },

  /**
   * Update a department's name and/or description.
   * @param {string} businessId - The business context ID
   * @param {string} departmentId - The department ID to update
   * @param {object} updates - Fields to update
   * @param {string} updates.name - New name (optional)
   * @param {string} updates.description - New description (optional)
   * @returns {Promise<{success: boolean, message: string}>}
   */
  async updateDepartment(businessId, departmentId, updates) {
    const response = await fetch(
      `${API_BASE}/api/businesses/${businessId}/departments/${departmentId}`,
      {
        method: 'PUT',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(updates),
      }
    );
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to update department' }));
      throw new Error(error.detail || 'Failed to update department');
    }
    return response.json();
  },

  /**
   * Add a new role to a department.
   * @param {string} businessId - The business context ID
   * @param {string} departmentId - The department to add the role to
   * @param {object} role - The role to create
   * @param {string} role.role_id - The role ID (lowercase, hyphenated)
   * @param {string} role.role_name - The display name for the role
   * @param {string} role.role_description - Optional description
   * @returns {Promise<{success: boolean, message: string, role: object}>}
   */
  async addRole(businessId, departmentId, role) {
    const response = await fetch(
      `${API_BASE}/api/businesses/${businessId}/departments/${departmentId}/roles`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(role),
      }
    );
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to add role' }));
      throw new Error(error.detail || 'Failed to add role');
    }
    return response.json();
  },

  /**
   * Update a role's name and/or description.
   * @param {string} businessId - The business context ID
   * @param {string} departmentId - The department the role belongs to
   * @param {string} roleId - The role ID to update
   * @param {object} updates - Fields to update
   * @param {string} updates.name - New name (optional)
   * @param {string} updates.description - New description (optional)
   * @returns {Promise<{success: boolean, message: string}>}
   */
  async updateRole(businessId, departmentId, roleId, updates) {
    const response = await fetch(
      `${API_BASE}/api/businesses/${businessId}/departments/${departmentId}/roles/${roleId}`,
      {
        method: 'PUT',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(updates),
      }
    );
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to update role' }));
      throw new Error(error.detail || 'Failed to update role');
    }
    return response.json();
  },

  /**
   * Get the system prompt/context for a specific role.
   * @param {string} businessId - The business context ID
   * @param {string} departmentId - The department ID
   * @param {string} roleId - The role ID
   * @returns {Promise<{context: string|null, exists: boolean, path: string}>}
   */
  async getRoleContext(businessId, departmentId, roleId) {
    const response = await fetch(
      `${API_BASE}/api/businesses/${businessId}/departments/${departmentId}/roles/${roleId}/context`
    );
    if (!response.ok) {
      throw new Error('Failed to get role context');
    }
    return response.json();
  },

  // ============ Projects API ============

  /**
   * List all projects for a company.
   * @param {string} companyId - The company ID
   * @returns {Promise<{projects: Array}>}
   */
  async listProjects(companyId) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/companies/${companyId}/projects`,
      { headers }
    );
    if (!response.ok) {
      throw new Error('Failed to list projects');
    }
    return response.json();
  },

  /**
   * Create a new project for a company.
   * @param {string} companyId - The company ID
   * @param {object} project - The project data
   * @param {string} project.name - Project name
   * @param {string} project.description - Optional description
   * @param {string} project.context_md - Optional markdown context
   * @returns {Promise<{project: object}>}
   */
  async createProject(companyId, project) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/companies/${companyId}/projects`,
      {
        method: 'POST',
        headers,
        body: JSON.stringify(project),
      }
    );
    if (!response.ok) {
      throw new Error('Failed to create project');
    }
    return response.json();
  },

  /**
   * Get a specific project.
   * @param {string} projectId - The project ID
   * @returns {Promise<{project: object}>}
   */
  async getProject(projectId) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/projects/${projectId}`,
      { headers }
    );
    if (!response.ok) {
      throw new Error('Failed to get project');
    }
    return response.json();
  },

  /**
   * Update a project.
   * @param {string} projectId - The project ID
   * @param {object} updates - Fields to update (name, description, context_md, status)
   * @returns {Promise<{project: object}>}
   */
  async updateProject(projectId, updates) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/projects/${projectId}`,
      {
        method: 'PATCH',
        headers,
        body: JSON.stringify(updates),
      }
    );
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to update project' }));
      throw new Error(error.detail || 'Failed to update project');
    }
    return response.json();
  },

  /**
   * Touch a project's last_accessed_at timestamp (when selected in chat).
   * @param {string} projectId - The project ID
   * @returns {Promise<{success: boolean}>}
   */
  async touchProject(projectId) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/projects/${projectId}/touch`,
      {
        method: 'POST',
        headers,
      }
    );
    if (!response.ok) {
      throw new Error('Failed to touch project');
    }
    return response.json();
  },

  /**
   * List projects with stats for Command Centre.
   * @param {string} companyId - The company ID
   * @param {object} options - Optional filters
   * @param {string} options.status - Filter by status ('active', 'completed', 'archived')
   * @param {boolean} options.includeArchived - Include archived projects
   * @returns {Promise<{projects: Array}>}
   */
  async listProjectsWithStats(companyId, options = {}) {
    const headers = await getAuthHeaders();
    const params = new URLSearchParams();
    if (options.status) params.append('status', options.status);
    if (options.includeArchived) params.append('include_archived', 'true');

    const url = `${API_BASE}/api/companies/${companyId}/projects/stats${params.toString() ? '?' + params.toString() : ''}`;
    const response = await fetch(url, { headers });
    if (!response.ok) {
      throw new Error('Failed to list projects with stats');
    }
    return response.json();
  },

  // ============ Utils API ============

  /**
   * Polish/rewrite text using AI.
   * @param {string} text - The text to polish
   * @param {string} fieldType - The field type for context (client_background, goals, constraints, additional)
   * @returns {Promise<{polished: string}>}
   */
  async polishText(text, fieldType) {
    const headers = await getAuthHeaders();
    const response = await fetch(
      `${API_BASE}/api/utils/polish-text`,
      {
        method: 'POST',
        headers,
        body: JSON.stringify({ text, field_type: fieldType }),
      }
    );
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to polish text' }));
      throw new Error(error.detail || 'Failed to polish text');
    }
    return response.json();
  },

  // ============ Billing API ============

  // ============================================
  // PROFILE METHODS
  // ============================================

  /**
   * Get current user's profile.
   * @returns {Promise<{display_name: string, company: string, phone: string, bio: string}>}
   */
  async getProfile() {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/profile`, {
      headers,
    });
    if (!response.ok) {
      throw new Error('Failed to get profile');
    }
    return response.json();
  },

  /**
   * Update current user's profile.
   * @param {Object} profile - Profile data
   * @param {string} profile.display_name - Display name
   * @param {string} profile.company - Company name
   * @param {string} profile.phone - Phone number
   * @param {string} profile.bio - Bio/description
   * @returns {Promise<{success: boolean, profile: Object}>}
   */
  async updateProfile(profile) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/profile`, {
      method: 'PUT',
      headers,
      body: JSON.stringify(profile),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to update profile' }));
      throw new Error(error.detail || 'Failed to update profile');
    }
    return response.json();
  },

  // ============================================
  // BILLING METHODS
  // ============================================

  /**
   * Get available subscription plans.
   * @returns {Promise<Array>} List of available plans
   */
  async getBillingPlans() {
    const response = await fetch(`${API_BASE}/api/billing/plans`);
    if (!response.ok) {
      throw new Error('Failed to get billing plans');
    }
    return response.json();
  },

  /**
   * Get current user's subscription status.
   * @returns {Promise<{tier: string, status: string, queries_used: number, queries_limit: number, period_end: string|null, features: string[]}>}
   */
  async getSubscription() {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/billing/subscription`, {
      headers,
    });
    if (!response.ok) {
      throw new Error('Failed to get subscription');
    }
    return response.json();
  },

  /**
   * Check if user can make a council query.
   * @returns {Promise<{can_query: boolean, reason: string|null, remaining: number}>}
   */
  async canQuery() {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/billing/can-query`, {
      headers,
    });
    if (!response.ok) {
      throw new Error('Failed to check query permission');
    }
    return response.json();
  },

  /**
   * Create a Stripe Checkout session for subscribing to a plan.
   * @param {string} tierId - The tier to subscribe to (pro, enterprise)
   * @returns {Promise<{checkout_url: string, session_id: string}>}
   */
  async createCheckout(tierId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/billing/checkout`, {
      method: 'POST',
      headers,
      body: JSON.stringify({
        tier_id: tierId,
        success_url: `${window.location.origin}/?billing=success`,
        cancel_url: `${window.location.origin}/?billing=cancelled`,
      }),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to create checkout' }));
      throw new Error(error.detail || 'Failed to create checkout');
    }
    return response.json();
  },

  /**
   * Create a Stripe Billing Portal session for managing subscription.
   * @returns {Promise<{portal_url: string}>}
   */
  async createBillingPortal() {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/billing/portal`, {
      method: 'POST',
      headers,
      body: JSON.stringify({
        return_url: window.location.origin,
      }),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to create portal' }));
      throw new Error(error.detail || 'Failed to create portal');
    }
    return response.json();
  },

  // ============================================
  // ATTACHMENTS METHODS
  // ============================================

  /**
   * Upload an image attachment.
   * @param {File} file - The image file to upload
   * @param {string|null} conversationId - Optional conversation ID to link to
   * @param {number|null} messageIndex - Optional message index within the conversation
   * @returns {Promise<{id: string, file_name: string, file_type: string, file_size: number, storage_path: string, signed_url: string}>}
   */
  async uploadAttachment(file, conversationId = null, messageIndex = null) {
    const token = getAccessToken ? await getAccessToken() : null;

    const formData = new FormData();
    formData.append('file', file);
    if (conversationId) {
      formData.append('conversation_id', conversationId);
    }
    if (messageIndex !== null) {
      formData.append('message_index', messageIndex.toString());
    }

    const response = await fetch(`${API_BASE}/api/attachments/upload`, {
      method: 'POST',
      headers: token ? { 'Authorization': `Bearer ${token}` } : {},
      body: formData,
    });

    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to upload attachment' }));
      throw new Error(error.detail || 'Failed to upload attachment');
    }
    return response.json();
  },

  /**
   * Get attachment metadata and a fresh signed URL.
   * @param {string} attachmentId - The attachment ID
   * @returns {Promise<{id: string, file_name: string, file_type: string, file_size: number, storage_path: string, signed_url: string}>}
   */
  async getAttachment(attachmentId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/attachments/${attachmentId}`, { headers });
    if (!response.ok) {
      throw new Error('Failed to get attachment');
    }
    return response.json();
  },

  /**
   * Get a fresh signed URL for an attachment.
   * @param {string} attachmentId - The attachment ID
   * @returns {Promise<{signed_url: string}>}
   */
  async getAttachmentUrl(attachmentId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/attachments/${attachmentId}/url`, { headers });
    if (!response.ok) {
      throw new Error('Failed to get attachment URL');
    }
    return response.json();
  },

  /**
   * Delete an attachment.
   * @param {string} attachmentId - The attachment ID
   * @returns {Promise<{success: boolean}>}
   */
  async deleteAttachment(attachmentId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/attachments/${attachmentId}`, {
      method: 'DELETE',
      headers,
    });
    if (!response.ok) {
      throw new Error('Failed to delete attachment');
    }
    return response.json();
  },

  // ============================================
  // KNOWLEDGE BASE METHODS
  // ============================================

  /**
   * Save a knowledge entry to the database.
   * @param {Object} entry - Knowledge entry to save
   * @param {string} entry.company_id - Company UUID
   * @param {string} entry.title - Title of the knowledge entry
   * @param {string} entry.summary - Summary/content of the entry
   * @param {string} entry.category - Category (technical_decision, ux_pattern, feature, policy, process)
   * @param {string|null} entry.department_id - Optional department UUID
   * @param {string|null} entry.conversation_id - Optional source conversation ID
   * @returns {Promise<{success: boolean, entry: Object}>}
   */
  async createKnowledgeEntry(entry) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/knowledge`, {
      method: 'POST',
      headers,
      body: JSON.stringify(entry),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to save knowledge entry' }));
      throw new Error(error.detail || 'Failed to save knowledge entry');
    }
    return response.json();
  },

  /**
   * Get knowledge entries for a company with filtering options.
   * @param {string} companyId - Company UUID
   * @param {Object} options - Filter options
   * @param {string|null} options.departmentId - Filter by department
   * @param {string|null} options.projectId - Filter by project
   * @param {string|null} options.category - Filter by category
   * @param {string|null} options.status - Filter by status (active, superseded, archived, or empty for all)
   * @param {string|null} options.search - Search term for title/problem/decision
   * @param {number} options.limit - Max entries to return
   * @returns {Promise<{entries: Array}>}
   */
  async getKnowledgeEntries(companyId, options = {}) {
    const headers = await getAuthHeaders();
    const params = new URLSearchParams();
    if (options.departmentId) params.append('department_id', options.departmentId);
    if (options.projectId) params.append('project_id', options.projectId);
    if (options.category) params.append('category', options.category);
    if (options.status !== undefined) params.append('status', options.status || '');
    if (options.search) params.append('search', options.search);
    if (options.limit) params.append('limit', options.limit.toString());

    const url = `${API_BASE}/api/knowledge/${companyId}${params.toString() ? '?' + params.toString() : ''}`;
    const response = await fetch(url, { headers });
    if (!response.ok) {
      throw new Error('Failed to get knowledge entries');
    }
    return response.json();
  },

  /**
   * Update a knowledge entry.
   * @param {string} entryId - Knowledge entry UUID
   * @param {Object} updates - Fields to update
   * @param {string|null} updates.title - New title
   * @param {string|null} updates.category - New category
   * @param {string|null} updates.department_id - New department
   * @param {string|null} updates.problem_statement - New problem statement
   * @param {string|null} updates.decision_text - New decision text
   * @param {string|null} updates.reasoning - New reasoning
   * @param {string|null} updates.status - New status (active, superseded, archived)
   * @param {string|null} updates.body_md - New long-form markdown content
   * @param {string|null} updates.version - New version string
   * @returns {Promise<Object>} Updated entry
   */
  async updateKnowledgeEntry(entryId, updates) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/knowledge/${entryId}`, {
      method: 'PATCH',
      headers,
      body: JSON.stringify(updates),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to update knowledge entry' }));
      throw new Error(error.detail || 'Failed to update knowledge entry');
    }
    return response.json();
  },

  /**
   * Deactivate a knowledge entry (soft delete).
   * @param {string} entryId - Knowledge entry UUID
   * @returns {Promise<{success: boolean}>}
   */
  async deactivateKnowledgeEntry(entryId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/knowledge/${entryId}`, {
      method: 'DELETE',
      headers,
    });
    if (!response.ok) {
      throw new Error('Failed to deactivate knowledge entry');
    }
    return response.json();
  },

  /**
   * Generate a project report with all decisions and recommendations.
   * Returns structured data that can be rendered as HTML/PDF.
   * Client-friendly - no mention of AI Council.
   * @param {string} projectId - Project UUID
   * @returns {Promise<Object>} Report data with:
   *   - project_name: string
   *   - generated_at: ISO timestamp
   *   - entry_count: number
   *   - categories: { [categoryName]: Array<{title, summary, date, department}> }
   *   - timeline: Array<{date, title, category}>
   *   - executive_summary: string
   */
  async getProjectReport(projectId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/projects/${projectId}/report`, { headers });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to generate report' }));
      throw new Error(error.detail || 'Failed to generate report');
    }
    return response.json();
  },

  /**
   * Get count of knowledge entries saved from a specific conversation.
   * @param {string} conversationId - Conversation UUID
   * @param {string} companyId - Company UUID
   * @returns {Promise<{count: number}>}
   */
  async getKnowledgeCountForConversation(conversationId, companyId) {
    const headers = await getAuthHeaders();
    const params = new URLSearchParams({ company_id: companyId });
    const response = await fetch(
      `${API_BASE}/api/conversations/${conversationId}/knowledge-count?${params.toString()}`,
      { headers }
    );
    if (!response.ok) {
      throw new Error('Failed to get knowledge count');
    }
    return response.json();
  },

  /**
   * Extract key decision/recommendation from a council response using AI.
   * This uses an LLM to intelligently extract what's important.
   * @param {string} userQuestion - The original user question
   * @param {string} councilResponse - The Stage 3 chairman synthesis
   * @returns {Promise<{success: boolean, extracted: Object, error: string}>}
   *   - extracted.title: Short descriptive title
   *   - extracted.problem_statement: What problem was addressed
   *   - extracted.decision_text: The key decision/recommendation
   *   - extracted.reasoning: Why this decision was made
   *   - extracted.category: One of technical_decision, ux_pattern, feature, policy, process
   *   - extracted.department: One of technology, ux, marketing, operations, strategy, finance, hr, general
   */
  async extractDecision(userQuestion, councilResponse) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/knowledge/extract`, {
      method: 'POST',
      headers,
      body: JSON.stringify({
        user_question: userQuestion,
        council_response: councilResponse,
      }),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to extract decision' }));
      throw new Error(error.detail || 'Failed to extract decision');
    }
    return response.json();
  },

  /**
   * Extract a clear project name and description from a council response using AI.
   * Designed to be understandable by anyone - like onboarding documentation.
   * @param {string} userQuestion - The original user question
   * @param {string} councilResponse - The Stage 3 chairman synthesis
   * @returns {Promise<{success: boolean, extracted: {name: string, description: string}, error: string}>}
   */
  async extractProject(userQuestion, councilResponse) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/projects/extract`, {
      method: 'POST',
      headers,
      body: JSON.stringify({
        user_question: userQuestion,
        council_response: councilResponse,
      }),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to extract project' }));
      throw new Error(error.detail || 'Failed to extract project');
    }
    return response.json();
  },

  // ============================================
  // MY COMPANY API METHODS
  // ============================================

  /**
   * Get company overview with stats.
   * @param {string} companyId - Company ID (slug or UUID)
   * @returns {Promise<Object>} Company overview with stats
   */
  async getCompanyOverview(companyId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/overview`, { headers });
    if (!response.ok) {
      throw new Error('Failed to get company overview');
    }
    return response.json();
  },

  /**
   * Update company info.
   * @param {string} companyId - Company ID
   * @param {Object} data - Company data to update
   * @returns {Promise<Object>} Updated company
   */
  async updateCompanyOverview(companyId, data) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/overview`, {
      method: 'POST',
      headers,
      body: JSON.stringify(data),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to update company' }));
      throw new Error(error.detail || 'Failed to update company');
    }
    return response.json();
  },

  /**
   * Update company context markdown.
   * @param {string} companyId - Company ID
   * @param {Object} data - {context_md: string}
   * @returns {Promise<Object>} Updated company
   */
  async updateCompanyContext(companyId, data) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/context`, {
      method: 'PUT',
      headers,
      body: JSON.stringify(data),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to update company context' }));
      throw new Error(error.detail || 'Failed to update company context');
    }
    return response.json();
  },

  /**
   * Get team structure (departments and roles).
   * @param {string} companyId - Company ID
   * @returns {Promise<{departments: Array}>}
   */
  async getCompanyTeam(companyId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/team`, { headers });
    if (!response.ok) {
      throw new Error('Failed to get team structure');
    }
    return response.json();
  },

  /**
   * Create a new department.
   * @param {string} companyId - Company ID
   * @param {Object} dept - Department data {name, slug, description, purpose}
   * @returns {Promise<Object>} Created department
   */
  async createCompanyDepartment(companyId, dept) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/departments`, {
      method: 'POST',
      headers,
      body: JSON.stringify(dept),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to create department' }));
      throw new Error(error.detail || 'Failed to create department');
    }
    return response.json();
  },

  /**
   * Update a department.
   * @param {string} companyId - Company ID
   * @param {string} deptId - Department ID
   * @param {Object} data - Fields to update
   * @returns {Promise<Object>} Updated department
   */
  async updateCompanyDepartment(companyId, deptId, data) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/departments/${deptId}`, {
      method: 'PUT',
      headers,
      body: JSON.stringify(data),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to update department' }));
      throw new Error(error.detail || 'Failed to update department');
    }
    return response.json();
  },

  /**
   * Create a new role in a department.
   * @param {string} companyId - Company ID
   * @param {string} deptId - Department ID
   * @param {Object} role - Role data {name, slug, title, responsibilities, system_prompt}
   * @returns {Promise<Object>} Created role
   */
  async createCompanyRole(companyId, deptId, role) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/departments/${deptId}/roles`, {
      method: 'POST',
      headers,
      body: JSON.stringify(role),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to create role' }));
      throw new Error(error.detail || 'Failed to create role');
    }
    return response.json();
  },

  /**
   * Update a role.
   * @param {string} companyId - Company ID
   * @param {string} deptId - Department ID
   * @param {string} roleId - Role ID
   * @param {Object} updates - Role updates {name, title, responsibilities, system_prompt}
   * @returns {Promise<Object>} Updated role
   */
  async updateCompanyRole(companyId, deptId, roleId, updates) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/departments/${deptId}/roles/${roleId}`, {
      method: 'PUT',
      headers,
      body: JSON.stringify(updates),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to update role' }));
      throw new Error(error.detail || 'Failed to update role');
    }
    return response.json();
  },

  /**
   * Get playbooks (SOPs, frameworks, policies).
   * @param {string} companyId - Company ID
   * @param {string} docType - Optional filter: 'sop', 'framework', 'policy'
   * @returns {Promise<{playbooks: Array}>}
   */
  async getCompanyPlaybooks(companyId, docType = null) {
    const headers = await getAuthHeaders();
    const params = docType ? `?doc_type=${docType}` : '';
    const response = await fetch(`${API_BASE}/api/company/${companyId}/playbooks${params}`, { headers });
    if (!response.ok) {
      throw new Error('Failed to get playbooks');
    }
    return response.json();
  },

  /**
   * Get all unique tags used across playbooks for a company.
   * @param {string} companyId - Company ID
   * @returns {Promise<{tags: Array<string>}>}
   */
  async getCompanyPlaybookTags(companyId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/playbooks/tags`, { headers });
    if (!response.ok) {
      throw new Error('Failed to get playbook tags');
    }
    return response.json();
  },

  /**
   * Create a new playbook.
   * @param {string} companyId - Company ID
   * @param {Object} playbook - Playbook data {title, doc_type, content, department_id}
   * @returns {Promise<Object>} Created playbook with version
   */
  async createCompanyPlaybook(companyId, playbook) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/playbooks`, {
      method: 'POST',
      headers,
      body: JSON.stringify(playbook),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to create playbook' }));
      throw new Error(error.detail || 'Failed to create playbook');
    }
    return response.json();
  },

  /**
   * Update a playbook (creates new version).
   * @param {string} companyId - Company ID
   * @param {string} playbookId - Playbook ID
   * @param {Object} data - {content, change_summary}
   * @returns {Promise<Object>} Updated playbook with new version
   */
  async updateCompanyPlaybook(companyId, playbookId, data) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/playbooks/${playbookId}`, {
      method: 'PUT',
      headers,
      body: JSON.stringify(data),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to update playbook' }));
      throw new Error(error.detail || 'Failed to update playbook');
    }
    return response.json();
  },

  // Alias for updateCompanyPlaybook for consistency with MyCompany.jsx naming
  async updatePlaybook(companyId, playbookId, data) {
    return this.updateCompanyPlaybook(companyId, playbookId, data);
  },

  /**
   * Delete a playbook.
   * @param {string} companyId - Company ID
   * @param {string} playbookId - Playbook ID
   * @returns {Promise<void>}
   */
  async deletePlaybook(companyId, playbookId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/playbooks/${playbookId}`, {
      method: 'DELETE',
      headers,
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to delete playbook' }));
      throw new Error(error.detail || 'Failed to delete playbook');
    }
    return response.json();
  },

  /**
   * Get decisions (saved council outputs).
   * @param {string} companyId - Company ID
   * @returns {Promise<{decisions: Array}>}
   */
  async getCompanyDecisions(companyId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/decisions`, { headers });
    if (!response.ok) {
      throw new Error('Failed to get decisions');
    }
    return response.json();
  },

  /**
   * Save a decision from council output.
   * @param {string} companyId - Company ID
   * @param {Object} decision - Decision data {title, content, department_id, source_conversation_id, tags}
   * @returns {Promise<Object>} Created decision
   */
  async createCompanyDecision(companyId, decision) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/decisions`, {
      method: 'POST',
      headers,
      body: JSON.stringify(decision),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to save decision' }));
      throw new Error(error.detail || 'Failed to save decision');
    }
    return response.json();
  },

  /**
   * Promote a decision to a playbook.
   * @param {string} companyId - Company ID
   * @param {string} decisionId - Decision ID
   * @param {Object} data - {doc_type, title}
   * @returns {Promise<Object>} Created playbook
   */
  async promoteDecisionToPlaybook(companyId, decisionId, data) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/decisions/${decisionId}/promote`, {
      method: 'POST',
      headers,
      body: JSON.stringify(data),
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to promote decision' }));
      throw new Error(error.detail || 'Failed to promote decision');
    }
    return response.json();
  },

  /**
   * Archive a decision (soft delete).
   * @param {string} companyId - Company ID
   * @param {string} decisionId - Decision ID
   * @returns {Promise<Object>} Success response
   */
  async archiveDecision(companyId, decisionId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/decisions/${decisionId}/archive`, {
      method: 'POST',
      headers,
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to archive decision' }));
      throw new Error(error.detail || 'Failed to archive decision');
    }
    return response.json();
  },

  /**
   * Delete a decision permanently.
   * @param {string} companyId - Company ID
   * @param {string} decisionId - Decision ID
   * @returns {Promise<Object>} Success response
   */
  async deleteDecision(companyId, decisionId) {
    const headers = await getAuthHeaders();
    const response = await fetch(`${API_BASE}/api/company/${companyId}/decisions/${decisionId}`, {
      method: 'DELETE',
      headers,
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({ detail: 'Failed to delete decision' }));
      throw new Error(error.detail || 'Failed to delete decision');
    }
    return response.json();
  },

  /**
   * Get activity logs for a company.
   * @param {string} companyId - Company ID
   * @param {number} limit - Max number of logs to return
   * @param {string} eventType - Optional filter by event type
   * @returns {Promise<{logs: Array}>}
   */
  async getCompanyActivity(companyId, limit = 50, eventType = null) {
    const headers = await getAuthHeaders();
    const params = new URLSearchParams();
    if (limit) params.append('limit', limit);
    if (eventType) params.append('event_type', eventType);
    const queryString = params.toString() ? `?${params.toString()}` : '';
    const response = await fetch(`${API_BASE}/api/company/${companyId}/activity${queryString}`, { headers });
    if (!response.ok) {
      throw new Error('Failed to get activity logs');
    }
    return response.json();
  },
};

```